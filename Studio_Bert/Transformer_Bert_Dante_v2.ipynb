{"cells":[{"cell_type":"markdown","metadata":{"id":"yDKuSNBd92YI"},"source":["## Pacchetti da installare"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":29014,"status":"ok","timestamp":1683459085348,"user":{"displayName":"Daniele Badiali","userId":"07880650122235290376"},"user_tz":-120},"id":"hJy-juNOpUOY","outputId":"37eff663-ee85-4561-94b5-9940b58432c9"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"1eALqJmsL4C_","executionInfo":{"status":"ok","timestamp":1683459089344,"user_tz":-120,"elapsed":4002,"user":{"displayName":"Daniele Badiali","userId":"07880650122235290376"}}},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","\n","from sklearn.model_selection import train_test_split"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":67505,"status":"ok","timestamp":1683459156840,"user":{"displayName":"Daniele Badiali","userId":"07880650122235290376"},"user_tz":-120},"id":"NE4enZGpvMRX","colab":{"base_uri":"https://localhost:8080/"},"outputId":"c1581ba0-56fe-4d10-b3d7-d0da633feb55"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m33.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m498.1/498.1 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m462.3/462.3 kB\u001b[0m \u001b[31m38.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m78.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m72.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m99.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m101.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","tensorflow-metadata 1.13.1 requires protobuf<5,>=3.20.3, but you have protobuf 3.19.6 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0m"]}],"source":["!pip install -q -U 'tensorflow-text==2.8.*'"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":90271,"status":"ok","timestamp":1683459247105,"user":{"displayName":"Daniele Badiali","userId":"07880650122235290376"},"user_tz":-120},"id":"FPtWz_qHuofc","colab":{"base_uri":"https://localhost:8080/"},"outputId":"38753b50-9f00-49e9-a683-749377c25c7b"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m31.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m240.6/240.6 kB\u001b[0m \u001b[31m26.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m175.1/175.1 kB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.9/118.9 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m585.9/585.9 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m63.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m591.0/591.0 kB\u001b[0m \u001b[31m46.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m72.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.4/302.4 kB\u001b[0m \u001b[31m35.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m85.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m89.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m440.7/440.7 kB\u001b[0m \u001b[31m42.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m81.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m110.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Building wheel for pyyaml (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n"]}],"source":["!pip install -q tf-models-official"]},{"cell_type":"markdown","metadata":{"id":"xXYm-Qqw-ANh"},"source":["## Import notebook"]},{"cell_type":"code","execution_count":5,"metadata":{"collapsed":true,"id":"UaAiWsEuC_4K","executionInfo":{"status":"ok","timestamp":1683459249201,"user_tz":-120,"elapsed":2121,"user":{"displayName":"Daniele Badiali","userId":"07880650122235290376"}}},"outputs":[],"source":["import os\n","import re\n","import datetime\n","import pathlib\n","import json\n","from pathlib import Path\n","'''\n","import pandas as pd\n","import numpy as np\n","\n","from sklearn.model_selection import train_test_split\n","'''\n","import tensorflow as tf\n","import tensorflow_hub as hub\n","import tensorflow_text as text\n","from tensorflow_text.tools.wordpiece_vocab import bert_vocab_from_dataset as bert_vocab\n","\n","import matplotlib.pyplot as plt\n","\n","from typing import Tuple\n","from tensorboard.plugins.hparams import api as hp"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"uKEqRlKowOQS","executionInfo":{"status":"ok","timestamp":1683459249202,"user_tz":-120,"elapsed":13,"user":{"displayName":"Daniele Badiali","userId":"07880650122235290376"}}},"outputs":[],"source":["tf.get_logger().setLevel('ERROR')\n","tf.config.run_functions_eagerly(True)"]},{"cell_type":"markdown","metadata":{"id":"HRe16D-rUBLA"},"source":["## Variabili Globali"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"ewLgCIuEpczO","executionInfo":{"status":"ok","timestamp":1683459249202,"user_tz":-120,"elapsed":13,"user":{"displayName":"Daniele Badiali","userId":"07880650122235290376"}}},"outputs":[],"source":["# PARAMETRI GLOBALI\n","root_folder = 'drive/MyDrive/BERT/'\n","\n","# DATI\n","data_folder_name = 'data'\n","train_filename = 'train_data.csv'\n","\n","DATA_PATH = os.path.abspath(os.path.join(root_folder, data_folder_name))\n","train_data_filenamepath = os.path.abspath(os.path.join(DATA_PATH, train_filename))\n","\n","# PATH LOG Tensorboard\n","PATH_LOG = 'logs/fit/transformer_multi_bert_dante'\n","PATH_LOG = os.path.abspath(os.path.join(root_folder, PATH_LOG))\n","log_dir =  os.path.abspath(os.path.join(PATH_LOG, datetime.datetime.now().strftime('%Y%m%d-%H%M%S'))) \n","log_history = os.path.abspath(os.path.join(PATH_LOG, 'histrory.json'))\n","\n","# PATH WEIGHTS Tensorboard\n","PATH_WEIGHTS = 'weights/transformer_multi_bert_dante'\n","PATH_WEIGHTS = os.path.abspath(os.path.join(root_folder, PATH_WEIGHTS))\n","checkpoint_path = os.path.abspath(os.path.join(PATH_WEIGHTS, 'cp.ckpt'))\n","\n","# VOCABOLARIO\n","vocab_folder = 'vocab'\n","multilingual_vocab_finalname = 'multilingual_vocab.txt'\n","ita_vocab_finalname = 'ita_dante_vocab.txt'\n","\n","VOCAB_PATH = os.path.abspath(os.path.join(root_folder, vocab_folder))\n","multilingual_vocab_filenamepath = os.path.abspath(os.path.join(VOCAB_PATH, multilingual_vocab_finalname))\n","ita_vocab_filenamepath = os.path.abspath(os.path.join(VOCAB_PATH, ita_vocab_finalname))\n","\n","# parametri per il modello\n","ORIGINAL_COLUMN = 'Original'\n","TRANSLATE_COLUMN = 'Translate'\n","TYPE_COLUMN ='Type'"]},{"cell_type":"markdown","metadata":{"id":"LCiP6wT05k6j"},"source":["## Iper Parametri Modello"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"8CN-4Uzoqbjl","executionInfo":{"status":"ok","timestamp":1683459249203,"user_tz":-120,"elapsed":14,"user":{"displayName":"Daniele Badiali","userId":"07880650122235290376"}}},"outputs":[],"source":["NUM_SAMPLES = 25000\n","TEST = 200\n","TEST_SIZE = 0.3\n","\n","MAX_VOCAB_SIZE = 30000 \n","EMBEDDING_DIM = 128\n","HIDDEN_DIM = 1024 # numero di celle nei layer ricorrenti nascosti\n","\n","BATCH_SIZE = 32\n","BUFFER_SIZE = 2000\n","MAX_SEQ_LENGTH = 128\n","\n","NUM_LAYERS = 2 # Numero di layer di Decoder del Transformer\n","NUM_HEADS = 8 # Numero di meccanismi di multi-head attention\n","FF_DIM = 32 # Numero di celle dei Layer Feed Forward\n","DROPUOT = 0.5\n","\n","# Ottimizzatore Adam\n","LEARNING_RATE_ADAM = 1e-4\n","BETA_1 = 0.66\n","BETA_2 = 0.999\n","EPOCHS_ADAM = 5\n","\n","# IMPOSTO IL DEBUG A TRUE \n","debug = True\n","trainable = False\n","training = True"]},{"cell_type":"markdown","metadata":{"id":"BehZY4rETECN"},"source":["## Parametri BERT"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":13,"status":"ok","timestamp":1683459249203,"user":{"displayName":"Daniele Badiali","userId":"07880650122235290376"},"user_tz":-120},"id":"fodDcY6sm392","colab":{"base_uri":"https://localhost:8080/"},"outputId":"8fc8478d-63ef-4201-85dc-12197404aaf1"},"outputs":[{"output_type":"stream","name":"stdout","text":["BERT model name                    :  distilbert_multi_cased_L-6_H-768_A-12/1\n","BERT model selected                :  https://tfhub.dev/jeongukjae/distilbert_multi_cased_L-6_H-768_A-12/1\n","BERT preprocess                    :  https://tfhub.dev/jeongukjae/distilbert_multi_cased_preprocess/2\n"]}],"source":["bert_model_name = 'distilbert_multi_cased_L-6_H-768_A-12/1'  \n","tfhub_handle_preprocess = 'https://tfhub.dev/jeongukjae/distilbert_multi_cased_preprocess/2'\n","tfhub_handle_encoder =  'https://tfhub.dev/jeongukjae/distilbert_multi_cased_L-6_H-768_A-12/1'\n","\n","if debug:\n","  print('BERT model name                    : ', bert_model_name)\n","  print('BERT model selected                : ', tfhub_handle_encoder)\n","  print('BERT preprocess                    : ', tfhub_handle_preprocess)"]},{"cell_type":"markdown","metadata":{"id":"5DPeN9Vanbvv"},"source":["## DATASET"]},{"cell_type":"markdown","metadata":{"id":"LU7AorKXT8K7"},"source":["### Caricamento Dati"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"Jm_Up6gyOTgW","executionInfo":{"status":"ok","timestamp":1683459249204,"user_tz":-120,"elapsed":11,"user":{"displayName":"Daniele Badiali","userId":"07880650122235290376"}}},"outputs":[],"source":["def preprocess_sentence(w):\n","  '''\n","  Preprocessing dei testi di input, impostando tutti i caratteri\n","  minuscoli, aggiungendo uno spazio prima di ogni punto e sostituendo\n","  qualsiasi carattere con uno spazio se non è compreso nel seguente elenco:\n","  (a-z, A-Z, \".\", \"?\", \"!\", \",\", \"'\", \"’\")\n","  '''\n","  # inserimento di uno spazio tra ogni parola e il successivo punto,\n","  # punto esclamativo, punto interrogativo e virgola\n","  # esempio: \"ciao, come và?\" => \"ciao , come và ?\"\n","  w = re.sub(r\"([?.!,])\", r\" \\1 \", w) # inserimento di uno spazio\n","\n","  # sostituzione dei caratteri apostrofo\n","  w = re.sub(r\"([’]+)\", \"'\", w)\n","\n","  w = w.replace(\"á\", \"à\")\n","  w = w.replace(\"é\", \"è\")\n","  w = w.replace(\"í\", \"ì\")\n","  w = w.replace(\"ó\", \"ò\")\n","  w = w.replace(\"ú\", \"ù\")\n","  w = w.replace('\"', \" \")\n","  w = w.replace(':', \" \")\n","  w = w.replace('«', \" \")\n","  w = w.replace('»', \" \")\n","  w = w.replace('‘', \" \")\n","  w = w.replace('-', \" \")\n","  w = w.replace('[', \" \")\n","  w = w.replace(']', \" \")\n","  w = w.replace('(', \" \")\n","  w = w.replace(')', \" \")\n","  w = w.replace(\"•\", \" \")\n","  w = w.replace(\"..\", \".\")\n","  w = w.replace(\"...\", \".\")\n","  w = w.replace(\"\\xa0\", \" \")\n","  w = w.replace(\"\\xc3\\xa8\", \" \")\n","  w = w.replace(\"\\xe2\\x80\\xaf\", \" \")\n","  w = w.replace(\"   \", \" \")\n","  w = w.replace(\"–\", \" \")\n","  w = w.replace(\"“\", \" \")\n","  w = w.replace(\"”\", \" \")\n","  w = w.replace(\"„\", \" \")\n","  w = w.replace(\"─\", \" \")\n","  w = w.replace(\"♪\", \" \")\n","  w = w.replace(\"#\", \" \")\n","  w = w.replace(\"/\", \" \")\n","  w = w.replace(\"=\", \" \")\n","  w = w.replace(\">\", \" \")\n","  w = w.replace(\"\\\\\", \" \")\n","  w = w.replace(\"`\", \" \")\n","  w = w.replace(\"¡\", \" \")\n","  w = w.replace(\"¿\", \" \")\n","  w = w.replace(\"œ\", \" \")\n","  w = w.replace(\"♗\", \" \")\n","  w = w.replace(\"♘\", \" \")\n","  w = w.replace(\"《\", \" \")\n","  w = w.replace(\"》\", \" \")\n","  # w = w.replace(\"\", \" \")\n","  # w = w.replace(\"\", \" \")\n","\n","  # inserimento di uno spazio dopo apostrofo\n","  w = re.sub(r\"(['])\", r\"\\1 \", w) \n","\n","  w = w.replace(\" ' \", \" '\")\n","\n","  w = re.sub(r'[\" \"]+', \" \", w) # rimozione di più spazi consecutivi\n","  return w"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":34114,"status":"ok","timestamp":1683459283308,"user":{"displayName":"Daniele Badiali","userId":"07880650122235290376"},"user_tz":-120},"id":"duGPhZ_jgPVI","colab":{"base_uri":"https://localhost:8080/"},"outputId":"3f8562cb-32f1-4895-a610-ba24dca4e5d5"},"outputs":[{"output_type":"stream","name":"stdout","text":["Dati totali presenti nel Dataset               : 379582\n","----------------------------------- TRAIN SET -----------------------------------------\n","['Min önskan och vilja styrdes av gudomlig kärlek som driver solen och andra stjärnor framåt som ett hjul flyttade regelbundet . ']\n","[\" ma già volgeva il mio disio e 'l velle , sì come rota ch' igualmente è mossa , l' amor che move il sole e l' altre stelle\"]\n","[\"De même que , en temps de guerre , officiers et soldats se sentent autorisès par l' opinion gènèrale à commettre des actes qui , en temps de paix , sont tenus pour criminels , de même les rèvolutionnaires , dans leur lutte , se regardaient comme couverts par l' opinion de leur cercle , en vertu de laquelle les actes de cruautè qu' ils commettaient ètaient nobles et moraux , ètant commis par eux au prix de leur libertè , de leur vie , de tout ce qui est cher à la plupart des hommes . Ainsi s' expliquait , que des personnes excellentes , incapables non seulement de causer une souffrance , mais même d' en supporter la vue , pussent se prèparer tranquillement à la violence et au meurtre , et professer la saintetè de tels actes , considèrès comme moyens de dèfense , ou encore comme instrument utile à la rèalisation d' un idèal de bonheur pour l' humanitè . \"]\n","[\"Così come in tempo di guerra , ufficiali e soldati si sentono responsabilizzati dall' opinione generale a commettere atti che , in tempo di pace , sono necessari per i criminali , anche rivoluzionari nella loro lotta , considerati coperti dal parere del loro circolo , secondo cui gli atti di crudeltà che hanno commesso erano nobili e morali , essendo commessi da loro nel prezzo della loro libertà , della loro vita , di tutto ciò che è caro alla maggior parte degli uomini . Ciò ha spiegato che persone eccellenti , in grado non solo di causare sofferenza , ma anche di sopportarne la vista , potrebbero felicemente prepararsi alla violenza e all' omicidio , e professare la santità di tali atti , considerati come un mezzo di difesa , o come utili per la realizzazione di un ideale di felicità per l' umanità . \"]\n"]}],"source":["df = pd.read_csv(\n","  train_data_filenamepath,\n","  usecols=[ORIGINAL_COLUMN, TRANSLATE_COLUMN, TYPE_COLUMN],\n",")\n","\n","# Preprocessing dei dati di Input\n","df[ORIGINAL_COLUMN] = df[ORIGINAL_COLUMN].apply(lambda x : preprocess_sentence(x))\n","\n","# Preprocessing dei dati Target con aggiunta del token di fine frase\n","df[TRANSLATE_COLUMN] = df[TRANSLATE_COLUMN].apply(lambda x : preprocess_sentence(x))\n","\n","if debug:\n","  print(f'Dati totali presenti nel Dataset               : {len(df)}')\n","  print('----------------------------------- TRAIN SET -----------------------------------------')\n","  print((df[ORIGINAL_COLUMN].tolist())[-1:])\n","  print((df[TRANSLATE_COLUMN].tolist())[-1:])\n","  print((df[ORIGINAL_COLUMN].tolist())[:1])\n","  print((df[TRANSLATE_COLUMN].tolist())[:1])"]},{"cell_type":"markdown","metadata":{"id":"njyY9RWlFMWu"},"source":["## Tokenizer\n","\n","Creo due differenti tokenizer che mi servizranno per la predisposizione dei dati di input:\n","\n","\n","*   EncTokenizer classe custom per la tokenizzazione dei dati di input al Layer di Encoder di Bert\n","*   DecTokenizer classe custom per la tokenizzazione dei dati di input al Layer di Decoder\n","\n"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":4258,"status":"ok","timestamp":1683459287539,"user":{"displayName":"Daniele Badiali","userId":"07880650122235290376"},"user_tz":-120},"id":"fUG1fTAYekOy","colab":{"base_uri":"https://localhost:8080/"},"outputId":"dbb95e56-6965-4662-ae92-27e66ac07a0e"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/structured_function.py:254: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n","  warnings.warn(\n"]}],"source":["input_data_vocab = df[ORIGINAL_COLUMN].tolist()\n","target_data_vocab = df[TRANSLATE_COLUMN].tolist()\n","\n","dataset = tf.data.Dataset.from_tensor_slices((input_data_vocab, target_data_vocab))\n","dataset = dataset.shuffle(len(input_data_vocab)).batch(BATCH_SIZE, drop_remainder=True)\n","\n","train_multilingual = dataset.map(lambda multilingual, ita: multilingual)\n","train_ita = dataset.map(lambda multilingual, ita: ita)"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"xWO-LrXJe0cF","executionInfo":{"status":"ok","timestamp":1683459287540,"user_tz":-120,"elapsed":34,"user":{"displayName":"Daniele Badiali","userId":"07880650122235290376"}}},"outputs":[],"source":["def write_vocab_file(filepath, vocab):\n","  with open(filepath, 'w') as f:\n","    for token in vocab:\n","      print(token, file=f)"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"yGdsrOoKiYUK","executionInfo":{"status":"ok","timestamp":1683459287541,"user_tz":-120,"elapsed":33,"user":{"displayName":"Daniele Badiali","userId":"07880650122235290376"}}},"outputs":[],"source":["def cleanup_text(reserved_tokens, token_txt):\n","\n","  # Drop the reserved tokens, except for \"[UNK]\".\n","  bad_tokens = [re.escape(tok) for tok in reserved_tokens if tok != \"[UNK]\"]\n","  bad_token_re = \"|\".join(bad_tokens)\n","\n","  bad_cells = tf.strings.regex_full_match(token_txt, bad_token_re)\n","  result = tf.ragged.boolean_mask(token_txt, ~bad_cells)\n","\n","  # Join them into strings.\n","  result = tf.strings.reduce_join(result, separator=' ', axis=-1)\n","\n","  return result"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"qbKNS_uQhHLz","executionInfo":{"status":"ok","timestamp":1683459287541,"user_tz":-120,"elapsed":32,"user":{"displayName":"Daniele Badiali","userId":"07880650122235290376"}}},"outputs":[],"source":["tokenizers = tf.Module()"]},{"cell_type":"markdown","metadata":{"id":"0KUcCnjXVjt3"},"source":["### Classe EncTokenizer\n","\n","Classe custom per la tokenizzazione dei dati di italiano e che crea i tre vettori necessari al layer di Encoder \n","Bert:\n","\n","\n","*   input_word_ids\n","*   input_type_ids\n","*   input_mask\n","\n","\n","\n"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"Yr0izOZLembx","executionInfo":{"status":"ok","timestamp":1683459287542,"user_tz":-120,"elapsed":32,"user":{"displayName":"Daniele Badiali","userId":"07880650122235290376"}}},"outputs":[],"source":["bert_tokenizer_params=dict(lower_case=True)\n","reserved_tokens = {\n","  'start_of_sequence_id': 101,\n","  'end_of_segment_id': 102,\n","  'padding_id': 0,\n","  'mask_id': 103\n","}\n","\n","bert_vocab_args = dict(\n","  # The target vocabulary size\n","  vocab_size = MAX_VOCAB_SIZE,\n","  # Reserved tokens that must be included in the vocabulary\n","  reserved_tokens=reserved_tokens,\n","  # Arguments for `text.BertTokenizer`\n","  bert_tokenizer_params=bert_tokenizer_params,\n","  # Arguments for `wordpiece_vocab.wordpiece_tokenizer_learner_lib.learn`\n","  learn_params={},\n",")"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"BwSKtlLSe7bH","executionInfo":{"status":"ok","timestamp":1683459287543,"user_tz":-120,"elapsed":32,"user":{"displayName":"Daniele Badiali","userId":"07880650122235290376"}}},"outputs":[],"source":["exist_vocab = Path(multilingual_vocab_filenamepath)\n","\n","if not exist_vocab.exists():\n","  multilingual_vocab = bert_vocab.bert_vocab_from_dataset(\n","      train_multilingual.batch(MAX_VOCAB_SIZE).prefetch(tf.data.AUTOTUNE),\n","      **bert_vocab_args\n","  )\n","\n","  write_vocab_file(multilingual_vocab_filenamepath, multilingual_vocab)"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"WmsNdDLNf6vr","executionInfo":{"status":"ok","timestamp":1683459287543,"user_tz":-120,"elapsed":32,"user":{"displayName":"Daniele Badiali","userId":"07880650122235290376"}}},"outputs":[],"source":["class EncTokenizer(tf.Module):\n","  def __init__(self, tfhub_handle_preprocess):\n","    self.preprocessor = hub.KerasLayer(tfhub_handle_preprocess)\n","    \n","  @tf.function\n","  def tokenize(self, strings):\n","    return self.preprocessor(strings)"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"-4B-HWWcmsmz","executionInfo":{"status":"ok","timestamp":1683459296739,"user_tz":-120,"elapsed":9227,"user":{"displayName":"Daniele Badiali","userId":"07880650122235290376"}}},"outputs":[],"source":["tokenizers.multilingual = EncTokenizer(tfhub_handle_preprocess)"]},{"cell_type":"markdown","metadata":{"id":"mICEGEzJVnvx"},"source":["### Classe DecTokenizer\n","\n","Classe custom per la tokenizzazione dei dati in lingua italiana per il layer di Decoder\n"]},{"cell_type":"code","execution_count":20,"metadata":{"id":"abBEnJJGV0AD","executionInfo":{"status":"ok","timestamp":1683459296739,"user_tz":-120,"elapsed":9,"user":{"displayName":"Daniele Badiali","userId":"07880650122235290376"}}},"outputs":[],"source":["bert_tokenizer_params=dict(lower_case=True)\n","reserved_tokens_vocab=[\"[PAD]\", \"[UNK]\", \"[START]\", \"[END]\"]\n","\n","bert_vocab_args = dict(\n","  # The target vocabulary size\n","  vocab_size = MAX_VOCAB_SIZE,\n","  # Reserved tokens that must be included in the vocabulary\n","  reserved_tokens=reserved_tokens_vocab,\n","  # Arguments for `text.BertTokenizer`\n","  bert_tokenizer_params=bert_tokenizer_params,\n","  # Arguments for `wordpiece_vocab.wordpiece_tokenizer_learner_lib.learn`\n","  learn_params={},\n",")"]},{"cell_type":"code","execution_count":21,"metadata":{"id":"dGsP1V4nVz6S","executionInfo":{"status":"ok","timestamp":1683459296740,"user_tz":-120,"elapsed":9,"user":{"displayName":"Daniele Badiali","userId":"07880650122235290376"}}},"outputs":[],"source":["exist_vocab = Path(ita_vocab_filenamepath)\n","\n","if not exist_vocab.exists():\n","  ita_vocab = bert_vocab.bert_vocab_from_dataset(\n","      train_ita.batch(MAX_VOCAB_SIZE).prefetch(tf.data.AUTOTUNE),\n","      **bert_vocab_args\n","  )\n","\n","  write_vocab_file(ita_vocab_filenamepath, ita_vocab)"]},{"cell_type":"code","execution_count":22,"metadata":{"id":"BeaD2-uLWT50","executionInfo":{"status":"ok","timestamp":1683459296740,"user_tz":-120,"elapsed":9,"user":{"displayName":"Daniele Badiali","userId":"07880650122235290376"}}},"outputs":[],"source":["START = tf.argmax(tf.constant(reserved_tokens_vocab) == \"[START]\")\n","END = tf.argmax(tf.constant(reserved_tokens_vocab) == \"[END]\")\n","\n","def add_start_end(ragged):\n","  count = ragged.bounding_shape(out_type=tf.int32)[0]\n","\n","  starts = tf.fill([count,1], START)\n","  starts = tf.cast(starts, tf.int32)\n","\n","  ends = tf.fill([count,1], END)\n","  ends = tf.cast(ends, tf.int32)\n","\n","  x = tf.concat([starts, ragged, ends], axis=1)\n","  return x"]},{"cell_type":"code","execution_count":23,"metadata":{"id":"iaAW-xm5WT1_","executionInfo":{"status":"ok","timestamp":1683459296741,"user_tz":-120,"elapsed":9,"user":{"displayName":"Daniele Badiali","userId":"07880650122235290376"}}},"outputs":[],"source":["class DecTokenizer(tf.Module):\n","  def __init__(self, reserved_tokens_vocab, vocab_path):\n","    self.tokenizer = text.BertTokenizer(vocab_path, lower_case=True, token_out_type=tf.int32)\n","    self._reserved_tokens_vocab = reserved_tokens_vocab\n","    self._vocab_path = tf.saved_model.Asset(vocab_path)\n","\n","    vocab = pathlib.Path(vocab_path).read_text().splitlines()\n","    self.vocab = tf.Variable(vocab)\n","\n","    ## Create the signatures for export:   \n","\n","    # Include a tokenize signature for a batch of strings. \n","    self.tokenize.get_concrete_function(\n","        tf.TensorSpec(shape=[None], dtype=tf.string))\n","    \n","    # Include `detokenize` and `lookup` signatures for:\n","    #   * `Tensors` with shapes [tokens] and [batch, tokens]\n","    #   * `RaggedTensors` with shape [batch, tokens]\n","    self.detokenize.get_concrete_function(\n","        tf.TensorSpec(shape=[None, None], dtype=tf.int32))\n","    self.detokenize.get_concrete_function(\n","          tf.RaggedTensorSpec(shape=[None, None], dtype=tf.int32))\n","\n","    self.lookup.get_concrete_function(\n","        tf.TensorSpec(shape=[None, None], dtype=tf.int32))\n","    self.lookup.get_concrete_function(\n","          tf.RaggedTensorSpec(shape=[None, None], dtype=tf.int32))\n","\n","    # These `get_*` methods take no arguments\n","    self.get_vocab_size.get_concrete_function()\n","    self.get_vocab_path.get_concrete_function()\n","    self.get_reserved_tokens.get_concrete_function()\n","    \n","  @tf.function\n","  def tokenize(self, strings):\n","    enc = self.tokenizer.tokenize(strings)\n","    # Merge the `word` and `word-piece` axes.\n","    enc = enc.merge_dims(-2,-1)\n","    enc = add_start_end(enc)\n","    return enc\n","\n","  @tf.function\n","  def detokenize(self, tokenized):\n","    words = self.tokenizer.detokenize(tokenized)\n","    return cleanup_text(self._reserved_tokens_vocab, words)\n","\n","  @tf.function\n","  def lookup(self, token_ids):\n","    return tf.gather(self.vocab, token_ids)\n","\n","  @tf.function\n","  def get_vocab_size(self):\n","    return tf.shape(self.vocab)[0]\n","\n","  @tf.function\n","  def get_vocab_path(self):\n","    return self._vocab_path\n","\n","  @tf.function\n","  def get_reserved_tokens(self):\n","    return tf.constant(self._reserved_tokens_vocab)"]},{"cell_type":"code","execution_count":24,"metadata":{"id":"svlLobM4WTzC","executionInfo":{"status":"ok","timestamp":1683459299906,"user_tz":-120,"elapsed":3172,"user":{"displayName":"Daniele Badiali","userId":"07880650122235290376"}}},"outputs":[],"source":["tokenizers.ita = DecTokenizer(reserved_tokens_vocab, ita_vocab_filenamepath)"]},{"cell_type":"markdown","metadata":{"id":"pKZxiQ5_Whmw"},"source":["### Analisi Dati Tokenizzati"]},{"cell_type":"code","execution_count":25,"metadata":{"executionInfo":{"elapsed":13,"status":"ok","timestamp":1683459299907,"user":{"displayName":"Daniele Badiali","userId":"07880650122235290376"},"user_tz":-120},"id":"Jrg6TwQzW5LN","colab":{"base_uri":"https://localhost:8080/"},"outputId":"548b267b-72bf-4ae1-8b72-3f4df05bd42f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Vocabolario Italiano : 23120\n"]}],"source":["print(f'Vocabolario Italiano : {tokenizers.ita.get_vocab_size()}')"]},{"cell_type":"markdown","metadata":{"id":"5QIDajkEsVU1"},"source":["## Creazione dataset\n","Utilizzo della libreria tf.data per la gestione del dataset da utilizzare.\n","Verranno creati batch di esempi che verranno utilizzati durante l'addestramento."]},{"cell_type":"code","execution_count":26,"metadata":{"id":"ESHUcQtthhd2","executionInfo":{"status":"ok","timestamp":1683459299907,"user_tz":-120,"elapsed":7,"user":{"displayName":"Daniele Badiali","userId":"07880650122235290376"}}},"outputs":[],"source":["def split_dataset(df: pd.DataFrame,\n","                  filter_column: str, \n","                  debug: bool = False) -> Tuple:\n","\n","  print(f'Lunghezza df {len(df)}')\n","  dataset = (df.loc[df[TYPE_COLUMN] == filter_column]).copy() \n","  print(f'Lunghezza dataset {len(dataset)}')\n","  \n","  if NUM_SAMPLES > 0:\n","    dataset = dataset[:NUM_SAMPLES]\n","\n","  input_data = dataset[ORIGINAL_COLUMN].tolist()\n","  target_data = dataset[TRANSLATE_COLUMN].tolist()\n","\n","  train_input_data, validation_input_data, train_target_data, validation_target_data = train_test_split(\n","    input_data[:-TEST], \n","    target_data[:-TEST], \n","    test_size=TEST_SIZE, \n","    random_state=42,\n","    shuffle=True\n","  ) \n","\n","  train_input_data = train_input_data[:(int((len(train_input_data) / BATCH_SIZE)) * BATCH_SIZE)]\n","  train_target_data = train_target_data[:(int((len(train_target_data) / BATCH_SIZE)) * BATCH_SIZE)]\n","  \n","  validation_input_data = validation_input_data[:(int((len(validation_input_data) / BATCH_SIZE)) * BATCH_SIZE)]\n","  validation_target_data = validation_target_data[:(int((len(validation_target_data) / BATCH_SIZE)) * BATCH_SIZE)]\n","\n","  test_input_data = input_data[len(train_input_data)+len(validation_input_data):]\n","  test_target_data = target_data[len(train_target_data)+len(validation_target_data):]\n","\n","  if debug:\n","    print(f'Dati totali presenti nel Dataset               : {len(df)}')\n","    print(f'Dati totali presenti nel Dataset di Train      : {len(train_input_data)}')\n","    print(f'Dati totali presenti nel Dataset di Validation : {len(validation_input_data)}')\n","    print(f'Dati totali presenti nel Dataset di Test       : {len(test_input_data)}\\n')\n","\n","\n","    print('----------------------------------- TRAIN SET -----------------------------------------')\n","    print(train_input_data[-4:])\n","    print(train_target_data[-4:])\n","    print('--------------------------------- VALIDATION SET --------------------------------------')\n","    print(validation_input_data[-4:])\n","    print(validation_target_data[-4:])\n","    print('----------------------------------- TEST SET ------------------------------------------')\n","    print(test_input_data[-4:])\n","    print(test_target_data[-4:])\n","\n","    print('-------------------------------- ANALISI DATI -----------------------------------------')\n","    print(f'Esempi nel Dataset di Train                            : {len(train_input_data)}')\n","    print(f'Frase più corta nel Dataset Input di Train             : {min(train_input_data, key = len)}')\n","    print(f'Frase più corta nel Dataset Target di Train            : {min(train_target_data, key = len)}')\n","    print(f'Frase più lunga nel Dataset Input di Train             : {max(train_input_data, key = len)}')\n","    print(f'Frase più lunga nel Dataset Target di Train            : {max(train_target_data, key = len)}')\n","    print('---------------------------------------------------------------------------------------')\n","    print(f'Esempi nel Dataset di Validation                       : {len(validation_input_data)}')\n","    print(f'Frase più corta nel Dataset Input di Validation        : {min(validation_input_data, key = len)}')\n","    print(f'Frase più corta nel Dataset Target di Validation       : {min(validation_target_data, key = len)}')\n","    print(f'Frase più lunga nel Dataset Input di Validation        : {max(validation_input_data, key = len)}')\n","    print(f'Frase più lunga nel Dataset Target di Validation       : {max(validation_target_data, key = len)}')\n","    print('---------------------------------------------------------------------------------------')\n","    print(f'Esempi nel Dataset di Test                             : {len(test_input_data)}')\n","    print(f'Frase più corta nel Dataset Input di Test              : {min(test_input_data, key = len)}')\n","    print(f'Frase più corta nel Dataset Target di Test             : {min(test_target_data, key = len)}')\n","    print(f'Frase più lunga nel Dataset Input di Test              : {max(test_input_data, key = len)}')\n","    print(f'Frase più lunga nel Dataset Target di Test             : {max(test_target_data, key = len)}')    \n","\n","    print('\\n--------------------------------- EXAMPLE ---------------------------------------------')\n","    print([min(train_input_data, key = len)])\n","    print(tokenizers.multilingual.tokenize([min(train_input_data, key = len)])['input_word_ids'][:, :32])\n","    print('------------------------------------------------------------------')\n","    print([min(train_target_data, key = len)])\n","    print(tokenizers.ita.tokenize([min(train_target_data, key = len)]))\n","    print('\\n')\n","    print([max(train_input_data, key = len)])\n","    print(tokenizers.multilingual.tokenize([max(train_input_data, key = len)])['input_word_ids'])\n","    print('------------------------------------------------------------------')\n","    print([max(train_target_data, key = len)])\n","    print(tokenizers.ita.tokenize([max(train_target_data, key = len)]))  \n","  \n","  return train_input_data, validation_input_data, test_input_data, train_target_data, validation_target_data, test_target_data "]},{"cell_type":"code","execution_count":27,"metadata":{"id":"ccH3jHoABPzV","executionInfo":{"status":"ok","timestamp":1683459299908,"user_tz":-120,"elapsed":7,"user":{"displayName":"Daniele Badiali","userId":"07880650122235290376"}}},"outputs":[],"source":["def prepare_batch(multilingual, ita):\n","  zero = tf.zeros([BATCH_SIZE, MAX_SEQ_LENGTH], tf.int32)\n","\n","  # Tokenizzo l'input per l'Encoder\n","  encoder = tokenizers.multilingual.tokenize(multilingual)          \n","\n","  # Tokenizzo l'input per il Decder e creo la variabile Target\n","  ita = tokenizers.ita.tokenize(ita)\n","  decoder = ita[:, :-1].to_tensor()  # Drop the [END] tokens\n","  target = ita[:, 1:].to_tensor()   # Drop the [START] tokens\n","  \n","  decoder = tf.concat([decoder, zero], 1)\n","  decoder = decoder[:, :(MAX_SEQ_LENGTH)]\n","\n","  target = tf.concat([target, zero], 1)\n","  target = target[:, :(MAX_SEQ_LENGTH)]\n","\n","  return (encoder, decoder), target"]},{"cell_type":"code","execution_count":28,"metadata":{"id":"l_dswlCiBTdR","executionInfo":{"status":"ok","timestamp":1683459299908,"user_tz":-120,"elapsed":7,"user":{"displayName":"Daniele Badiali","userId":"07880650122235290376"}}},"outputs":[],"source":["def make_batches(ds):\n","  return (\n","    ds\n","    .shuffle(BUFFER_SIZE)\n","    .batch(BATCH_SIZE)\n","    .map(prepare_batch, tf.data.AUTOTUNE)\n","    .prefetch(buffer_size=tf.data.AUTOTUNE))"]},{"cell_type":"code","execution_count":29,"metadata":{"id":"tktJ5YuIsYe3","executionInfo":{"status":"ok","timestamp":1683459299909,"user_tz":-120,"elapsed":8,"user":{"displayName":"Daniele Badiali","userId":"07880650122235290376"}}},"outputs":[],"source":["def train_val_test_dataset(df: pd.DataFrame, \n","                          filter_column: str, \n","                          debug: bool = False) -> Tuple:\n","\n","  # Recupero il dataset \n","  train_input_data, validation_input_data, test_input_data, train_target_data, validation_target_data, test_target_data = split_dataset(df=df, filter_column=filter_column, debug=debug)\n","\n","  # Definizione del dataset\n","  # [from_tensor_slices] permette di recuperare batch\n","  # di esempi dai dataset di riferimento\n","  train_dataset = tf.data.Dataset.from_tensor_slices((train_input_data, train_target_data))\n","  validation_dataset = tf.data.Dataset.from_tensor_slices((validation_input_data, validation_target_data))\n","  test_dataset = tf.data.Dataset.from_tensor_slices((test_input_data, test_target_data))\n","\n","  # impostazione del recupero di esempi presi in maniera\n","  # casuale in gruppi di [BATCH_SIZE] tra quelli disponibili\n","  train_dataset = make_batches(train_dataset)\n","  validation_dataset = make_batches(validation_dataset)\n","\n","  return train_dataset, validation_dataset, test_dataset"]},{"cell_type":"code","execution_count":30,"metadata":{"executionInfo":{"elapsed":4985,"status":"ok","timestamp":1683459304887,"user":{"displayName":"Daniele Badiali","userId":"07880650122235290376"},"user_tz":-120},"id":"nkcyLV1qqQHL","colab":{"base_uri":"https://localhost:8080/"},"outputId":"3b8f36fb-c204-4e4d-db04-4e687d9a4046"},"outputs":[{"output_type":"stream","name":"stdout","text":["Lunghezza df 379582\n","Lunghezza dataset 244398\n","Dati totali presenti nel Dataset               : 379582\n","Dati totali presenti nel Dataset di Train      : 17344\n","Dati totali presenti nel Dataset di Validation : 7424\n","Dati totali presenti nel Dataset di Test       : 232\n","\n","----------------------------------- TRAIN SET -----------------------------------------\n","[\"C' est le braquage de banque le plus sanglant qu' a connu ce pays . \", \"Il s' est converti au christianisme . \", 'Vous pouvez ècrire dans la langue que vous voulez . Sur Tatoeba , toutes les langues sont ègales . ', 'Elle a trois s urs une est infirmière et les autres sont enseignantes . ']\n","['È la rapina in banca più sanguinosa della storia di questo paese . ', 'Si è convertito al Cristianesimo . ', 'Puoi scrivere in qualsiasi lingua desideri . Su Tatoeba tutte le lingue sono uguali . ', 'Lei ha tre sorelle una è infermiera e le altre sono insegnanti . ']\n","--------------------------------- VALIDATION SET --------------------------------------\n","['Pourquoi la chance vous haït elle ? ', \"Le gouvernement des États Unis a taxè plusieurs pays d' États voyous , mais l' ironie du sort est qu' aujourd' hui , et après des dècennies de politiques agressives , d' interventions et d' invasions , ce sont les États Unis eux mêmes qui sont considèrès , dans le monde , comme l' État voyou par excellence . \", \"Je m' inquiète des rèsultats de l' examen . \", 'Vous allez marcher tous les matins . ']\n","['Perchè la fortuna vi odia ? ', \"Il governo americano ha tacciato diversi paesi come Stati canaglia , ma l' ironia è che oggi , dopo decenni di politiche aggressive , interventi e invasioni , sono gli Stati Uniti sono considerati in tutto il mondo come lo Stato canaglia per eccellenza . \", \"Mi preoccupo per i risultati dell' esame . \", 'Va a camminare ogni mattina . ']\n","----------------------------------- TEST SET ------------------------------------------\n","['Je ne vois aucun problème avec ça . ', 'Vous devez travailler , pas penser . ', \"Tatoeba n' est pas un dictionnaire . \", \"L' orthographe est très importante . \"]\n","['Non vedo dove stia il problema . ', 'Dovete lavorare , non pensare . ', 'Tatoeba non è un dizionario . ', \"L' ortografia è molto importante . \"]\n","-------------------------------- ANALISI DATI -----------------------------------------\n","Esempi nel Dataset di Train                            : 17344\n","Frase più corta nel Dataset Input di Train             :  Veux tu l' acheter ? Oui . \n","Frase più corta nel Dataset Target di Train            : Oggi offro io . \n","Frase più lunga nel Dataset Input di Train             : De même que , en temps de guerre , officiers et soldats se sentent autorisès par l' opinion gènèrale à commettre des actes qui , en temps de paix , sont tenus pour criminels , de même les rèvolutionnaires , dans leur lutte , se regardaient comme couverts par l' opinion de leur cercle , en vertu de laquelle les actes de cruautè qu' ils commettaient ètaient nobles et moraux , ètant commis par eux au prix de leur libertè , de leur vie , de tout ce qui est cher à la plupart des hommes . Ainsi s' expliquait , que des personnes excellentes , incapables non seulement de causer une souffrance , mais même d' en supporter la vue , pussent se prèparer tranquillement à la violence et au meurtre , et professer la saintetè de tels actes , considèrès comme moyens de dèfense , ou encore comme instrument utile à la rèalisation d' un idèal de bonheur pour l' humanitè . \n","Frase più lunga nel Dataset Target di Train            : Così come in tempo di guerra , ufficiali e soldati si sentono responsabilizzati dall' opinione generale a commettere atti che , in tempo di pace , sono necessari per i criminali , anche rivoluzionari nella loro lotta , considerati coperti dal parere del loro circolo , secondo cui gli atti di crudeltà che hanno commesso erano nobili e morali , essendo commessi da loro nel prezzo della loro libertà , della loro vita , di tutto ciò che è caro alla maggior parte degli uomini . Ciò ha spiegato che persone eccellenti , in grado non solo di causare sofferenza , ma anche di sopportarne la vista , potrebbero felicemente prepararsi alla violenza e all' omicidio , e professare la santità di tali atti , considerati come un mezzo di difesa , o come utili per la realizzazione di un ideale di felicità per l' umanità . \n","---------------------------------------------------------------------------------------\n","Esempi nel Dataset di Validation                       : 7424\n","Frase più corta nel Dataset Input di Validation        :  Veux tu l' acheter ? Oui . \n","Frase più corta nel Dataset Target di Validation       : Vuoi farlo ora ? \n","Frase più lunga nel Dataset Input di Validation        : Les États Unis ont plusieurs fois justifiè des interventions dans d' autres pays au nom de la protection des sacro saints intèrêts amèricains ou des citoyens amèricains à travers le monde . Le jour où , en 2008 , la Gèorgie avait attaquè des civils et des militaires russes en Ossètie du Sud , les Russes sont ègalement intervenus pour la protection lègitime de ses citoyens et militaires qui n' ètaient pas seulement victimes d' une attaque , mais d' un massacre . Mais lorsque ce sont les autres pays qui dèfendent leurs intèrêts et leurs civils au delà de leurs frontières , ceci ne plaît èvidemment pas aux États Unis . \n","Frase più lunga nel Dataset Target di Validation       : Gli Stati Uniti hanno ripetutamente giustificato degli interventi in altri paesi in nome della tutela degli interessi sacrosanti americani o dei cittadini americani in tutto il mondo . Il giorno in cui , nel 2008 , la Georgia ha attaccato civili e soldati russi in Ossezia del Sud , i russi sono ugualmente intervenuti per la legittima tutela dei loro cittadini e soldati che non erano solo le vittime di un attacco , ma di un massacro . Ma quando gli altri paesi stanno difendendo i loro interessi e civili oltre i loro confini , questo ovviamente non piace agli Stati Uniti . \n","---------------------------------------------------------------------------------------\n","Esempi nel Dataset di Test                             : 232\n","Frase più corta nel Dataset Input di Test              :  J' aime voyager . Moi aussi . \n","Frase più corta nel Dataset Target di Test             : Oggi è venerdì . \n","Frase più lunga nel Dataset Input di Test              : L' un est rouge , l' autre est blanc . \n","Frase più lunga nel Dataset Target di Test             : Molte persone hanno partecipato alla riunione . \n","\n","--------------------------------- EXAMPLE ---------------------------------------------\n","[\" Veux tu l' acheter ? Oui . \"]\n","tf.Tensor(\n","[[  101 19561 11855 13055   180   112 33478 28647   136 47060 10116   119\n","    102     0     0     0     0     0     0     0     0     0     0     0\n","      0     0     0     0     0     0     0     0]], shape=(1, 32), dtype=int32)\n","------------------------------------------------------------------\n","['Oggi offro io . ']\n","<tf.RaggedTensor [[2, 260, 21120, 85, 11, 3]]>\n","\n","\n","[\"De même que , en temps de guerre , officiers et soldats se sentent autorisès par l' opinion gènèrale à commettre des actes qui , en temps de paix , sont tenus pour criminels , de même les rèvolutionnaires , dans leur lutte , se regardaient comme couverts par l' opinion de leur cercle , en vertu de laquelle les actes de cruautè qu' ils commettaient ètaient nobles et moraux , ètant commis par eux au prix de leur libertè , de leur vie , de tout ce qui est cher à la plupart des hommes . Ainsi s' expliquait , que des personnes excellentes , incapables non seulement de causer une souffrance , mais même d' en supporter la vue , pussent se prèparer tranquillement à la violence et au meurtre , et professer la saintetè de tels actes , considèrès comme moyens de dèfense , ou encore comme instrument utile à la rèalisation d' un idèal de bonheur pour l' humanitè . \"]\n","tf.Tensor(\n","[[   101  10190  11594  10121    117  10110  12358  10104  14158    117\n","   59973  10131  25734  10126  97705  10368  37882  10107  13230  10248\n","     180    112  32282    175  20276  37833  10284    254  10986  11527\n","   10246  10139  37481  10355    117  10110  12358  10104  41795    117\n","   10647  69323  10107  10322    171 102422  58798    117  10104  11594\n","   10152    186  13340  34381  30861  38260    117  10260  11807  43927\n","     117  10126  42047  32247  10986  11170  98095  10107  10248    180\n","     112  32282  10104  11807  57775    117  10110  20900  10138  10104\n","   20600  10152  37481  10104    171  60021  11159  13340  10608    112\n","   13178  10986  12201  15617    262  26812  11405  43657  10131  25528\n","   11855    117    262  19533  10212  15240  10248  22502  10257  18236\n","   10104  11807  72517  10123  13340    117  10104  11807  13772    117\n","   10104  13003  10794  10355  10176  10262  10129    102]], shape=(1, 128), dtype=int32)\n","------------------------------------------------------------------\n","[\"Così come in tempo di guerra , ufficiali e soldati si sentono responsabilizzati dall' opinione generale a commettere atti che , in tempo di pace , sono necessari per i criminali , anche rivoluzionari nella loro lotta , considerati coperti dal parere del loro circolo , secondo cui gli atti di crudeltà che hanno commesso erano nobili e morali , essendo commessi da loro nel prezzo della loro libertà , della loro vita , di tutto ciò che è caro alla maggior parte degli uomini . Ciò ha spiegato che persone eccellenti , in grado non solo di causare sofferenza , ma anche di sopportarne la vista , potrebbero felicemente prepararsi alla violenza e all' omicidio , e professare la santità di tali atti , considerati come un mezzo di difesa , o come utili per la realizzazione di un ideale di felicità per l' umanità . \"]\n","<tf.RaggedTensor [[2, 125, 99, 83, 172, 78, 575, 10, 11697, 5987, 31, 3991, 81, 5792, 6586,\n","  5661, 532, 8, 1488, 2750, 27, 6224, 1923, 76, 10, 83, 172, 78, 604, 10,\n","  91, 21111, 82, 35, 4450, 10, 281, 18720, 22435, 20890, 926, 206, 122,\n","  5619, 10, 11841, 6829, 158, 2737, 97, 122, 20964, 10, 409, 163, 128,\n","  1923, 78, 10810, 76, 134, 2985, 245, 10121, 31, 12939, 10, 3117, 11007,\n","  95, 122, 119, 1374, 141, 122, 1739, 10, 141, 122, 192, 10, 78, 130, 167,\n","  76, 31, 962, 153, 497, 189, 333, 708, 11, 167, 89, 4918, 76, 270, 20590,\n","  10, 83, 414, 79, 195, 78, 12719, 21200, 10, 104, 281, 78, 209, 20483,\n","  10185, 77, 329, 10, 10297, 417, 978, 11350, 153, 2474, 31, 229, 8, 2764,\n","  10, 31, 18116, 377, 77, 1241, 384, 78, 2481, 1923, 10, 11841, 99, 84,\n","  451, 78, 3976, 10, 41, 99, 6098, 82, 77, 13024, 78, 84, 7265, 78, 2322,\n","  82, 38, 8, 5381, 11, 3]]>\n"]}],"source":["train_dataset_ita, validation_dataset_ita, test_dataset = train_val_test_dataset(df=df,\n","                                                                                 filter_column='ITA',\n","                                                                                 debug=debug)"]},{"cell_type":"code","execution_count":31,"metadata":{"executionInfo":{"elapsed":1742,"status":"ok","timestamp":1683459306604,"user":{"displayName":"Daniele Badiali","userId":"07880650122235290376"},"user_tz":-120},"id":"VH_aKPlV_AWA","colab":{"base_uri":"https://localhost:8080/"},"outputId":"c8636010-4186-47d7-fb3e-699bb4cf1630"},"outputs":[{"output_type":"stream","name":"stdout","text":["----------------------- ENCODER  -------------------------------\n","Shape                    : {'input_mask': <tf.Tensor: shape=(32, 128), dtype=int32, numpy=\n","array([[1, 1, 1, ..., 0, 0, 0],\n","       [1, 1, 1, ..., 0, 0, 0],\n","       [1, 1, 1, ..., 0, 0, 0],\n","       ...,\n","       [1, 1, 1, ..., 0, 0, 0],\n","       [1, 1, 1, ..., 0, 0, 0],\n","       [1, 1, 1, ..., 0, 0, 0]], dtype=int32)>, 'input_word_ids': <tf.Tensor: shape=(32, 128), dtype=int32, numpy=\n","array([[   101,  12275,  10176, ...,      0,      0,      0],\n","       [   101,    147,    112, ...,      0,      0,      0],\n","       [   101,  10468,  38921, ...,      0,      0,      0],\n","       ...,\n","       [   101,    147,    112, ...,      0,      0,      0],\n","       [   101,  23387, 104253, ...,      0,      0,      0],\n","       [   101,  19994,  10141, ...,      0,      0,      0]], dtype=int32)>}\n","Shape                    : (32, 128)\n","Word Ids                 : [  101 12275 10176 22324 10119 14574 10563 52059 10121 11834   119   102\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0]\n","Input Mask               : [1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n","--------------------- DECODER ----------------------------------\n","Shape it input           : (32, 128)\n","Example it input         : [   2   86   31  721   84  236    8   94 2669   78  121   11    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0]\n","--------------------- TARGET -----------------------------------\n","Shape it input           : (32, 128)\n","Example it target        : [  86   31  721   84  236    8   94 2669   78  121   11    3    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0]\n"]}],"source":["# Recupero un batch di esempi per la verifica delle classi custom che andrò a creare\n","for (enc_input, dec_input), target in train_dataset_ita.take(1):\n","  print('----------------------- ENCODER  -------------------------------')\n","  print(f'Shape                    : {enc_input}')\n","  print(f'Shape                    : {enc_input[\"input_word_ids\"].shape}')\n","  print(f'Word Ids                 : {enc_input[\"input_word_ids\"][0, :MAX_SEQ_LENGTH]}')\n","  print(f'Input Mask               : {enc_input[\"input_mask\"][0, :MAX_SEQ_LENGTH]}')\n","  print('--------------------- DECODER ----------------------------------')\n","  print(f'Shape it input           : {dec_input.shape}')\n","  print(f'Example it input         : {dec_input[0]}')  \n","  print('--------------------- TARGET -----------------------------------')\n","  print(f'Shape it input           : {target.shape}')\n","  print(f'Example it target        : {target[0]}')  "]},{"cell_type":"markdown","metadata":{"id":"8dtVuZGJpvXl"},"source":["## Encoder BERT\n","\n","Predispondo la classe necessaria per la costruzione di BERT\n"]},{"cell_type":"code","execution_count":32,"metadata":{"id":"L0OniBSyW-rF","executionInfo":{"status":"ok","timestamp":1683459306604,"user_tz":-120,"elapsed":13,"user":{"displayName":"Daniele Badiali","userId":"07880650122235290376"}}},"outputs":[],"source":["class MLPMixerLayer(tf.keras.layers.Layer):\n","  def __init__(self, num_patches, dropout_rate, *args, **kwargs):\n","    super().__init__(*args, **kwargs)\n","\n","    self.mlp = tf.keras.Sequential(\n","        [\n","            tf.keras.layers.Dense(units=num_patches * 2, name='MLPMixerLayer_dense_1'),\n","            tf.keras.layers.Dense(units=num_patches, name='MLPMixerLayer_dense_2'),\n","            tf.keras.layers.Dropout(rate=dropout_rate, name='MLPMixerLayer_dropout'),\n","        ]\n","    )\n","    self.normalize = tf.keras.layers.LayerNormalization(epsilon=1e-6, name='MLPMixerLayer_layer_normalization')\n","\n","  def call(self, inputs):\n","    # Apply layer normalization.\n","    x = self.normalize(inputs)\n","    # Transpose inputs from [num_batches, num_patches, hidden_units] to [num_batches, hidden_units, num_patches].\n","    x_channels = tf.linalg.matrix_transpose(x)\n","    # Apply mlp on each channel independently.\n","    mlp_outputs = self.mlp(x_channels)\n","    # Transpose mlp_outputs from [num_batches, hidden_dim, num_patches] to [num_batches, num_patches, hidden_units].\n","    mlp_outputs = tf.linalg.matrix_transpose(mlp_outputs)\n","    return mlp_outputs"]},{"cell_type":"code","execution_count":33,"metadata":{"id":"m7v9Y-Lep4CD","executionInfo":{"status":"ok","timestamp":1683459306605,"user_tz":-120,"elapsed":12,"user":{"displayName":"Daniele Badiali","userId":"07880650122235290376"}}},"outputs":[],"source":["class EncoderBert(tf.keras.layers.Layer):\n","  def __init__(self, bert_encoder, embedding_dim, max_len, rate=0.5, name='EncoderBert', trainable=False):\n","    super(EncoderBert, self).__init__()\n","\n","    self.encoder = hub.KerasLayer(bert_encoder, name='BERT_encoder', trainable=trainable)\n","\n","    self.conv_1 = tf.keras.layers.Conv1D(embedding_dim * 4, 1, activation='relu', name='EncoderBert_conv_1') \n","    self.conv_2 = tf.keras.layers.Conv1D(embedding_dim * 2, 1, activation='relu', name='EncoderBert_conv_2') \n","    self.conv_3 = tf.keras.layers.Conv1D(embedding_dim, 1, activation='relu', name='EncoderBert_conv_3') \n","    # self.lambda_layer = tf.keras.layers.Lambda(lambda x: x[:,:max_len])\n","    self.mlp_mixer = MLPMixerLayer(num_patches=embedding_dim // 2, dropout_rate=rate, name='EncoderBert_MLPMixer')\n","    self.max_len = max_len\n","\n","  def call(self, x, debug=False):\n","\n","    if debug:\n","      print(f'****************** DEBUG ENCODER BERT ******************')\n","      print(f\"First example\")\n","      print(f'Keys                         : {list(x.keys())}')\n","      print(f'Shape                        : {x[\"input_word_ids\"].shape}')\n","      print(f'Word Ids                     : {x[\"input_word_ids\"][0, :16]}')\n","      print(f'Input Mask                   : {x[\"input_mask\"][0, :16]}')\n","      \n","    x = self.encoder(x)['sequence_output'] \n","    # encoder_outputs stato intermedio di BERT prima che esegua la traduzione recuperare la metà della lunghezza\n","    # x = self.encoder(x)['encoder_outputs'] \n","    # x = x[int(len(x) / 2) - 1]\n","\n","    if debug:\n","      print()\n","      print(f'Encoder Outputs BERT Shape   : {x.shape}')\n","      print(f'Encoder Outputs BERT Values  : {x[0, :1, :16]}')\n","\n","    x = self.conv_1(x)\n","    if debug:\n","      print()\n","      print(f'Sequence Conv1 Shape         : {x.shape}')\n","\n","    x = self.conv_2(x)\n","    if debug:\n","      print(f'Sequence Conv2 Shape         : {x.shape}')\n","\n","    x = self.conv_3(x)\n","    if debug:\n","      print(f'Sequence Conv3 Shape         : {x.shape}')\n","      \n","    x = self.mlp_mixer(x)\n","    if debug:\n","      print(f'Sequence MLP-Mixer Shape     : {x.shape}')\n","      print()\n","      print(f'Sequence Outputs Values      : {x[0, 0, :16]}')      \n","      print('*********************************************************') \n","\n","    return x"]},{"cell_type":"code","execution_count":34,"metadata":{"executionInfo":{"elapsed":14217,"status":"ok","timestamp":1683459320813,"user":{"displayName":"Daniele Badiali","userId":"07880650122235290376"},"user_tz":-120},"id":"Q08luTkusEfn","colab":{"base_uri":"https://localhost:8080/"},"outputId":"0a22aada-3b4d-4763-9818-ebd2363aa231"},"outputs":[{"output_type":"stream","name":"stdout","text":["****************** DEBUG ENCODER BERT ******************\n","First example\n","Keys                         : ['input_mask', 'input_word_ids']\n","Shape                        : (32, 128)\n","Word Ids                     : [  101 12275 10176 22324 10119 14574 10563 52059 10121 11834   119   102\n","     0     0     0     0]\n","Input Mask                   : [1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0]\n","\n","Encoder Outputs BERT Shape   : (32, 128, 768)\n","Encoder Outputs BERT Values  : [[ 0.03444304 -0.1869041  -0.10346976 -0.0668864  -0.1971668   0.16195884\n","  -0.1911944   0.3437928   0.0286778   0.33445466  0.3566227  -0.10913363\n","  -0.3666266   0.24493366 -0.4214461   0.08677098]]\n","\n","Sequence Conv1 Shape         : (32, 128, 512)\n","Sequence Conv2 Shape         : (32, 128, 256)\n","Sequence Conv3 Shape         : (32, 128, 128)\n","Sequence MLP-Mixer Shape     : (32, 64, 128)\n","\n","Sequence Outputs Values      : [ 2.7119164  -0.523017    1.7350165  -0.7603388   0.28469598 -0.6894938\n"," -0.751467   -0.71512604  0.4886384  -0.75160825  0.0450775  -0.60785246\n"," -0.7570131  -0.38234267 -0.8167121  -0.84520847]\n","*********************************************************\n"]}],"source":["encoder_bert = EncoderBert(bert_encoder=tfhub_handle_encoder, \n","                           embedding_dim=EMBEDDING_DIM, \n","                           max_len=MAX_SEQ_LENGTH,\n","                           rate=DROPUOT,\n","                           trainable=trainable)\n","\n","bert_outputs = encoder_bert(enc_input, debug) "]},{"cell_type":"markdown","metadata":{"id":"ReEQ5rX7aGtl"},"source":["## Decoder\n","\n","Predispondo la classe necessaria per la costruzione di un Layer di Decoder"]},{"cell_type":"markdown","metadata":{"id":"gAu1IXlRZzlq"},"source":["### TOKEN AND POSITION EMBEDDING\n","\n","Implementazione del blocco Embedding per l'utilizzo di vettori posizionali insieme ai vettori di token di parole tramite estensione della classe Layer di Keras. "]},{"cell_type":"code","execution_count":35,"metadata":{"id":"o9-RSKTqsmUC","executionInfo":{"status":"ok","timestamp":1683459320814,"user_tz":-120,"elapsed":22,"user":{"displayName":"Daniele Badiali","userId":"07880650122235290376"}}},"outputs":[],"source":["class TokenAndPositionEmbedding(tf.keras.layers.Layer):\n","  def __init__(self, maxlen, vocab_size, embed_dim):\n","    super(TokenAndPositionEmbedding, self).__init__()\n","    self.maxlen = maxlen\n","    self.token_emb = tf.keras.layers.Embedding(input_dim=vocab_size, output_dim=embed_dim, name='Token_Embedding')\n","    self.pos_emb = tf.keras.layers.Embedding(input_dim=maxlen, output_dim=embed_dim, name='Positional_Embedding')\n","\n","  def call(self, x, debug=False):\n","    x = tf.keras.preprocessing.sequence.pad_sequences(x, maxlen=self.maxlen, padding='post')\n","    maxlen = tf.shape(x)[-1]\n","\n","    if debug:\n","      print('********** DEBUG TOKEN AND POSITION EMBEDDING ***********')\n","      print(f'Sequence Max len                          : {maxlen}')\n","      print(f'Sequence Shape                            : {tf.shape(x)}')\n","\n","    positions = tf.range(start=0, limit=maxlen, delta=1)\n","    positions = self.pos_emb(positions)\n","    x = self.token_emb(x)\n","    output = x + positions\n","\n","    if debug:\n","      print(f'Shape TokenAndPositionEmbedding           : {output.shape}')\n","      print('*********************************************************')\n","\n","    return output"]},{"cell_type":"code","execution_count":36,"metadata":{"executionInfo":{"elapsed":18,"status":"ok","timestamp":1683459320814,"user":{"displayName":"Daniele Badiali","userId":"07880650122235290376"},"user_tz":-120},"id":"rr_EWQUX8EWP","colab":{"base_uri":"https://localhost:8080/"},"outputId":"729b2f68-a405-4b51-8337-622d2122d414"},"outputs":[{"output_type":"stream","name":"stdout","text":["********** DEBUG TOKEN AND POSITION EMBEDDING ***********\n","Sequence Max len                          : 128\n","Sequence Shape                            : [ 32 128]\n","Shape TokenAndPositionEmbedding           : (32, 128, 128)\n","*********************************************************\n"]}],"source":["token_position_it = TokenAndPositionEmbedding(MAX_SEQ_LENGTH, tokenizers.ita.get_vocab_size(), EMBEDDING_DIM)\n","\n","inputs_decoder = token_position_it(dec_input, debug)"]},{"cell_type":"markdown","metadata":{"id":"XdLv-6nidKGK"},"source":["### LAYER DECODER\n","\n","Implementazione di un blocco di DecoderTransformer tramite estensione della classe Layer di Keras"]},{"cell_type":"markdown","metadata":{"id":"_iq7Y-d4eRd8"},"source":["#### DecodeBert\n","\n","Implmentazione di un blocco di  decodifica custom per decodificare l'output dal layer EncoderBert prima di passarlo al Decoder del Transformer tramite estensione della classe Layer di Keras"]},{"cell_type":"code","execution_count":37,"metadata":{"id":"joTBTlWF8ETD","executionInfo":{"status":"ok","timestamp":1683459321147,"user_tz":-120,"elapsed":7,"user":{"displayName":"Daniele Badiali","userId":"07880650122235290376"}}},"outputs":[],"source":["class DecodeBert(tf.keras.layers.Layer):\n","  def __init__(self, max_len, embed_dim, num_heads, ff_dim, rate=0.5, name='DecodeBert', num_layers_name=1):\n","    super(DecodeBert, self).__init__()\n","    self.att = tf.keras.layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim, name='DecodeBert_MultiHeadAttention_Block_'+str(num_layers_name))\n","    self.ffn = tf.keras.Sequential(\n","      [tf.keras.layers.Dense(ff_dim, activation='relu', name='DecodeBert_FFN_Dense_1_Block_'+str(num_layers_name)), \n","       tf.keras.layers.Dense(embed_dim, name='DecodeBert_FFN_Dense_2_Block_'+str(num_layers_name))]\n","    )\n","    self.layernorm1 = tf.keras.layers.LayerNormalization(name='DecodeBert_LayerNormalization_1_Block_'+str(num_layers_name))\n","    self.layernorm2 = tf.keras.layers.LayerNormalization(name='DecodeBert_LayerNormalization_2_Block_'+str(num_layers_name))\n","    self.dropout1 = tf.keras.layers.Dropout(rate, name='DecodeBert_Dropout_1_Block_'+str(num_layers_name))\n","    self.dropout2 = tf.keras.layers.Dropout(rate, name='DecodeBert_Dropout_2_Block_'+str(num_layers_name))\n","    self._name = name\n","\n","  def call(self, bert_outputs, training=False, debug=False):\n","    attn_output = self.att(query=bert_outputs,\n","                           value=bert_outputs, \n","                           key=bert_outputs)\n","    \n","    attn_output = self.dropout1(attn_output)\n","    out1 = self.layernorm1(bert_outputs + attn_output)\n","\n","    ffn_output = self.ffn(out1)\n","    ffn_output = self.dropout2(ffn_output, training=training)\n","\n","    output = self.layernorm2(out1 + ffn_output)\n","\n","    if debug:\n","      print('********************* DEBUG DECODE-BERT *********************')\n","      print(f'Shape Input Layer Decode-Bert       : {bert_outputs.shape}')\n","      print(f'Shape Output Layer Decode-Bert      : {output.shape}')\n","      print('*********************************************************')\n","\n","    return output"]},{"cell_type":"code","execution_count":38,"metadata":{"executionInfo":{"elapsed":837,"status":"ok","timestamp":1683459321978,"user":{"displayName":"Daniele Badiali","userId":"07880650122235290376"},"user_tz":-120},"id":"JaIzBxFCfKe9","colab":{"base_uri":"https://localhost:8080/"},"outputId":"a81c9742-3db0-43da-8b98-afbb78edb0a5"},"outputs":[{"output_type":"stream","name":"stdout","text":["********************* DEBUG DECODE-BERT *********************\n","Shape Input Layer Decode-Bert       : (32, 64, 128)\n","Shape Output Layer Decode-Bert      : (32, 64, 128)\n","*********************************************************\n"]}],"source":["encoder = DecodeBert(MAX_SEQ_LENGTH, \n","                     EMBEDDING_DIM, \n","                     NUM_HEADS, \n","                     FF_DIM, \n","                     DROPUOT)\n","\n","dec_bert = encoder(bert_outputs=bert_outputs,\n","                   training=training, \n","                   debug=debug)"]},{"cell_type":"markdown","metadata":{"id":"dMTKLwd3dRw5"},"source":["#### Layer Decoder"]},{"cell_type":"code","execution_count":39,"metadata":{"id":"SO5rYsFpfFS_","executionInfo":{"status":"ok","timestamp":1683459321980,"user_tz":-120,"elapsed":11,"user":{"displayName":"Daniele Badiali","userId":"07880650122235290376"}}},"outputs":[],"source":["class Decoder(tf.keras.layers.Layer):\n","  def __init__(self, max_len, embed_dim, num_heads, ff_dim, rate=0.5, name='DECODER', num_layers_name=1):\n","    super(Decoder, self).__init__()\n","    # self.decode_bert = DecodeBert(max_len=max_len, embed_dim=embed_dim, num_heads=num_heads, ff_dim=ff_dim, rate=rate, name='DecodeBert_Block_'+str(num_layers_name), num_layers_name=num_layers_name)\n","    self.att1 = tf.keras.layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim, name='Decoder_MultiHeadAttention_input_decoder_Block_'+str(num_layers_name))\n","    self.att2 = tf.keras.layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim, name='Decoder_MultiHeadAttention_output_encoder_Block_'+str(num_layers_name))\n","    self.ffn = tf.keras.Sequential(\n","      [\n","       # tf.keras.layers.Dense(ff_dim, activation='relu', kernel_initializer=tf.keras.initializers.GlorotNormal(), bias_initializer=tf.keras.initializers.Constant(-0.01), name='Decoder_FFN_Dense_1_Block_'+str(num_layers_name)), \n","       tf.keras.layers.Dense(ff_dim, activation='relu', name='Decoder_FFN_Dense_1_Block_'+str(num_layers_name)), \n","       tf.keras.layers.Dense(embed_dim, kernel_initializer=tf.keras.initializers.RandomUniform(), name='Decoder_FFN_Dense_2_Block_'+str(num_layers_name)),]\n","    )\n","    self.layernorm1 = tf.keras.layers.LayerNormalization(name='Decoder_LayerNormalization_1_Block_'+str(num_layers_name))\n","    self.layernorm2 = tf.keras.layers.LayerNormalization(name='Decoder_LayerNormalization_2_Block_'+str(num_layers_name))\n","    self.layernorm3 = tf.keras.layers.LayerNormalization(name='Decoder_LayerNormalization_3_Block_'+str(num_layers_name))\n","    self.dropout1 = tf.keras.layers.Dropout(rate, name='Decoder_Dropout_1_Block_'+str(num_layers_name))\n","    self.dropout2 = tf.keras.layers.Dropout(rate, name='Decoder_Dropout_2_Block_'+str(num_layers_name))\n","    self.dropout3 = tf.keras.layers.Dropout(rate, name='Decoder_Dropout_3_Block_'+str(num_layers_name))\n","\n","    self._name = name\n","\n","  def call(self, inputs, bert_outputs, dec_bert, training=False, debug=False):\n","    attn_output1 = self.att1(query=inputs,\n","                             value=inputs, \n","                             key=inputs, \n","                             use_causal_mask=True)\n","    \n","    attn_output1 = self.dropout1(attn_output1)\n","    out1 = self.layernorm1(inputs + attn_output1)\n","\n","    # dec_bert = self.decode_bert(bert_outputs=bert_outputs, training=training, debug=debug)\n","\n","    attn_output2 = self.att2(key=dec_bert, \n","                             value=dec_bert, \n","                             query=out1)\n","    \n","    attn_output2 = self.dropout2(attn_output2, training=training)\n","    out2 = self.layernorm2(out1 + attn_output2)\n","\n","    ffn_output = self.ffn(out2)\n","    ffn_output = self.dropout3(ffn_output, training=training)\n","    \n","    output = self.layernorm3(out2 + ffn_output)\n","\n","    if debug:\n","      print('******************* DEBUG DECODER ***********************')\n","      print(f'Input Shape                       : {inputs.shape}')\n","      print(f'Shape Outputs Decoder             : {output.shape}')\n","      print('*********************************************************')\n","\n","    return output"]},{"cell_type":"code","execution_count":40,"metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1683459321981,"user":{"displayName":"Daniele Badiali","userId":"07880650122235290376"},"user_tz":-120},"id":"yysVdkHH8EPH","colab":{"base_uri":"https://localhost:8080/"},"outputId":"8dc50a6e-5bac-4b41-9899-ae38de038aa7"},"outputs":[{"output_type":"stream","name":"stdout","text":["******************* DEBUG DECODER ***********************\n","Input Shape                       : (32, 128, 128)\n","Shape Outputs Decoder             : (32, 128, 128)\n","*********************************************************\n"]}],"source":["decoder = Decoder(MAX_SEQ_LENGTH, \n","                  EMBEDDING_DIM, \n","                  NUM_HEADS, \n","                  FF_DIM, \n","                  DROPUOT)\n","\n","outputs_decoder = decoder(inputs=inputs_decoder, \n","                          bert_outputs=bert_outputs,\n","                          dec_bert=dec_bert,  \n","                          training=training,\n","                          debug=debug)"]},{"cell_type":"markdown","metadata":{"id":"ne4zTOG_NKfV"},"source":["## TRANSFORMER\n","\n","Implementazione del blocco Transformer tramite estensione della classe Layer di Keras."]},{"cell_type":"code","execution_count":41,"metadata":{"id":"lw2xMCAMC_4M","executionInfo":{"status":"ok","timestamp":1683459321981,"user_tz":-120,"elapsed":8,"user":{"displayName":"Daniele Badiali","userId":"07880650122235290376"}}},"outputs":[],"source":["class TransformerBlock(tf.keras.Model):\n","  def __init__(self, \n","               num_layers, \n","               embed_dim, \n","               num_heads, \n","               ff_dim, \n","               max_len,\n","               vocab_size,\n","               tfhub_handle_encoder,\n","               trainable,\n","               rate=0.5):\n","    \n","    super(TransformerBlock, self).__init__()\n","\n","    self.num_layers = num_layers\n","\n","    self.token_pos_dec = TokenAndPositionEmbedding(max_len, vocab_size, embed_dim)\n","\n","    self.encoder = EncoderBert(tfhub_handle_encoder, embed_dim, max_len, trainable=trainable)\n","    self.dec_bert = DecodeBert(max_len=max_len, embed_dim=embed_dim, num_heads=num_heads, ff_dim=ff_dim, rate=rate, name='DecodeBert_Block_1')\n","    self.decoder = [Decoder(max_len, embed_dim, num_heads, ff_dim, rate, num_layers_name=i+1) for i in range(num_layers)]\n","\n","    self.dropout = tf.keras.layers.Dropout(rate, name='Transformer_Dropout_Pre_Final_Layer')\n","    self.final_layer = tf.keras.layers.Dense(vocab_size, name='Transformer_Final_Layer')\n","\n","  def call(self, inputs, training=False, debug=False):\n","    inputs_encoder, inputs_decoder  = inputs\n","\n","    encoder_output = self.encoder(inputs_encoder, debug) \n","    decode_bert = self.dec_bert(encoder_output, debug)\n","\n","    inputs_decoder = self.token_pos_dec(inputs_decoder, debug)\n","\n","    if debug:\n","      print(f'---------------- DEBUG TRANSFORMER BLOCK ----------------')\n","      print(f'inputs_encoder       : {inputs_encoder[\"input_word_ids\"].shape}')\n","      print(f'inputs_decoder       : {inputs_decoder.shape}')      \n","\n","    transformer_output = inputs_decoder\n","\n","    for i in range(self.num_layers):\n","      transformer_output = self.decoder[i](inputs=transformer_output, \n","                                           bert_outputs=encoder_output, \n","                                           dec_bert=decode_bert,\n","                                           training=training,\n","                                           debug=debug)\n","    \n","    transformer_output = self.dropout(transformer_output)   \n","      \n","    transformer_output = self.final_layer(transformer_output)\n","\n","    if debug:\n","      print(f'Output Shape       : {transformer_output.shape}')\n","      print(f'Output Transformer : {transformer_output[0, :1, :12]}')    \n","      print(f'---------------------------------------------------------')\n","\n","    return transformer_output"]},{"cell_type":"code","execution_count":42,"metadata":{"executionInfo":{"elapsed":4689,"status":"ok","timestamp":1683459326663,"user":{"displayName":"Daniele Badiali","userId":"07880650122235290376"},"user_tz":-120},"id":"pr--G0ZZVAMi","colab":{"base_uri":"https://localhost:8080/"},"outputId":"18ac1f99-4400-413d-e776-a189fb703919"},"outputs":[{"output_type":"stream","name":"stdout","text":["****************** DEBUG ENCODER BERT ******************\n","First example\n","Keys                         : ['input_mask', 'input_word_ids']\n","Shape                        : (32, 128)\n","Word Ids                     : [  101 12275 10176 22324 10119 14574 10563 52059 10121 11834   119   102\n","     0     0     0     0]\n","Input Mask                   : [1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0]\n","\n","Encoder Outputs BERT Shape   : (32, 128, 768)\n","Encoder Outputs BERT Values  : [[ 0.03444304 -0.1869041  -0.10346976 -0.0668864  -0.1971668   0.16195884\n","  -0.1911944   0.3437928   0.0286778   0.33445466  0.3566227  -0.10913363\n","  -0.3666266   0.24493366 -0.4214461   0.08677098]]\n","\n","Sequence Conv1 Shape         : (32, 128, 512)\n","Sequence Conv2 Shape         : (32, 128, 256)\n","Sequence Conv3 Shape         : (32, 128, 128)\n","Sequence MLP-Mixer Shape     : (32, 64, 128)\n","\n","Sequence Outputs Values      : [ 0.         2.7851746  0.         2.7045043  2.7619123  2.8156168\n"," -8.019099   0.        -0.351658  -0.8850645  2.7774844  0.\n","  0.         0.         0.         0.       ]\n","*********************************************************\n","********** DEBUG TOKEN AND POSITION EMBEDDING ***********\n","Sequence Max len                          : 128\n","Sequence Shape                            : [ 32 128]\n","Shape TokenAndPositionEmbedding           : (32, 128, 128)\n","*********************************************************\n","---------------- DEBUG TRANSFORMER BLOCK ----------------\n","inputs_encoder       : (32, 128)\n","inputs_decoder       : (32, 128, 128)\n","******************* DEBUG DECODER ***********************\n","Input Shape                       : (32, 128, 128)\n","Shape Outputs Decoder             : (32, 128, 128)\n","*********************************************************\n","******************* DEBUG DECODER ***********************\n","Input Shape                       : (32, 128, 128)\n","Shape Outputs Decoder             : (32, 128, 128)\n","*********************************************************\n","Output Shape       : (32, 128, 23120)\n","Output Transformer : [[ 0.07777049 -0.16737185 -0.05014326  0.05373039 -0.17247613 -0.19802609\n","   0.27412194  0.00184963 -0.18382828  0.09016108 -0.29559866 -0.14027172]]\n","---------------------------------------------------------\n"]}],"source":["transformer = TransformerBlock(NUM_LAYERS, \n","                               EMBEDDING_DIM, \n","                               NUM_HEADS, \n","                               FF_DIM,\n","                               MAX_SEQ_LENGTH,\n","                               tokenizers.ita.get_vocab_size(),\n","                               tfhub_handle_encoder,\n","                               trainable,\n","                               DROPUOT)\n","\n","transformer_output = transformer((enc_input, dec_input), \n","                                 training=training,\n","                                 debug=debug)"]},{"cell_type":"code","execution_count":43,"metadata":{"executionInfo":{"elapsed":22,"status":"ok","timestamp":1683459326664,"user":{"displayName":"Daniele Badiali","userId":"07880650122235290376"},"user_tz":-120},"id":"0kYt6ehvh-8B","colab":{"base_uri":"https://localhost:8080/"},"outputId":"1f7baaa2-345b-4d59-9576-307469c0b554"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"transformer_block\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," token_and_position_embeddin  multiple                 2975744   \n"," g_1 (TokenAndPositionEmbedd                                     \n"," ing)                                                            \n","                                                                 \n"," encoder_bert_1 (EncoderBert  multiple                 135317056 \n"," )                                                               \n","                                                                 \n"," DecodeBert_Block_1 (DecodeB  multiple                 536352    \n"," ert)                                                            \n","                                                                 \n"," DECODER (Decoder)           multiple                  1064096   \n","                                                                 \n"," DECODER (Decoder)           multiple                  1064096   \n","                                                                 \n"," Transformer_Dropout_Pre_Fin  multiple                 0         \n"," al_Layer (Dropout)                                              \n","                                                                 \n"," Transformer_Final_Layer (De  multiple                 2982480   \n"," nse)                                                            \n","                                                                 \n","=================================================================\n","Total params: 143,939,824\n","Trainable params: 9,205,744\n","Non-trainable params: 134,734,080\n","_________________________________________________________________\n"]}],"source":["transformer.summary()"]},{"cell_type":"code","source":["tf.keras.utils.plot_model(transformer, show_shapes=True)"],"metadata":{"id":"qBBYdkvUqjTO","executionInfo":{"status":"ok","timestamp":1683459327017,"user_tz":-120,"elapsed":358,"user":{"displayName":"Daniele Badiali","userId":"07880650122235290376"}},"colab":{"base_uri":"https://localhost:8080/","height":77},"outputId":"fdd50c8f-98c5-4067-b63f-cd1879c079df"},"execution_count":44,"outputs":[{"output_type":"execute_result","data":{"image/png":"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\n","text/plain":["<IPython.core.display.Image object>"]},"metadata":{},"execution_count":44}]},{"cell_type":"markdown","metadata":{"id":"IFmcHTSDTvYk"},"source":["## Addestramento Modello"]},{"cell_type":"markdown","metadata":{"id":"tiuqPlHo0Z0n"},"source":["### Compilazione"]},{"cell_type":"code","execution_count":45,"metadata":{"id":"bOyqCyjIr-L2","executionInfo":{"status":"ok","timestamp":1683459327019,"user_tz":-120,"elapsed":14,"user":{"displayName":"Daniele Badiali","userId":"07880650122235290376"}}},"outputs":[],"source":["transformer.compile(\n","  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n","  optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE_ADAM, \n","                                     beta_1=BETA_1, \n","                                     beta_2=BETA_2),\n","  metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])"]},{"cell_type":"markdown","metadata":{"id":"-z6qj1uclHRa"},"source":["### Callbacks"]},{"cell_type":"code","execution_count":46,"metadata":{"id":"3hurmpSjJ_dT","executionInfo":{"status":"ok","timestamp":1683459327020,"user_tz":-120,"elapsed":13,"user":{"displayName":"Daniele Badiali","userId":"07880650122235290376"}}},"outputs":[],"source":["# Create a callback that saves the model's weights\n","cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n","                                                 save_weights_only=True,\n","                                                 save_best_only=True)\n","\n","# Create a callback Tensorboard\n","# log_dir =  os.path.abspath(os.path.join(PATH_LOG, '1_LAYER')) \n","log_dir =  os.path.abspath(os.path.join(PATH_LOG, 'T_1_Enc_2_Dec_lr_1e4_init_bias__')) \n","tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1, write_graph=True)\n","\n","# Create a callback save the log history\n","json_logging_callback = tf.keras.callbacks.LambdaCallback(\n","  on_epoch_end=lambda epoch, logs: json_log.write(\n","    json.dumps({'epoch': epoch, \n","                'loss': logs['loss'],\n","                'sparse_categorical_accuracy': logs['sparse_categorical_accuracy'],\n","                'val_loss': logs['val_loss'],\n","                'val_sparse_categorical_accuracy': logs['val_sparse_categorical_accuracy']}) + '\\n'),\n","  on_train_end=lambda logs: json_log.close()\n",")"]},{"cell_type":"markdown","metadata":{"id":"Day7C7Qh0b4G"},"source":["### Train Ita"]},{"cell_type":"code","source":["transformer.compile(\n","  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n","  optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3, \n","                                     beta_1=BETA_1, \n","                                     beta_2=BETA_2),\n","  metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])"],"metadata":{"id":"I_fbsEx6LkAg","executionInfo":{"status":"ok","timestamp":1683459327021,"user_tz":-120,"elapsed":13,"user":{"displayName":"Daniele Badiali","userId":"07880650122235290376"}}},"execution_count":47,"outputs":[]},{"cell_type":"code","source":["start = datetime.datetime.now()\n","json_log = open(log_history, mode='a', buffering=1, encoding='utf-8')\n","\n","transformer.fit(train_dataset_ita,\n","                initial_epoch=0,\n","                epochs=10,\n","                shuffle=True,\n","                validation_data=validation_dataset_ita,\n","                callbacks=[#tensorboard_callback,\n","                           json_logging_callback, \n","                           # cp_callback\n","                           ])\n","\n","end = datetime.datetime.now()\n","print(f'Tempo necessario per l\\'addestramento: {end - start}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hLilDwbxL382","outputId":"fce77e0f-7473-4c01-f320-4ef09a060be6","executionInfo":{"status":"ok","timestamp":1683464872866,"user_tz":-120,"elapsed":630095,"user":{"displayName":"Daniele Badiali","userId":"07880650122235290376"}}},"execution_count":48,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","542/542 [==============================] - 546s 996ms/step - loss: 0.8204 - sparse_categorical_accuracy: 0.9316 - val_loss: 0.3885 - val_sparse_categorical_accuracy: 0.9416\n","Epoch 2/10\n","542/542 [==============================] - 505s 931ms/step - loss: 0.3697 - sparse_categorical_accuracy: 0.9433 - val_loss: 0.3338 - val_sparse_categorical_accuracy: 0.9473\n","Epoch 3/10\n","542/542 [==============================] - 503s 929ms/step - loss: 0.3226 - sparse_categorical_accuracy: 0.9477 - val_loss: 0.3054 - val_sparse_categorical_accuracy: 0.9509\n","Epoch 4/10\n","542/542 [==============================] - 529s 976ms/step - loss: 0.2912 - sparse_categorical_accuracy: 0.9510 - val_loss: 0.2858 - val_sparse_categorical_accuracy: 0.9536\n","Epoch 5/10\n","542/542 [==============================] - 506s 933ms/step - loss: 0.2658 - sparse_categorical_accuracy: 0.9539 - val_loss: 0.2710 - val_sparse_categorical_accuracy: 0.9562\n","Epoch 6/10\n","542/542 [==============================] - 530s 979ms/step - loss: 0.2446 - sparse_categorical_accuracy: 0.9564 - val_loss: 0.2575 - val_sparse_categorical_accuracy: 0.9585\n","Epoch 7/10\n","542/542 [==============================] - 533s 983ms/step - loss: 0.2262 - sparse_categorical_accuracy: 0.9586 - val_loss: 0.2493 - val_sparse_categorical_accuracy: 0.9604\n","Epoch 8/10\n","542/542 [==============================] - 530s 978ms/step - loss: 0.2104 - sparse_categorical_accuracy: 0.9607 - val_loss: 0.2459 - val_sparse_categorical_accuracy: 0.9619\n","Epoch 9/10\n","542/542 [==============================] - 529s 975ms/step - loss: 0.1972 - sparse_categorical_accuracy: 0.9625 - val_loss: 0.2362 - val_sparse_categorical_accuracy: 0.9634\n","Epoch 10/10\n","542/542 [==============================] - 527s 973ms/step - loss: 0.1858 - sparse_categorical_accuracy: 0.9640 - val_loss: 0.2325 - val_sparse_categorical_accuracy: 0.9646\n","Tempo necessario per l'addestramento: 1:32:25.776867\n"]}]},{"cell_type":"code","source":["# Carico i pesi modello\n","latest = tf.train.latest_checkpoint(PATH_WEIGHTS)\n","transformer.load_weights(latest)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vyusWc3PL546","executionInfo":{"status":"ok","timestamp":1682875037198,"user_tz":-120,"elapsed":1678,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}},"outputId":"7538decf-2443-446a-f68d-a9c66ff65174"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x7fe96c540940>"]},"metadata":{},"execution_count":49}]},{"cell_type":"code","source":["transformer.compile(\n","  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n","  optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4, \n","                                     beta_1=BETA_1, \n","                                     beta_2=BETA_2),\n","  metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])"],"metadata":{"id":"SZLdhmMpL51U"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["start = datetime.datetime.now()\n","json_log = open(log_history, mode='a', buffering=1, encoding='utf-8')\n","\n","transformer.fit(train_dataset_ita,\n","                initial_epoch=3,\n","                epochs=10,\n","                shuffle=True,\n","                validation_data=validation_dataset_ita,\n","                callbacks=[tensorboard_callback,\n","                           json_logging_callback, \n","                           cp_callback])\n","\n","end = datetime.datetime.now()\n","print(f'Tempo necessario per l\\'addestramento: {end - start}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sfHesJuQL5x_","executionInfo":{"status":"ok","timestamp":1682877126415,"user_tz":-120,"elapsed":2089225,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}},"outputId":"ceb9d096-abbd-4bbb-b86f-414a077d34a6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 4/10\n","542/542 [==============================] - 297s 547ms/step - loss: 0.2927 - sparse_categorical_accuracy: 0.9504 - val_loss: 0.3060 - val_sparse_categorical_accuracy: 0.9505\n","Epoch 5/10\n","542/542 [==============================] - 297s 547ms/step - loss: 0.2832 - sparse_categorical_accuracy: 0.9515 - val_loss: 0.3020 - val_sparse_categorical_accuracy: 0.9513\n","Epoch 6/10\n","542/542 [==============================] - 298s 551ms/step - loss: 0.2760 - sparse_categorical_accuracy: 0.9524 - val_loss: 0.2989 - val_sparse_categorical_accuracy: 0.9519\n","Epoch 7/10\n","542/542 [==============================] - 298s 550ms/step - loss: 0.2692 - sparse_categorical_accuracy: 0.9531 - val_loss: 0.2954 - val_sparse_categorical_accuracy: 0.9525\n","Epoch 8/10\n","542/542 [==============================] - 297s 549ms/step - loss: 0.2628 - sparse_categorical_accuracy: 0.9538 - val_loss: 0.2940 - val_sparse_categorical_accuracy: 0.9527\n","Epoch 9/10\n","542/542 [==============================] - 297s 547ms/step - loss: 0.2571 - sparse_categorical_accuracy: 0.9545 - val_loss: 0.2902 - val_sparse_categorical_accuracy: 0.9534\n","Epoch 10/10\n","542/542 [==============================] - 297s 548ms/step - loss: 0.2516 - sparse_categorical_accuracy: 0.9552 - val_loss: 0.2879 - val_sparse_categorical_accuracy: 0.9540\n","Tempo necessario per l'addestramento: 0:34:49.732610\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"QF0_s2p7MAjm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"SQ_oogFNL_9_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"tVnFxskJL5n7"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2093406,"status":"ok","timestamp":1682315593434,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"},"user_tz":-120},"id":"etOGtBcer9yi","outputId":"b2e26755-3dd0-4227-a568-6db1253d121f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/5\n","542/542 [==============================] - 422s 770ms/step - loss: 3.5840 - sparse_categorical_accuracy: 0.9059 - val_loss: 0.6999 - val_sparse_categorical_accuracy: 0.9160\n","Epoch 2/5\n","542/542 [==============================] - 415s 766ms/step - loss: 0.6231 - sparse_categorical_accuracy: 0.9247 - val_loss: 0.5238 - val_sparse_categorical_accuracy: 0.9331\n","Epoch 3/5\n","542/542 [==============================] - 417s 770ms/step - loss: 0.5168 - sparse_categorical_accuracy: 0.9324 - val_loss: 0.4763 - val_sparse_categorical_accuracy: 0.9350\n","Epoch 4/5\n","542/542 [==============================] - 414s 765ms/step - loss: 0.4731 - sparse_categorical_accuracy: 0.9348 - val_loss: 0.4472 - val_sparse_categorical_accuracy: 0.9371\n","Epoch 5/5\n","542/542 [==============================] - 416s 767ms/step - loss: 0.4436 - sparse_categorical_accuracy: 0.9370 - val_loss: 0.4277 - val_sparse_categorical_accuracy: 0.9390\n","Tempo necessario per l'addestramento: 0:34:52.932722\n"]}],"source":["start = datetime.datetime.now()\n","json_log = open(log_history, mode='a', buffering=1, encoding='utf-8')\n","\n","transformer.fit(train_dataset_ita,\n","                initial_epoch=1,\n","                epochs=3,\n","                shuffle=True,\n","                validation_data=validation_dataset_ita,\n","                callbacks=[# tensorboard_callback,\n","                           json_logging_callback, \n","                           cp_callback])\n","\n","end = datetime.datetime.now()\n","print(f'Tempo necessario per l\\'addestramento: {end - start}')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zpO5e1p7xmFU"},"outputs":[],"source":["transformer = TransformerBlock(NUM_LAYERS*3, \n","                               EMBEDDING_DIM, \n","                               NUM_HEADS, \n","                               FF_DIM,\n","                               MAX_SEQ_LENGTH,\n","                               tokenizers.ita.get_vocab_size(),\n","                               tfhub_handle_encoder,\n","                               trainable,\n","                               DROPUOT)\n","\n","transformer.compile(\n","  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n","  optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE_ADAM, \n","                                     beta_1=BETA_1, \n","                                     beta_2=BETA_2),\n","  metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])\n","\n","# Create a callback that saves the model's weights\n","cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n","                                                 save_weights_only=True,\n","                                                 save_best_only=True)\n","\n","# Create a callback Tensorboard\n","# log_dir =  os.path.abspath(os.path.join(PATH_LOG, '3_LAYER')) \n","log_dir =  os.path.abspath(os.path.join(PATH_LOG, datetime.datetime.now().strftime('%Y%m%d-%H%M%S'))) \n","tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1, write_graph=True)\n","hparams_callback = hp.KerasCallback(log_dir, {\n","    'num_relu_units': 512,\n","    'dropout': 0.2\n","})\n","\n","# Create a callback save the log history\n","json_logging_callback = tf.keras.callbacks.LambdaCallback(\n","  on_epoch_end=lambda epoch, logs: json_log.write(\n","    json.dumps({'epoch': epoch, \n","                'loss': logs['loss'],\n","                'sparse_categorical_accuracy': logs['sparse_categorical_accuracy'],\n","                'val_loss': logs['val_loss'],\n","                'val_sparse_categorical_accuracy': logs['val_sparse_categorical_accuracy']}) + '\\n'),\n","  on_train_end=lambda logs: json_log.close()\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2142949,"status":"ok","timestamp":1681650308784,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"},"user_tz":-120},"id":"uEN0baYZyBxH","outputId":"4047e967-8802-4155-bd2b-859e2d1023cc"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/5\n","542/542 [==============================] - 429s 781ms/step - loss: 3.5119 - sparse_categorical_accuracy: 0.9049 - val_loss: 0.6980 - val_sparse_categorical_accuracy: 0.9160\n","Epoch 2/5\n","542/542 [==============================] - 426s 787ms/step - loss: 0.6236 - sparse_categorical_accuracy: 0.9249 - val_loss: 0.5246 - val_sparse_categorical_accuracy: 0.9330\n","Epoch 3/5\n","542/542 [==============================] - 426s 785ms/step - loss: 0.5180 - sparse_categorical_accuracy: 0.9325 - val_loss: 0.4784 - val_sparse_categorical_accuracy: 0.9348\n","Epoch 4/5\n","542/542 [==============================] - 429s 792ms/step - loss: 0.4759 - sparse_categorical_accuracy: 0.9346 - val_loss: 0.4504 - val_sparse_categorical_accuracy: 0.9370\n","Epoch 5/5\n","542/542 [==============================] - 425s 785ms/step - loss: 0.4470 - sparse_categorical_accuracy: 0.9367 - val_loss: 0.4280 - val_sparse_categorical_accuracy: 0.9385\n","Tempo necessario per l'addestramento: 0:35:43.026300\n"]}],"source":["start = datetime.datetime.now()\n","json_log = open(log_history, mode='a', buffering=1, encoding='utf-8')\n","\n","transformer.fit(train_dataset_ita,\n","                initial_epoch=0,\n","                epochs=EPOCHS_ADAM,\n","                shuffle=True,\n","                validation_data=validation_dataset_ita,\n","                callbacks=[tensorboard_callback,\n","                           hparams_callback,\n","                           json_logging_callback, \n","                           cp_callback])\n","\n","end = datetime.datetime.now()\n","print(f'Tempo necessario per l\\'addestramento: {end - start}')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dp36goSBucHV"},"outputs":[],"source":["transformer = TransformerBlock(NUM_LAYERS*6, \n","                               EMBEDDING_DIM, \n","                               NUM_HEADS, \n","                               FF_DIM,\n","                               MAX_SEQ_LENGTH,\n","                               tokenizers.ita.get_vocab_size(),\n","                               tfhub_handle_encoder,\n","                               trainable,\n","                               DROPUOT)\n","\n","transformer.compile(\n","  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n","  optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE_ADAM, \n","                                     beta_1=BETA_1, \n","                                     beta_2=BETA_2),\n","  metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])\n","\n","# Create a callback that saves the model's weights\n","cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n","                                                 save_weights_only=True,\n","                                                 save_best_only=True)\n","\n","# Create a callback Tensorboard\n","log_dir =  os.path.abspath(os.path.join(PATH_LOG, '6_LAYER')) \n","tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n","\n","# Create a callback save the log history\n","json_logging_callback = tf.keras.callbacks.LambdaCallback(\n","  on_epoch_end=lambda epoch, logs: json_log.write(\n","    json.dumps({'epoch': epoch, \n","                'loss': logs['loss'],\n","                'sparse_categorical_accuracy': logs['sparse_categorical_accuracy'],\n","                'val_loss': logs['val_loss'],\n","                'val_sparse_categorical_accuracy': logs['val_sparse_categorical_accuracy']}) + '\\n'),\n","  on_train_end=lambda logs: json_log.close()\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3637350,"status":"ok","timestamp":1681576984674,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"},"user_tz":-120},"id":"a0V5iy_TvBfw","outputId":"72114d05-2c67-4665-aa3f-803d7567e609"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/5\n","542/542 [==============================] - 730s 1s/step - loss: 3.5403 - sparse_categorical_accuracy: 0.9059 - val_loss: 0.7135 - val_sparse_categorical_accuracy: 0.9160\n","Epoch 2/5\n","542/542 [==============================] - 725s 1s/step - loss: 0.6356 - sparse_categorical_accuracy: 0.9234 - val_loss: 0.5293 - val_sparse_categorical_accuracy: 0.9311\n","Epoch 3/5\n","542/542 [==============================] - 726s 1s/step - loss: 0.5269 - sparse_categorical_accuracy: 0.9314 - val_loss: 0.4867 - val_sparse_categorical_accuracy: 0.9340\n","Epoch 4/5\n","542/542 [==============================] - 726s 1s/step - loss: 0.4849 - sparse_categorical_accuracy: 0.9337 - val_loss: 0.4597 - val_sparse_categorical_accuracy: 0.9352\n","Epoch 5/5\n","542/542 [==============================] - 725s 1s/step - loss: 0.4588 - sparse_categorical_accuracy: 0.9354 - val_loss: 0.4420 - val_sparse_categorical_accuracy: 0.9375\n","Tempo necessario per l'addestramento: 1:00:37.523950\n"]}],"source":["start = datetime.datetime.now()\n","json_log = open(log_history, mode='a', buffering=1, encoding='utf-8')\n","\n","transformer.fit(train_dataset_ita,\n","                initial_epoch=0,\n","                epochs=EPOCHS_ADAM,\n","                shuffle=True,\n","                validation_data=validation_dataset_ita,\n","                callbacks=[tensorboard_callback,\n","                           json_logging_callback, \n","                           cp_callback])\n","\n","end = datetime.datetime.now()\n","print(f'Tempo necessario per l\\'addestramento: {end - start}')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OxEh6LPovcjd"},"outputs":[],"source":["transformer = TransformerBlock(NUM_LAYERS*12, \n","                               EMBEDDING_DIM, \n","                               NUM_HEADS, \n","                               FF_DIM,\n","                               MAX_SEQ_LENGTH,\n","                               tokenizers.ita.get_vocab_size(),\n","                               tfhub_handle_encoder,\n","                               trainable,\n","                               DROPUOT)\n","\n","transformer.compile(\n","  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n","  optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE_ADAM, \n","                                     beta_1=BETA_1, \n","                                     beta_2=BETA_2),\n","  metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])\n","\n","# Create a callback that saves the model's weights\n","cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n","                                                 save_weights_only=True,\n","                                                 save_best_only=True)\n","\n","# Create a callback Tensorboard\n","log_dir =  os.path.abspath(os.path.join(PATH_LOG, '12_LAYER')) \n","tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n","\n","# Create a callback save the log history\n","json_logging_callback = tf.keras.callbacks.LambdaCallback(\n","  on_epoch_end=lambda epoch, logs: json_log.write(\n","    json.dumps({'epoch': epoch, \n","                'loss': logs['loss'],\n","                'sparse_categorical_accuracy': logs['sparse_categorical_accuracy'],\n","                'val_loss': logs['val_loss'],\n","                'val_sparse_categorical_accuracy': logs['val_sparse_categorical_accuracy']}) + '\\n'),\n","  on_train_end=lambda logs: json_log.close()\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"F7dYaByAvcSk"},"outputs":[],"source":["start = datetime.datetime.now()\n","json_log = open(log_history, mode='a', buffering=1, encoding='utf-8')\n","\n","transformer.fit(train_dataset_ita,\n","                initial_epoch=0,\n","                epochs=EPOCHS_ADAM,\n","                shuffle=True,\n","                validation_data=validation_dataset_ita,\n","                callbacks=[tensorboard_callback,\n","                           json_logging_callback, \n","                           cp_callback])\n","\n","end = datetime.datetime.now()\n","print(f'Tempo necessario per l\\'addestramento: {end - start}')"]},{"cell_type":"markdown","metadata":{"id":"GhBGzbvrh2Rw"},"source":["### Train Dante"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kndzuk5XVnmM"},"outputs":[],"source":["train_dataset_dante, validation_dataset_dante, test_dataset = train_val_test_dataset(df=df, filter_column='DANTE', debug=debug)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4ejTGcN8h4we"},"outputs":[],"source":["# Carico i pesi modello\n","latest = tf.train.latest_checkpoint(PATH_WEIGHTS)\n","transformer.load_weights(latest)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UZ0iTUOXh70W"},"outputs":[],"source":["start = datetime.datetime.now()\n","\n","json_log = open(log_history, mode='a', buffering=1, encoding='utf-8')\n","\n","transformer.fit(train_dataset_dante,\n","                initial_epoch=EPOCHS_ADAM+EPOCHS_ADAM,\n","                epochs=EPOCHS_ADAM+EPOCHS_ADAM+EPOCHS_ADAM,\n","                shuffle=True,\n","                validation_data=validation_dataset_dante,\n","                callbacks=[tensorboard_callback,\n","                           json_logging_callback, \n","                           cp_callback])\n","\n","end = datetime.datetime.now()\n","print(f'Tempo necessario per l\\'addestramento: {end - start}')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9239599,"status":"ok","timestamp":1679961715381,"user":{"displayName":"Daniele Badiali","userId":"15682358814001311695"},"user_tz":-120},"id":"3yZ-Zq0xJIZX","outputId":"3c642054-9a67-452e-946c-9e43f8ebf9b6"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 61/80\n","542/542 [==============================] - 459s 838ms/step - loss: 0.1464 - sparse_categorical_accuracy: 0.9687 - val_loss: 0.1401 - val_sparse_categorical_accuracy: 0.9709\n","Epoch 62/80\n","542/542 [==============================] - 454s 838ms/step - loss: 0.1416 - sparse_categorical_accuracy: 0.9695 - val_loss: 0.1367 - val_sparse_categorical_accuracy: 0.9715\n","Epoch 63/80\n","542/542 [==============================] - 456s 842ms/step - loss: 0.1380 - sparse_categorical_accuracy: 0.9701 - val_loss: 0.1337 - val_sparse_categorical_accuracy: 0.9720\n","Epoch 64/80\n","542/542 [==============================] - 423s 781ms/step - loss: 0.1343 - sparse_categorical_accuracy: 0.9707 - val_loss: 0.1300 - val_sparse_categorical_accuracy: 0.9725\n","Epoch 65/80\n","542/542 [==============================] - 453s 836ms/step - loss: 0.1306 - sparse_categorical_accuracy: 0.9713 - val_loss: 0.1291 - val_sparse_categorical_accuracy: 0.9728\n","Epoch 66/80\n","542/542 [==============================] - 424s 783ms/step - loss: 0.1275 - sparse_categorical_accuracy: 0.9718 - val_loss: 0.1264 - val_sparse_categorical_accuracy: 0.9733\n","Epoch 67/80\n","542/542 [==============================] - 451s 832ms/step - loss: 0.1238 - sparse_categorical_accuracy: 0.9723 - val_loss: 0.1237 - val_sparse_categorical_accuracy: 0.9738\n","Epoch 68/80\n","542/542 [==============================] - 451s 832ms/step - loss: 0.1213 - sparse_categorical_accuracy: 0.9728 - val_loss: 0.1224 - val_sparse_categorical_accuracy: 0.9742\n","Epoch 69/80\n","542/542 [==============================] - 422s 779ms/step - loss: 0.1181 - sparse_categorical_accuracy: 0.9733 - val_loss: 0.1221 - val_sparse_categorical_accuracy: 0.9746\n","Epoch 70/80\n","542/542 [==============================] - 451s 833ms/step - loss: 0.1157 - sparse_categorical_accuracy: 0.9738 - val_loss: 0.1190 - val_sparse_categorical_accuracy: 0.9750\n","Epoch 71/80\n","542/542 [==============================] - 419s 772ms/step - loss: 0.1127 - sparse_categorical_accuracy: 0.9741 - val_loss: 0.1169 - val_sparse_categorical_accuracy: 0.9755\n","Epoch 72/80\n","542/542 [==============================] - 451s 832ms/step - loss: 0.1102 - sparse_categorical_accuracy: 0.9746 - val_loss: 0.1157 - val_sparse_categorical_accuracy: 0.9756\n","Epoch 73/80\n","542/542 [==============================] - 452s 833ms/step - loss: 0.1076 - sparse_categorical_accuracy: 0.9751 - val_loss: 0.1148 - val_sparse_categorical_accuracy: 0.9759\n","Epoch 74/80\n","542/542 [==============================] - 423s 780ms/step - loss: 0.1055 - sparse_categorical_accuracy: 0.9756 - val_loss: 0.1130 - val_sparse_categorical_accuracy: 0.9763\n","Epoch 75/80\n","542/542 [==============================] - 455s 839ms/step - loss: 0.1031 - sparse_categorical_accuracy: 0.9760 - val_loss: 0.1123 - val_sparse_categorical_accuracy: 0.9766\n","Epoch 76/80\n","542/542 [==============================] - 426s 785ms/step - loss: 0.1012 - sparse_categorical_accuracy: 0.9762 - val_loss: 0.1112 - val_sparse_categorical_accuracy: 0.9768\n","Epoch 77/80\n","542/542 [==============================] - 456s 842ms/step - loss: 0.0992 - sparse_categorical_accuracy: 0.9766 - val_loss: 0.1090 - val_sparse_categorical_accuracy: 0.9772\n","Epoch 78/80\n","542/542 [==============================] - 454s 838ms/step - loss: 0.0967 - sparse_categorical_accuracy: 0.9771 - val_loss: 0.1082 - val_sparse_categorical_accuracy: 0.9775\n","Epoch 79/80\n","542/542 [==============================] - 454s 839ms/step - loss: 0.0948 - sparse_categorical_accuracy: 0.9774 - val_loss: 0.1093 - val_sparse_categorical_accuracy: 0.9775\n","Epoch 80/80\n","542/542 [==============================] - 427s 788ms/step - loss: 0.0930 - sparse_categorical_accuracy: 0.9777 - val_loss: 0.1080 - val_sparse_categorical_accuracy: 0.9776\n","Tempo necessario per l'addestramento: 2:33:59.968229\n"]}],"source":["start = datetime.datetime.now()\n","\n","json_log = open(log_history, mode='a', buffering=1, encoding='utf-8')\n","\n","transformer.fit(train_dataset_dante,\n","                initial_epoch=EPOCHS_ADAM+EPOCHS_ADAM+EPOCHS_ADAM,\n","                epochs=EPOCHS_ADAM+EPOCHS_ADAM+EPOCHS_ADAM+EPOCHS_ADAM,\n","                shuffle=True,\n","                validation_data=validation_dataset_dante,\n","                callbacks=[tensorboard_callback,\n","                           json_logging_callback, \n","                           cp_callback])\n","\n","end = datetime.datetime.now()\n","print(f'Tempo necessario per l\\'addestramento: {end - start}')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9079306,"status":"ok","timestamp":1679988668497,"user":{"displayName":"Daniele Badiali","userId":"07880650122235290376"},"user_tz":-120},"id":"7yibFj-xkgRP","outputId":"d19121ca-fe7e-4772-e61b-4e7011b5e11e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 81/100\n","542/542 [==============================] - 455s 821ms/step - loss: 0.0919 - sparse_categorical_accuracy: 0.9779 - val_loss: 0.1066 - val_sparse_categorical_accuracy: 0.9780\n","Epoch 82/100\n","542/542 [==============================] - 441s 814ms/step - loss: 0.0898 - sparse_categorical_accuracy: 0.9783 - val_loss: 0.1068 - val_sparse_categorical_accuracy: 0.9780\n","Epoch 83/100\n","542/542 [==============================] - 442s 815ms/step - loss: 0.0884 - sparse_categorical_accuracy: 0.9787 - val_loss: 0.1052 - val_sparse_categorical_accuracy: 0.9784\n","Epoch 84/100\n","542/542 [==============================] - 438s 808ms/step - loss: 0.0863 - sparse_categorical_accuracy: 0.9790 - val_loss: 0.1053 - val_sparse_categorical_accuracy: 0.9787\n","Epoch 85/100\n","542/542 [==============================] - 443s 818ms/step - loss: 0.0849 - sparse_categorical_accuracy: 0.9792 - val_loss: 0.1050 - val_sparse_categorical_accuracy: 0.9786\n","Epoch 86/100\n","542/542 [==============================] - 408s 754ms/step - loss: 0.0837 - sparse_categorical_accuracy: 0.9795 - val_loss: 0.1059 - val_sparse_categorical_accuracy: 0.9788\n","Epoch 87/100\n","542/542 [==============================] - 443s 818ms/step - loss: 0.0821 - sparse_categorical_accuracy: 0.9798 - val_loss: 0.1023 - val_sparse_categorical_accuracy: 0.9791\n","Epoch 88/100\n","542/542 [==============================] - 441s 814ms/step - loss: 0.0806 - sparse_categorical_accuracy: 0.9801 - val_loss: 0.1031 - val_sparse_categorical_accuracy: 0.9793\n","Epoch 89/100\n","542/542 [==============================] - 442s 815ms/step - loss: 0.0792 - sparse_categorical_accuracy: 0.9803 - val_loss: 0.1020 - val_sparse_categorical_accuracy: 0.9793\n","Epoch 90/100\n","542/542 [==============================] - 410s 757ms/step - loss: 0.0780 - sparse_categorical_accuracy: 0.9807 - val_loss: 0.1020 - val_sparse_categorical_accuracy: 0.9797\n","Epoch 91/100\n","542/542 [==============================] - 439s 810ms/step - loss: 0.0766 - sparse_categorical_accuracy: 0.9809 - val_loss: 0.1027 - val_sparse_categorical_accuracy: 0.9797\n","Epoch 92/100\n","542/542 [==============================] - 443s 817ms/step - loss: 0.0757 - sparse_categorical_accuracy: 0.9811 - val_loss: 0.1017 - val_sparse_categorical_accuracy: 0.9798\n","Epoch 93/100\n","542/542 [==============================] - 443s 817ms/step - loss: 0.0740 - sparse_categorical_accuracy: 0.9814 - val_loss: 0.1026 - val_sparse_categorical_accuracy: 0.9800\n","Epoch 94/100\n","542/542 [==============================] - 438s 807ms/step - loss: 0.0730 - sparse_categorical_accuracy: 0.9816 - val_loss: 0.1021 - val_sparse_categorical_accuracy: 0.9799\n","Epoch 95/100\n","542/542 [==============================] - 439s 810ms/step - loss: 0.0720 - sparse_categorical_accuracy: 0.9818 - val_loss: 0.1012 - val_sparse_categorical_accuracy: 0.9803\n","Epoch 96/100\n","542/542 [==============================] - 409s 755ms/step - loss: 0.0709 - sparse_categorical_accuracy: 0.9820 - val_loss: 0.1018 - val_sparse_categorical_accuracy: 0.9804\n","Epoch 97/100\n","542/542 [==============================] - 440s 811ms/step - loss: 0.0696 - sparse_categorical_accuracy: 0.9822 - val_loss: 0.1005 - val_sparse_categorical_accuracy: 0.9804\n","Epoch 98/100\n","542/542 [==============================] - 409s 754ms/step - loss: 0.0687 - sparse_categorical_accuracy: 0.9825 - val_loss: 0.1012 - val_sparse_categorical_accuracy: 0.9805\n","Epoch 99/100\n","542/542 [==============================] - 436s 805ms/step - loss: 0.0675 - sparse_categorical_accuracy: 0.9827 - val_loss: 0.1011 - val_sparse_categorical_accuracy: 0.9805\n","Epoch 100/100\n","542/542 [==============================] - 442s 815ms/step - loss: 0.0668 - sparse_categorical_accuracy: 0.9828 - val_loss: 0.1004 - val_sparse_categorical_accuracy: 0.9808\n","Tempo necessario per l'addestramento: 2:31:18.600566\n"]}],"source":["start = datetime.datetime.now()\n","\n","json_log = open(log_history, mode='a', buffering=1, encoding='utf-8')\n","\n","transformer.fit(train_dataset_dante,\n","                initial_epoch=EPOCHS_ADAM+EPOCHS_ADAM+EPOCHS_ADAM+EPOCHS_ADAM,\n","                epochs=EPOCHS_ADAM+EPOCHS_ADAM+EPOCHS_ADAM+EPOCHS_ADAM+EPOCHS_ADAM,\n","                shuffle=True,\n","                validation_data=validation_dataset_dante,\n","                callbacks=[tensorboard_callback,\n","                           json_logging_callback, \n","                           cp_callback])\n","\n","end = datetime.datetime.now()\n","print(f'Tempo necessario per l\\'addestramento: {end - start}')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5831448,"status":"ok","timestamp":1680037480635,"user":{"displayName":"daniele badiali","userId":"08100546172874775759"},"user_tz":-120},"id":"9HtFRuW6dDEE","outputId":"6ddcb8c5-e814-4462-8bf9-0cc6c68b330d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 101/120\n","542/542 [==============================] - 463s 839ms/step - loss: 0.0660 - sparse_categorical_accuracy: 0.9831 - val_loss: 0.1000 - val_sparse_categorical_accuracy: 0.9807\n","Epoch 102/120\n","542/542 [==============================] - 473s 873ms/step - loss: 0.0649 - sparse_categorical_accuracy: 0.9832 - val_loss: 0.0999 - val_sparse_categorical_accuracy: 0.9811\n","Epoch 103/120\n","542/542 [==============================] - 447s 825ms/step - loss: 0.0639 - sparse_categorical_accuracy: 0.9835 - val_loss: 0.0998 - val_sparse_categorical_accuracy: 0.9810\n","Epoch 104/120\n","542/542 [==============================] - 440s 812ms/step - loss: 0.0628 - sparse_categorical_accuracy: 0.9837 - val_loss: 0.0993 - val_sparse_categorical_accuracy: 0.9812\n","Epoch 105/120\n","542/542 [==============================] - 447s 825ms/step - loss: 0.0620 - sparse_categorical_accuracy: 0.9839 - val_loss: 0.0983 - val_sparse_categorical_accuracy: 0.9814\n","Epoch 106/120\n","542/542 [==============================] - 469s 866ms/step - loss: 0.0610 - sparse_categorical_accuracy: 0.9841 - val_loss: 0.0996 - val_sparse_categorical_accuracy: 0.9812\n","Epoch 107/120\n","542/542 [==============================] - 469s 866ms/step - loss: 0.0603 - sparse_categorical_accuracy: 0.9843 - val_loss: 0.0996 - val_sparse_categorical_accuracy: 0.9814\n","Epoch 108/120\n","542/542 [==============================] - 465s 857ms/step - loss: 0.0596 - sparse_categorical_accuracy: 0.9844 - val_loss: 0.1000 - val_sparse_categorical_accuracy: 0.9815\n","Epoch 109/120\n","542/542 [==============================] - 431s 794ms/step - loss: 0.0587 - sparse_categorical_accuracy: 0.9846 - val_loss: 0.1002 - val_sparse_categorical_accuracy: 0.9815\n","Epoch 110/120\n","542/542 [==============================] - 464s 857ms/step - loss: 0.0577 - sparse_categorical_accuracy: 0.9847 - val_loss: 0.0993 - val_sparse_categorical_accuracy: 0.9818\n","Epoch 111/120\n","542/542 [==============================] - 465s 858ms/step - loss: 0.0570 - sparse_categorical_accuracy: 0.9849 - val_loss: 0.0989 - val_sparse_categorical_accuracy: 0.9819\n","Epoch 112/120\n","542/542 [==============================] - 434s 800ms/step - loss: 0.0564 - sparse_categorical_accuracy: 0.9851 - val_loss: 0.0990 - val_sparse_categorical_accuracy: 0.9818\n","Epoch 113/120\n","542/542 [==============================] - 462s 854ms/step - loss: 0.0559 - sparse_categorical_accuracy: 0.9852 - val_loss: 0.0990 - val_sparse_categorical_accuracy: 0.9819\n","Epoch 114/120\n","542/542 [==============================] - 465s 858ms/step - loss: 0.0548 - sparse_categorical_accuracy: 0.9855 - val_loss: 0.1004 - val_sparse_categorical_accuracy: 0.9820\n","Epoch 115/120\n","542/542 [==============================] - 461s 850ms/step - loss: 0.0539 - sparse_categorical_accuracy: 0.9856 - val_loss: 0.0994 - val_sparse_categorical_accuracy: 0.9821\n","Epoch 116/120\n","542/542 [==============================] - 436s 805ms/step - loss: 0.0537 - sparse_categorical_accuracy: 0.9857 - val_loss: 0.0985 - val_sparse_categorical_accuracy: 0.9823\n","Epoch 117/120\n","542/542 [==============================] - 437s 807ms/step - loss: 0.0530 - sparse_categorical_accuracy: 0.9859 - val_loss: 0.1001 - val_sparse_categorical_accuracy: 0.9822\n","Epoch 118/120\n","542/542 [==============================] - 469s 865ms/step - loss: 0.0520 - sparse_categorical_accuracy: 0.9861 - val_loss: 0.1001 - val_sparse_categorical_accuracy: 0.9822\n","Epoch 119/120\n","542/542 [==============================] - 438s 808ms/step - loss: 0.0513 - sparse_categorical_accuracy: 0.9863 - val_loss: 0.1011 - val_sparse_categorical_accuracy: 0.9823\n","Epoch 120/120\n","542/542 [==============================] - 470s 868ms/step - loss: 0.0510 - sparse_categorical_accuracy: 0.9863 - val_loss: 0.1003 - val_sparse_categorical_accuracy: 0.9824\n","Tempo necessario per l'addestramento: 2:38:25.610550\n"]}],"source":["start = datetime.datetime.now()\n","\n","json_log = open(log_history, mode='a', buffering=1, encoding='utf-8')\n","\n","transformer.fit(train_dataset_dante,\n","                initial_epoch=EPOCHS_ADAM+EPOCHS_ADAM+EPOCHS_ADAM+EPOCHS_ADAM+EPOCHS_ADAM,\n","                epochs=EPOCHS_ADAM+EPOCHS_ADAM+EPOCHS_ADAM+EPOCHS_ADAM+EPOCHS_ADAM+EPOCHS_ADAM,\n","                shuffle=True,\n","                validation_data=validation_dataset_dante,\n","                callbacks=[tensorboard_callback,\n","                           json_logging_callback, \n","                           cp_callback])\n","\n","end = datetime.datetime.now()\n","print(f'Tempo necessario per l\\'addestramento: {end - start}')"]},{"cell_type":"markdown","metadata":{"id":"L0w4wF79UhAp"},"source":["## Valutazione dell'addestramento\n","Avendo in output il log ed i risultati dell'addestramento, possiamo visualizzare\n","queste informazioni relativamente alle metriche di interesse."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":336},"executionInfo":{"elapsed":2103,"status":"ok","timestamp":1680037482737,"user":{"displayName":"daniele badiali","userId":"08100546172874775759"},"user_tz":-120},"id":"RpXR2p5VAdoG","outputId":"140be4b2-f687-4803-9a3d-541ac202b8c8"},"outputs":[{"data":{"image/png":"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","text/plain":["<Figure size 1080x360 with 2 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["# Recupero il log di addestramento\n","df_history = pd.read_json(log_history, lines=True)\n","\n","# visualizzazione andamento addestramento\n","# su un grafico composto da due sub-plot\n","# uno per il loss, l'altro per l'accuracy\n","fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15,5))\n","\n","# Errore durante l'addestramento\n","ax1.plot(df_history['loss'], label='Loss')\n","ax1.plot(df_history['val_loss'], label='Validation Loss')\n","ax1.set_title('Training Loss')\n","ax1.legend()\n","\n","# Accuratezza durante l'addestramento\n","ax2.plot(df_history['sparse_categorical_accuracy'], label='Accuracy')\n","ax2.plot(df_history['val_sparse_categorical_accuracy'], label='Validation Accuracy')\n","ax2.set_title('Training Accuracy')\n","ax2.legend()\n","\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"ReOkcBp2WHWW"},"source":["## Test del modello\n","La seguente cella permette di caricare l'ultimo checkpoint dell'addestramento\n","precedentemente salvato."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RN0mnV8Wd92H"},"outputs":[],"source":["trainable = False\n","\n","transformer = TransformerBlock(NUM_LAYERS, \n","                               EMBEDDING_DIM, \n","                               NUM_HEADS, \n","                               FF_DIM,\n","                               MAX_SEQ_LENGTH,\n","                               tokenizers.ita.get_vocab_size(),\n","                               tfhub_handle_encoder,\n","                               trainable,\n","                               DROPUOT)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2567,"status":"ok","timestamp":1680071357857,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"},"user_tz":-120},"id":"5PIf_6-RSBb1","outputId":"49717920-febe-408f-938d-cc0f65095877"},"outputs":[{"data":{"text/plain":["<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x7fd371946d90>"]},"execution_count":50,"metadata":{},"output_type":"execute_result"}],"source":["# Carico i pesi modello\n","latest = tf.train.latest_checkpoint(PATH_WEIGHTS)\n","transformer.load_weights(latest)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"L2PEoJVb1V8x"},"outputs":[],"source":["class Translate:\n","  def __init__(self, transformer_block, tokenizers):\n","    self.transformer = transformer_block\n","    self.tokenizers = tokenizers\n","\n","  def predict(self, input_text, max_length):\n","    if input_text is None:\n","      input_text = (df[ORIGINAL_COLUMN].tolist())[np.random.choice(len(df[ORIGINAL_COLUMN].tolist()))]\n","      print(input_text)\n","\n","    inputs_bert = self.tokenizers.multilingual.tokenize(input_text)\n","\n","    start_end = self.tokenizers.ita.tokenize([''])[0]\n","    start = (start_end[0][tf.newaxis]).numpy()[0]\n","    end = (start_end[1][tf.newaxis]).numpy()[0]\n","\n","    output_array = tf.TensorArray(dtype=tf.int32, size=max_length, dynamic_size=True)\n","    output_array = output_array.write(0, tf.constant([start]))     \n","\n","    out_words = []\n","\n","    for i in tf.range(max_length):\n","      # decodifica e recupero probabilità di output\n","      output = tf.transpose(output_array.stack())\n","\n","      transformer_output = transformer((inputs_bert, output), \n","                                        training=False,\n","                                        debug=False)\n","\n","      predictions = transformer_output[:, -1:, :]\n","\n","      # selezione della parola più probabile\n","      predict = tf.argmax(predictions, -1)\n","      pred_values = (tf.keras.backend.argmax(transformer_output, axis=-1)).numpy()\n","    \n","      # inserimento della parola nella sequenza di output\n","      output_array = output_array.write(i+1, [pred_values[0][i]])\n","\n","      if pred_values[0][i] == end:\n","        break\n","\n","    output = tf.transpose(output_array.stack())\n","    text = tokenizers.ita.detokenize(output)[0]  \n","    tokens = tokenizers.ita.lookup(output)[0]\n","\n","    return text, tokens"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":254248,"status":"ok","timestamp":1680072092462,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"},"user_tz":-120},"id":"udIjI2jZWR6g","outputId":"347441fd-7509-4148-dd8b-d6a8093eea18"},"outputs":[{"name":"stdout","output_type":"stream","text":["Input          : Je lui ai fait croire que son bien être\n","Target         : A chui intender faciea , che 'l su' disdotto\n","Prediction     : a chui intender faciea , che ' l su ' disdotto\n","---------------------------------------------\n","Input          : J' ètais plus excitèe que tout . \n","Target         : Mi piaciea più che null' altro , ch' e' ssia . \n","Prediction     : e piu arditamente contr ' a llui piu che fele ;\n","---------------------------------------------\n","Input          : J' ètais sèduisante , jeune et drôle . \n","Target         : I' era bella , e giovane , e folletta , \n","Prediction     : e ' fu fondato per folle e fornita\n","---------------------------------------------\n","Input          : Mais il n' ètait pas à l' ècole d' affection . \n","Target         : Ma non era a la scuola de l' Amore\n","Prediction     : ma non era a l ' amor unquanche conosciuto ,\n","---------------------------------------------\n","Input          : C' ètait; cependant , je le sais maintenant en profondeur par c ur . \n","Target         : Istata; ma i' so or ben per cuore\n","Prediction     : istata ; ma i ' so or ben per cuore\n","---------------------------------------------\n","Input          : L' exercice qui sera prèsentè ici . \n","Target         : La pratica , la qual ti fie qui detta . \n","Prediction     : la qual sapranno ben sua malatia .\n","---------------------------------------------\n","Input          : L' habitude m' a rendu si expèrimentèe . \n","Target         : Usanza me n' à fatta sì savietta , \n","Prediction     : vergognia si mi mise per richiamo ,\n","---------------------------------------------\n","Input          : Je ne pouvais pas tromper les lecteurs . \n","Target         : Ched i' non dotterei nessun lettore , \n","Prediction     : ched i ' non dotterei nessun lettore ,\n","---------------------------------------------\n","Input          : qu' il m' a donnè une mauvaise opinion de ça . \n","Target         : Che di ciò mi faciesse desinore , \n","Prediction     : che di lui mi richiamo a pietanza ,\n","---------------------------------------------\n","Input          : Mais parce que j' ètais sèduisante et jeune . \n","Target         : Ma' ched i' fosse bella e giovanetta \n","Prediction     : ma ' ched i ' fu fondato .\n","---------------------------------------------\n","Input          : Parce que ce que j' ai fait est gènial . \n","Target         : Chèd egli è tanto ched i' non finai , \n","Prediction     : ched i ' si piacie d ' ben cio ,\n","---------------------------------------------\n","Input          : que l' apprentissage ou dans mon audace . \n","Target         : Che lla scienza i' ò nel mi' coragio . \n","Prediction     : che lla scienza i ' o nel mi ' coragio .\n","---------------------------------------------\n","Input          : Si vous l' aimez , vous l' ècouterez . \n","Target         : Sed e' ti piacie , tu l' ascholterai , \n","Prediction     : se ttu lo vi piacie , tu ' l ' intenda ,\n","---------------------------------------------\n","Input          : mais je ne l' aurais pas obtenue sans un grand sacrifice;\n","Target         : Ma i' no l' ebi sanza gran damagio \n","Prediction     : ma i ' non vi richegio ch ' e ' soccorra durante .\n","---------------------------------------------\n","Input          : J' ai souffert intensèment et j' ai travaillè dur . \n","Target         : Molta pen' e travaglio vi durai;\n","Prediction     : molta pen ' e travaglio vi durai ;\n","---------------------------------------------\n","Input          : Cependant , maintenant la douleur a disparu et j' ai gagnè la sagesse . \n","Target         : Ma pur e 'l mal se n' è mess' , e l' usagio . \n","Prediction     : ma pur e ' l mal se n ' e mess ' , e l ' usagio .\n","---------------------------------------------\n","Input          : J' ai conniquè beaucoup d' hommes . \n","Target         : Molti buon' uomini i' ò già 'nghannati , \n","Prediction     : ed i ' si vidi molto gran fretta ,\n","---------------------------------------------\n","Input          : Quand je les ai gardès coincès dans mes cravates . \n","Target         : Quand' i' gli tenni ne mie' lacci presi , \n","Prediction     : quand ' i ' gli tenni ne mie ' lacci presi ,\n","---------------------------------------------\n","Input          : Mais avant cela , j' ai ètè trompè pendant tant de mois . \n","Target         : Ma prima fu' 'ngannata tanti mesi\n","Prediction     : ma prima , ched i ' fu ' ' n asiglio ,\n","---------------------------------------------\n","Input          : que mes amusements avaient dèjà disparu . \n","Target         : Che ' più de' mie' sollazi eran passati . \n","Prediction     : che ' piu de ' mie ' sollazi eran passati .\n","---------------------------------------------\n","Input          : Cent mille d' entre eux ont ètè èchangès . \n","Target         : Cientomilia cotanti e' barattati\n","Prediction     : cientomilia cotanti e ' barattati\n","---------------------------------------------\n","Input          : Je le ferais , si je les avais acquises rapidement . \n","Target         : N' avrei , s' i' a buon' ora gli avesse tesi \n","Prediction     : si ' l faro , se tanta viltanza\n","---------------------------------------------\n","Input          : et compte , noble et riche bourgeois , \n","Target         : E conti , e cavalieri , e gran borgesi , \n","Prediction     : e conti , e cavalieri , e gran borgesi ,\n","---------------------------------------------\n","Input          : ça me donnerait beaucoup de florins d' or . \n","Target         : Ch' e' molti fiorin d' oro m' avrian dati . \n","Prediction     : che molte volte mi gastigava\n","---------------------------------------------\n","Input          : Quand j' ai rèalisè , il ètait dèjà trop tard . \n","Target         : Ma , quand' i' me n' avidi , egli era tardi , \n","Prediction     : quand ' i ' vidi venir un poco il fante ,\n","---------------------------------------------\n","Input          : parce que j' avais dèjà dèpassè l' adolescence\n","Target         : Chèd i' era già fuor di Giovaneza , \n","Prediction     : ched i ' avea per me ne trasale\n","---------------------------------------------\n","Input          : Et mes yeux tendres ètaient vides . \n","Target         : Ed eranmi falliti i dolzi isguardi , \n","Prediction     : e suo ' lodar suo ' eran caritevoli ,\n","---------------------------------------------\n","Input          : parce que ma maturitè m' a tenu sous son contrôle . \n","Target         : Perchè 'n sua balia mi tenea Vechieza . \n","Prediction     : ched i ' mi riguardai dal su ' arte ,\n","---------------------------------------------\n","Input          : Il convient maintenant , ma chère , que vous vous occupiez de vous même . \n","Target         : Or convien , figluola mia , che tu ti guardi , \n","Prediction     : or convien , figluola mia , che ti sai\n","---------------------------------------------\n","Input          : Que tu ne te comportes pas comme ça . \n","Target         : Chettu non ti conduchi a tale streza . \n","Prediction     : che ttu non troverai i nulla parte\n","---------------------------------------------\n","Input          : Mon c ur a souffert profondèment quand j' ai regardè\n","Target         : Molto mi dolea il cuor , quand' i' vedea\n","Prediction     : molto mi dolea il cuor , quand ' i ' vedea\n","---------------------------------------------\n","Input          : que ma porte ètait dans un endroit comme celui ci . \n","Target         : Chell' uscio mio stava in tal sogiorno , \n","Prediction     : che lla mia via era gia cio era .\n","---------------------------------------------\n","Input          : C' ètait tellement bondè autour d' elle . \n","Target         : Ch' e' vi solea aver tal pressa 'ntorno\n","Prediction     : si forte a llei atare ,\n","---------------------------------------------\n","Input          : que l' ensemble de la règion est nègatif . \n","Target         : Che tutta la contrada ne dolea . \n","Prediction     : che tutto ' l valletto , ch ' e fera ,\n","---------------------------------------------\n","Input          : Cependant , je m' en fichais . \n","Target         : Ma , quanto a me , e' no me ne calea , \n","Prediction     : ma ' si mi riguardai dal dritto lato ,\n","---------------------------------------------\n","Input          : parce que c' ètait trop agrèable pour eux , \n","Target         : Chè troppo più piaciea loro quel torno , \n","Prediction     : che troppo fu troppo tosto per lor podere ,\n","---------------------------------------------\n","Input          : que j' ètais alors si ènorme . \n","Target         : Ch' i' era allora di sì grande attorno , \n","Prediction     : che io fu messa la vo ' si troveria .\n","---------------------------------------------\n","Input          : que tout l' univers m' est apparu . \n","Target         : Che tutto quanto il mondo mi' parea . \n","Prediction     : che tutto ' l mondo i ' era ricordata ,\n","---------------------------------------------\n","Input          : Maintenant , il me convient de mourir de tristesse . \n","Target         : Or convenia che di dolor morisse , \n","Prediction     : or si trovai ver ' me fedel ,\n","---------------------------------------------\n","Input          : Quand j' ai vu ces enfants passer , \n","Target         : Quand' i' vedea que' giovani passare , \n","Prediction     : quand ' i ' udi ' valletti d ' antecristo ,\n","---------------------------------------------\n","Input          : Et tout le monde semblait se moquer de moi . \n","Target         : E ciaschedun parea che mi schernisse . \n","Prediction     : e ciaschedun parea che mi schernisse .\n","---------------------------------------------\n","Input          : Ils m' ont appelè Vieille dame gorgèe . \n","Target         :  Vechia increspata mi faciean chiamare\n","Prediction     : molto mi fecier dispett ' anno ,\n","---------------------------------------------\n","Input          : Pour qui seulement , c' est une fois\n","Target         : A colu' solamente , che giadisse\n","Prediction     : a che le potesse , e ' ntendimento ;\n","---------------------------------------------\n","Input          : Il m' aimait plus sensuellement . \n","Target         : Più carnalmente mi solea amare . \n","Prediction     : piu carnalmente mi solea amare .\n","---------------------------------------------\n","Input          : D' un autre point de vue , le c ur humain\n","Target         : Ancora d' altra parte cuore humano\n","Prediction     : ancor ' n altra parte cuore humano\n","---------------------------------------------\n","Input          : Tu n' imagines pas la profonde tristesse que je ressens . \n","Target         : Non penserebe il gran dolor , ch' i' sento , \n","Prediction     : tu metta inpaccio , ch ' i ' o perpensato ,\n","---------------------------------------------\n","Input          : De tous les moments où j' ai mèditè\n","Target         : Tratutte l' ore ch' i' ò pensamento\n","Prediction     : per tutti i tutti i nulla faglia ,\n","---------------------------------------------\n","Input          : Aux doux baisers qu' ils m' ont donnès . \n","Target         : De' be' basciar' , che m' ànno dato mano . \n","Prediction     : ma apressoche tutte le sante gloriose ,\n","---------------------------------------------\n","Input          : Tous les plaisirs sont maintenant à distance pour moi , \n","Target         : Ogni' Sollazo m' è ogi lontano , \n","Prediction     : tutti gli giurai a le sante\n","---------------------------------------------\n","Input          : mais pas l' indignation et la souffrance et une grande agonie\n","Target         : Ma non Ira e Dolori e Gran Tormento \n","Prediction     : ma non ira e dolori e gran tormento\n","---------------------------------------------\n"]}],"source":["translate = Translate(transformer_block=transformer,\n","                      tokenizers=tokenizers)\n","\n","# Recupero un batch di esempi per la verifica delle classi custom che andrò a creare\n","for test_input_data, test_target_data in test_dataset.take(50):\n","  test_input_data = test_input_data.numpy().decode()\n","  test_target_data = test_target_data.numpy().decode()\n","\n","  text, token = translate.predict(tf.constant([test_input_data]), MAX_SEQ_LENGTH)\n","\n","  print(f'{\"Input\":15s}: {test_input_data}')\n","  print(f'{\"Target\":15s}: {test_target_data}')\n","  print(f'{\"Prediction\":15s}: {text.numpy().decode(\"utf-8\")}')  \n","  print('---------------------------------------------')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7618,"status":"ok","timestamp":1680072300037,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"},"user_tz":-120},"id":"Qex8JVqvJxzp","outputId":"58ca9ac9-d032-45f1-8515-e44305d4b9cc"},"outputs":[{"name":"stdout","output_type":"stream","text":["Input          : Ieri sono andato al supermercato\n","Prediction     : i ' van cherendo lor vita ,\n","---------------------------------------------\n"]}],"source":["  text_input_data = 'Ieri sono andato al supermercato'\n","\n","  text, token = translate.predict(tf.constant([text_input_data]), MAX_SEQ_LENGTH)\n","  print(f'{\"Input\":15s}: {text_input_data}')\n","  print(f'{\"Prediction\":15s}: {text.numpy().decode(\"utf-8\")}')  \n","  print('---------------------------------------------')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8370,"status":"ok","timestamp":1680072336039,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"},"user_tz":-120},"id":"s9Dun8NnGaXd","outputId":"efd28f2d-c1c2-47a0-8b68-126447c92c56"},"outputs":[{"name":"stdout","output_type":"stream","text":["Input          : ho comprato la cocacolo\n","Prediction     : i ' potre ' ben tosto confortato ,\n","---------------------------------------------\n"]}],"source":["  text_input_data = 'ho comprato la cocacolo'\n","\n","  text, token = translate.predict(tf.constant([text_input_data]), MAX_SEQ_LENGTH)\n","  print(f'{\"Input\":15s}: {text_input_data}')\n","  print(f'{\"Prediction\":15s}: {text.numpy().decode(\"utf-8\")}')  \n","  print('---------------------------------------------')"]},{"cell_type":"markdown","metadata":{"id":"O16Hx71zjnNA"},"source":["## Tensorboard"]},{"cell_type":"code","source":["log_dir"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"84n8PLq1y2rO","executionInfo":{"status":"ok","timestamp":1682632957892,"user_tz":-120,"elapsed":47,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}},"outputId":"f34c242e-22ac-4d0e-ae07-1b901cddcc67"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/content/drive/MyDrive/BERT/logs/fit/transformer_multi_bert_dante/20230427-211111'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":48}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":50814,"status":"ok","timestamp":1682927247152,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"},"user_tz":-120},"id":"Qmo7Pi3TaoFJ","outputId":"5c4d7ee5-901f-45d2-b8a9-e2f80d8f5851"},"outputs":[{"output_type":"stream","name":"stdout","text":["2023-05-01 07:46:36.773388: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2023-05-01 07:46:38.322706: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","\n","***** TensorBoard Uploader *****\n","\n","This will upload your TensorBoard logs to https://tensorboard.dev/ from\n","the following directory:\n","\n","drive/MyDrive/BERT/logs/fit/transformer_multi_bert_dante/\n","\n","This TensorBoard will be visible to everyone. Do not upload sensitive\n","data.\n","\n","Your use of this service is subject to Google's Terms of Service\n","<https://policies.google.com/terms> and Privacy Policy\n","<https://policies.google.com/privacy>, and TensorBoard.dev's Terms of Service\n","<https://tensorboard.dev/policy/terms/>.\n","\n","This notice will not be shown again while you are logged into the uploader.\n","To log out, run `tensorboard dev auth revoke`.\n","\n","Continue? (yes/NO) yes\n","\n","To sign in with the TensorBoard uploader:\n","\n","1. On your computer or phone, visit:\n","\n","   https://www.google.com/device\n","\n","2. Sign in with your Google account, then enter:\n","\n","   WRTF-BSMD\n","\n","\n","\n","New experiment created. View your TensorBoard at: https://tensorboard.dev/experiment/bYnoPCabQeKK50pf5JJZ5g/\n","\n","\u001b[1m[2023-05-01T07:47:05]\u001b[0m Started scanning logdir.\n","\u001b[1m[2023-05-01T07:47:24]\u001b[0m Total uploaded: 390 scalars, 12250 tensors (8.6 MB), 0 binary objects\n","\u001b[1m[2023-05-01T07:47:24]\u001b[0m Done scanning logdir.\n","\n","\n","Done. View your TensorBoard at https://tensorboard.dev/experiment/bYnoPCabQeKK50pf5JJZ5g/\n"]}],"source":["!tensorboard dev upload --logdir drive/MyDrive/BERT/logs/fit/transformer_multi_bert_dante/ \\\n","  --name \"Simple experiment with DANTE\" \\\n","  --description \"Training results\" \\\n","  --one_shot"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5078,"status":"ok","timestamp":1682628990878,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"},"user_tz":-120},"id":"TDkluV2jatRW","outputId":"dd7760e0-13f2-4656-d658-5b962a34efbe"},"outputs":[{"output_type":"stream","name":"stdout","text":["2023-04-27 20:56:22.970611: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","https://tensorboard.dev/experiment/qwjNspAfQVu6fQhM1h1zHQ/\n","\tName                 Simple experiment with DANTE\n","\tDescription          Training results\n","\tId                   qwjNspAfQVu6fQhM1h1zHQ\n","\tCreated              2023-04-27 20:51:08 (5 minutes ago)\n","\tUpdated              2023-04-27 20:51:14 (5 minutes ago)\n","\tRuns                 2\n","\tTags                 246\n","\tScalars              30\n","\tTensor bytes         986150\n","\tBinary object bytes  0\n","https://tensorboard.dev/experiment/ji6RDWI9RbSqiMLVIKV5cg/\n","\tName                 Simple experiment with DANTE\n","\tDescription          Training results\n","\tId                   ji6RDWI9RbSqiMLVIKV5cg\n","\tCreated              2023-04-24 05:55:12\n","\tUpdated              2023-04-24 05:55:15\n","\tRuns                 2\n","\tTags                 246\n","\tScalars              30\n","\tTensor bytes         986150\n","\tBinary object bytes  0\n","https://tensorboard.dev/experiment/kz427r91RyG3KW8xxIKumA/\n","\tName                 Simple experiment with DANTE\n","\tDescription          Training results\n","\tId                   kz427r91RyG3KW8xxIKumA\n","\tCreated              2023-04-23 21:44:48\n","\tUpdated              2023-04-23 21:44:55\n","\tRuns                 8\n","\tTags                 448\n","\tScalars              66\n","\tTensor bytes         1827574\n","\tBinary object bytes  0\n","https://tensorboard.dev/experiment/sz29B3VyRmqfebbcgkDb5w/\n","\tName                 Simple experiment with DANTE\n","\tDescription          Training results\n","\tId                   sz29B3VyRmqfebbcgkDb5w\n","\tCreated              2023-04-16 13:06:26\n","\tUpdated              2023-04-16 13:06:32\n","\tRuns                 6\n","\tTags                 306\n","\tScalars              60\n","\tTensor bytes         1630344\n","\tBinary object bytes  0\n","https://tensorboard.dev/experiment/wpDS4ToWTRawoE6HXk2KDA/\n","\tName                 Simple experiment with DANTE\n","\tDescription          Training results\n","\tId                   wpDS4ToWTRawoE6HXk2KDA\n","\tCreated              2023-04-16 11:36:27\n","\tUpdated              2023-04-16 11:36:29\n","\tRuns                 3\n","\tTags                 164\n","\tScalars              30\n","\tTensor bytes         644022\n","\tBinary object bytes  0\n","https://tensorboard.dev/experiment/OzgNkTB5Roq1sKllyqs59A/\n","\tName                 Simple experiment with DANTE\n","\tDescription          Training results\n","\tId                   OzgNkTB5Roq1sKllyqs59A\n","\tCreated              2023-04-15 21:33:01\n","\tUpdated              2023-04-15 21:33:02\n","\tRuns                 2\n","\tTags                 162\n","\tScalars              6\n","\tTensor bytes         128770\n","\tBinary object bytes  0\n","https://tensorboard.dev/experiment/3U1Nf9KTREK7qjaoAVXkYw/\n","\tName                 Simple experiment with DANTE\n","\tDescription          Training results\n","\tId                   3U1Nf9KTREK7qjaoAVXkYw\n","\tCreated              2023-04-15 21:24:25\n","\tUpdated              2023-04-15 21:24:27\n","\tRuns                 2\n","\tTags                 162\n","\tScalars              30\n","\tTensor bytes         643850\n","\tBinary object bytes  0\n","https://tensorboard.dev/experiment/JmlqdrIrS5CdlYzWVdI54A/\n","\tName                 Simple experiment with DANTE\n","\tDescription          Training results\n","\tId                   JmlqdrIrS5CdlYzWVdI54A\n","\tCreated              2023-04-15 20:58:52\n","\tUpdated              2023-04-15 20:59:10\n","\tRuns                 2\n","\tTags                 162\n","\tScalars              30\n","\tTensor bytes         643850\n","\tBinary object bytes  0\n","https://tensorboard.dev/experiment/fygh8BLBQHOJdGzAMxmfXA/\n","\tName                 Simple experiment with DANTE\n","\tDescription          Training results\n","\tId                   fygh8BLBQHOJdGzAMxmfXA\n","\tCreated              2023-04-15 19:38:15\n","\tUpdated              2023-04-15 19:38:23\n","\tRuns                 6\n","\tTags                 572\n","\tScalars              90\n","\tTensor bytes         3129600\n","\tBinary object bytes  0\n","https://tensorboard.dev/experiment/lJb9W1RrQOaMYTKrynPUnQ/\n","\tName                 Simple experiment with MNIST\n","\tDescription          Training results from https://colab.sandbox.google.com/github/tensorflow/tensorboard/blob/master/docs/tbdev_getting_started.ipynb\n","\tId                   lJb9W1RrQOaMYTKrynPUnQ\n","\tCreated              2023-04-15 14:06:14\n","\tUpdated              2023-04-15 14:06:14\n","\tRuns                 3\n","\tTags                 11\n","\tScalars              30\n","\tTensor bytes         16472\n","\tBinary object bytes  39928\n","Total: 10 experiment(s)\n"]}],"source":["!tensorboard dev list"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UONyLudWHYCr"},"outputs":[],"source":["# Load the TensorBoard notebook extension\n","%load_ext tensorboard"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1681594356316,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"},"user_tz":-120},"id":"tGB-oC3ZzQqa","outputId":"77eef916-97fe-4d91-8883-bf54d4790262"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'/content/drive/MyDrive/BERT/logs/fit/transformer_multi_bert_dante/20230415-212813'"]},"execution_count":51,"metadata":{},"output_type":"execute_result"}],"source":["log_dir"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"elapsed":14,"status":"ok","timestamp":1681577488877,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"},"user_tz":-120},"id":"R4_6sNh5FS9b","outputId":"e8384872-ab83-4d43-d774-63bdf7623077"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'/content/drive/MyDrive/BERT/logs/fit/transformer_multi_bert_dante/1_LAYER'"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["os.path.abspath(os.path.join(PATH_LOG, '1_LAYER')) "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":156},"executionInfo":{"elapsed":6310,"status":"ok","timestamp":1681591441329,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"},"user_tz":-120},"id":"yosd9IsbjkAg","outputId":"2e2c5d20-e206-4743-c241-526b9af06c5d"},"outputs":[{"data":{"text/plain":["ERROR: Failed to launch TensorBoard (exited with 1).\n","Contents of stderr:\n","2023-04-15 20:43:58.364232: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","/usr/local/lib/python3.9/dist-packages/tensorboard_data_server/bin/server: /lib/x86_64-linux-gnu/libc.so.6: version `GLIBC_2.33' not found (required by /usr/local/lib/python3.9/dist-packages/tensorboard_data_server/bin/server)\n","/usr/local/lib/python3.9/dist-packages/tensorboard_data_server/bin/server: /lib/x86_64-linux-gnu/libc.so.6: version `GLIBC_2.34' not found (required by /usr/local/lib/python3.9/dist-packages/tensorboard_data_server/bin/server)\n","/usr/local/lib/python3.9/dist-packages/tensorboard_data_server/bin/server: /lib/x86_64-linux-gnu/libc.so.6: version `GLIBC_2.32' not found (required by /usr/local/lib/python3.9/dist-packages/tensorboard_data_server/bin/server)\n","Address already in use\n","Port 6006 is in use by another program. Either identify and stop that program, or start the server with a different port."]},"metadata":{},"output_type":"display_data"}],"source":["%tensorboard --logdir drive/MyDrive/BERT/logs/fit/transformer_multi_bert_dante/1_LAYER"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":243},"executionInfo":{"elapsed":5752,"status":"ok","timestamp":1681565223134,"user":{"displayName":"Daniele Badiali","userId":"07880650122235290376"},"user_tz":-120},"id":"p3No5FtKpx2c","outputId":"2939007d-ea81-4c4b-ec76-e4f9c0851f2d"},"outputs":[{"data":{"text/plain":["ERROR: Failed to launch TensorBoard (exited with -6).\n","Contents of stderr:\n","2023-04-15 13:26:59.019237: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","/usr/local/lib/python3.9/dist-packages/tensorboard_data_server/bin/server: /lib/x86_64-linux-gnu/libc.so.6: version `GLIBC_2.33' not found (required by /usr/local/lib/python3.9/dist-packages/tensorboard_data_server/bin/server)\n","/usr/local/lib/python3.9/dist-packages/tensorboard_data_server/bin/server: /lib/x86_64-linux-gnu/libc.so.6: version `GLIBC_2.34' not found (required by /usr/local/lib/python3.9/dist-packages/tensorboard_data_server/bin/server)\n","/usr/local/lib/python3.9/dist-packages/tensorboard_data_server/bin/server: /lib/x86_64-linux-gnu/libc.so.6: version `GLIBC_2.32' not found (required by /usr/local/lib/python3.9/dist-packages/tensorboard_data_server/bin/server)\n","Address already in use\n","Port 6006 is in use by another program. Either identify and stop that program, or start the server with a different port.\n","terminate called without an active exception\n","Fatal Python error: Aborted\n","\n","Thread 0x00007f4b14297740 (most recent call first):\n","<no Python frame>"]},"metadata":{},"output_type":"display_data"}],"source":["%tensorboard --logdir drive/MyDrive/BERT/logs/fit/transformer_multi_bert_dante/3_LAYER"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":399},"executionInfo":{"elapsed":5690,"status":"ok","timestamp":1681551431900,"user":{"displayName":"Daniele Badiali","userId":"07880650122235290376"},"user_tz":-120},"id":"-taBXIf6pzEg","outputId":"aa9dbf23-92e2-4820-defd-e499e6163c87"},"outputs":[{"data":{"text/plain":["ERROR: Failed to launch TensorBoard (exited with 2).\n","Contents of stderr:\n","2023-04-15 09:37:07.877822: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","usage: tensorboard [-h] [--helpfull] [--logdir PATH] [--logdir_spec PATH_SPEC]\n","                   [--host ADDR] [--bind_all] [--port PORT]\n","                   [--reuse_port BOOL] [--load_fast {false,auto,true}]\n","                   [--extra_data_server_flags EXTRA_DATA_SERVER_FLAGS]\n","                   [--grpc_creds_type {local,ssl,ssl_dev}]\n","                   [--grpc_data_provider PORT] [--purge_orphaned_data BOOL]\n","                   [--db URI] [--db_import] [--inspect] [--version_tb]\n","                   [--tag TAG] [--event_file PATH] [--path_prefix PATH]\n","                   [--window_title TEXT] [--max_reload_threads COUNT]\n","                   [--reload_interval SECONDS] [--reload_task TYPE]\n","                   [--reload_multifile BOOL]\n","                   [--reload_multifile_inactive_secs SECONDS]\n","                   [--generic_data TYPE]\n","                   [--samples_per_plugin SAMPLES_PER_PLUGIN]\n","                   [--detect_file_replacement BOOL]\n","                   [--whatif-use-unsafe-custom-prediction YOUR_CUSTOM_PREDICT_FUNCTION.py]\n","                   [--whatif-data-dir PATH]\n","                   {serve,dev} ...\n","tensorboard: error: argument {serve,dev}: invalid choice: '6_LAYER))' (choose from 'serve', 'dev')"]},"metadata":{},"output_type":"display_data"}],"source":["%tensorboard --logdir os.path.abspath(os.path.join(PATH_LOG, '6_LAYER')) "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Vw5GLv0vSNB2"},"outputs":[],"source":["logdir = os.path.abspath(os.path.join(PATH_LOG, '12_LAYER')) "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":156},"executionInfo":{"elapsed":6040,"status":"ok","timestamp":1681551784436,"user":{"displayName":"Daniele Badiali","userId":"07880650122235290376"},"user_tz":-120},"id":"gPF8Gml7p0SX","outputId":"ebb87115-5494-40c1-cbed-b105baf17bf4"},"outputs":[{"data":{"text/plain":["ERROR: Failed to launch TensorBoard (exited with 1).\n","Contents of stderr:\n","2023-04-15 09:43:00.743943: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","/usr/local/lib/python3.9/dist-packages/tensorboard_data_server/bin/server: /lib/x86_64-linux-gnu/libc.so.6: version `GLIBC_2.33' not found (required by /usr/local/lib/python3.9/dist-packages/tensorboard_data_server/bin/server)\n","/usr/local/lib/python3.9/dist-packages/tensorboard_data_server/bin/server: /lib/x86_64-linux-gnu/libc.so.6: version `GLIBC_2.34' not found (required by /usr/local/lib/python3.9/dist-packages/tensorboard_data_server/bin/server)\n","/usr/local/lib/python3.9/dist-packages/tensorboard_data_server/bin/server: /lib/x86_64-linux-gnu/libc.so.6: version `GLIBC_2.32' not found (required by /usr/local/lib/python3.9/dist-packages/tensorboard_data_server/bin/server)\n","Address already in use\n","Port 6006 is in use by another program. Either identify and stop that program, or start the server with a different port."]},"metadata":{},"output_type":"display_data"}],"source":["%tensorboard --logdir drive/MyDrive/BERT/logs/fit/transformer_multi_bert_dante/12_LAYER"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"elapsed":721,"status":"ok","timestamp":1681551485230,"user":{"displayName":"Daniele Badiali","userId":"07880650122235290376"},"user_tz":-120},"id":"cOERrwjDp2Cm","outputId":"1d634b6c-1cfe-4304-f650-0609428de75c"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'/content/drive/MyDrive/BERT/logs/fit/transformer_multi_bert_dante/12_LAYER'"]},"execution_count":53,"metadata":{},"output_type":"execute_result"}],"source":["os.path.abspath(os.path.join(PATH_LOG, '12_LAYER')) "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ip4B73rKR2Lw"},"outputs":[],"source":[]}],"metadata":{"colab":{"collapsed_sections":["GhBGzbvrh2Rw"],"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.6"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}