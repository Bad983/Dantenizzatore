{"cells":[{"cell_type":"markdown","source":["## Pacchetti da installare"],"metadata":{"id":"yDKuSNBd92YI"}},{"cell_type":"code","source":["!pip install -q -U 'tensorflow-text==2.8.*'"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NE4enZGpvMRX","executionInfo":{"status":"ok","timestamp":1680176251004,"user_tz":-120,"elapsed":78130,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}},"outputId":"18682556-2277-44fb-fa90-6ee59eb287fe"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m25.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m498.1/498.1 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m462.3/462.3 KB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 KB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}]},{"cell_type":"code","source":["!pip install -q tf-models-official"],"metadata":{"id":"FPtWz_qHuofc","executionInfo":{"status":"ok","timestamp":1680176310351,"user_tz":-120,"elapsed":59353,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"a89542d8-7b71-4459-b48b-dbfdfac17b11"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m32.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m238.9/238.9 KB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m56.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m588.3/588.3 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.9/118.9 KB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m73.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 KB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m630.1/630.1 KB\u001b[0m \u001b[31m51.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m66.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m58.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m53.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m439.2/439.2 KB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n"]}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"hJy-juNOpUOY","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1680176333978,"user_tz":-120,"elapsed":23642,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}},"outputId":"2390eb17-0257-4910-abfc-4c336c66fa1a"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","source":["## Import notebook"],"metadata":{"id":"xXYm-Qqw-ANh"}},{"cell_type":"code","execution_count":4,"metadata":{"collapsed":true,"id":"UaAiWsEuC_4K","executionInfo":{"status":"ok","timestamp":1680176340909,"user_tz":-120,"elapsed":6938,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}}},"outputs":[],"source":["import os\n","import re\n","import datetime\n","import pathlib\n","import json\n","from pathlib import Path\n","\n","import pandas as pd\n","import numpy as np\n","\n","from sklearn.model_selection import train_test_split\n","\n","import tensorflow as tf\n","import tensorflow_hub as hub\n","import tensorflow_text as text\n","from tensorflow_text.tools.wordpiece_vocab import bert_vocab_from_dataset as bert_vocab\n","\n","import matplotlib.pyplot as plt\n","\n","from typing import Tuple\n"]},{"cell_type":"code","source":["tf.get_logger().setLevel('ERROR')\n","tf.config.run_functions_eagerly(True)"],"metadata":{"id":"uKEqRlKowOQS","executionInfo":{"status":"ok","timestamp":1680176340910,"user_tz":-120,"elapsed":16,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["## Variabili Globali"],"metadata":{"id":"HRe16D-rUBLA"}},{"cell_type":"code","source":["# PARAMETRI GLOBALI\n","root_folder = 'drive/MyDrive/BERT/'\n","\n","# DATI\n","data_folder_name = 'data'\n","train_filename = 'train_data.csv'\n","\n","DATA_PATH = os.path.abspath(os.path.join(root_folder, data_folder_name))\n","train_data_filenamepath = os.path.abspath(os.path.join(DATA_PATH, train_filename))\n","\n","# PATH LOG Tensorboard\n","PATH_LOG = 'logs/fit/transformer_multi_bert_dante'\n","PATH_LOG = os.path.abspath(os.path.join(root_folder, PATH_LOG))\n","log_dir =  os.path.abspath(os.path.join(PATH_LOG, datetime.datetime.now().strftime('%Y%m%d-%H%M%S'))) \n","log_history = os.path.abspath(os.path.join(PATH_LOG, 'histrory.json'))\n","\n","# PATH WEIGHTS Tensorboard\n","PATH_WEIGHTS = 'weights/transformer_multi_bert_dante'\n","PATH_WEIGHTS = os.path.abspath(os.path.join(root_folder, PATH_WEIGHTS))\n","checkpoint_path = os.path.abspath(os.path.join(PATH_WEIGHTS, 'cp.ckpt'))\n","\n","# VOCABOLARIO\n","vocab_folder = 'vocab'\n","multilingual_vocab_finalname = 'multilingual_vocab.txt'\n","ita_vocab_finalname = 'ita_dante_vocab.txt'\n","\n","VOCAB_PATH = os.path.abspath(os.path.join(root_folder, vocab_folder))\n","multilingual_vocab_filenamepath = os.path.abspath(os.path.join(VOCAB_PATH, multilingual_vocab_finalname))\n","ita_vocab_filenamepath = os.path.abspath(os.path.join(VOCAB_PATH, ita_vocab_finalname))\n","\n","# parametri per il modello\n","ORIGINAL_COLUMN = 'Original'\n","TRANSLATE_COLUMN = 'Translate'\n","TYPE_COLUMN ='Type'"],"metadata":{"id":"ewLgCIuEpczO","executionInfo":{"status":"ok","timestamp":1680176340910,"user_tz":-120,"elapsed":15,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}}},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":["## Iper Parametri Modello"],"metadata":{"id":"LCiP6wT05k6j"}},{"cell_type":"code","source":["NUM_SAMPLES = 25000\n","TEST = 200\n","TEST_SIZE = 0.3\n","\n","MAX_VOCAB_SIZE = 30000 \n","EMBEDDING_DIM = 128\n","HIDDEN_DIM = 1024 # numero di celle nei layer ricorrenti nascosti\n","\n","BATCH_SIZE = 32\n","BUFFER_SIZE = 2000\n","MAX_SEQ_LENGTH = 128\n","\n","NUM_LAYERS = 1 # Numero di layer di Decoder del Transformer\n","NUM_HEADS = 8 # Numero di meccanismi di multi-head attention\n","FF_DIM = 16 # Numero di celle dei Layer Feed Forward\n","DROPUOT = 0.5\n","\n","# Ottimizzatore Adam\n","LEARNING_RATE_ADAM = 1e-4\n","BETA_1 = 0.66\n","BETA_2 = 0.999\n","EPOCHS_ADAM = 20\n","\n","# IMPOSTO IL DEBUG A TRUE \n","debug = True\n","trainable = False\n","training = True"],"metadata":{"id":"8CN-4Uzoqbjl","executionInfo":{"status":"ok","timestamp":1680176340911,"user_tz":-120,"elapsed":15,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}}},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":["## Parametri BERT"],"metadata":{"id":"BehZY4rETECN"}},{"cell_type":"code","source":["bert_model_name = 'distilbert_multi_cased_L-6_H-768_A-12/1'  \n","tfhub_handle_preprocess = 'https://tfhub.dev/jeongukjae/distilbert_multi_cased_preprocess/2'\n","tfhub_handle_encoder =  'https://tfhub.dev/jeongukjae/distilbert_multi_cased_L-6_H-768_A-12/1'\n","\n","if debug:\n","  print('BERT model name                    : ', bert_model_name)\n","  print('BERT model selected                : ', tfhub_handle_encoder)\n","  print('BERT preprocess                    : ', tfhub_handle_preprocess)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fodDcY6sm392","executionInfo":{"status":"ok","timestamp":1680176340911,"user_tz":-120,"elapsed":14,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}},"outputId":"5b50078e-1778-4a78-9182-8ae072bc115a"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["BERT model name                    :  distilbert_multi_cased_L-6_H-768_A-12/1\n","BERT model selected                :  https://tfhub.dev/jeongukjae/distilbert_multi_cased_L-6_H-768_A-12/1\n","BERT preprocess                    :  https://tfhub.dev/jeongukjae/distilbert_multi_cased_preprocess/2\n"]}]},{"cell_type":"markdown","source":["## DATASET"],"metadata":{"id":"5DPeN9Vanbvv"}},{"cell_type":"markdown","source":["### Caricamento Dati"],"metadata":{"id":"LU7AorKXT8K7"}},{"cell_type":"code","source":["def preprocess_sentence(w):\n","  '''\n","  Preprocessing dei testi di input, impostando tutti i caratteri\n","  minuscoli, aggiungendo uno spazio prima di ogni punto e sostituendo\n","  qualsiasi carattere con uno spazio se non è compreso nel seguente elenco:\n","  (a-z, A-Z, \".\", \"?\", \"!\", \",\", \"'\", \"’\")\n","  '''\n","  # inserimento di uno spazio tra ogni parola e il successivo punto,\n","  # punto esclamativo, punto interrogativo e virgola\n","  # esempio: \"ciao, come và?\" => \"ciao , come và ?\"\n","  w = re.sub(r\"([?.!,])\", r\" \\1 \", w) # inserimento di uno spazio\n","\n","  # sostituzione dei caratteri apostrofo\n","  w = re.sub(r\"([’]+)\", \"'\", w)\n","\n","  w = w.replace(\"á\", \"à\")\n","  w = w.replace(\"é\", \"è\")\n","  w = w.replace(\"í\", \"ì\")\n","  w = w.replace(\"ó\", \"ò\")\n","  w = w.replace(\"ú\", \"ù\")\n","  w = w.replace('\"', \" \")\n","  w = w.replace(':', \" \")\n","  w = w.replace('«', \" \")\n","  w = w.replace('»', \" \")\n","  w = w.replace('‘', \" \")\n","  w = w.replace('-', \" \")\n","  w = w.replace('[', \" \")\n","  w = w.replace(']', \" \")\n","  w = w.replace('(', \" \")\n","  w = w.replace(')', \" \")\n","  w = w.replace(\"•\", \" \")\n","  w = w.replace(\"..\", \".\")\n","  w = w.replace(\"...\", \".\")\n","  w = w.replace(\"\\xa0\", \" \")\n","  w = w.replace(\"\\xc3\\xa8\", \" \")\n","  w = w.replace(\"\\xe2\\x80\\xaf\", \" \")\n","  w = w.replace(\"   \", \" \")\n","  w = w.replace(\"–\", \" \")\n","  w = w.replace(\"“\", \" \")\n","  w = w.replace(\"”\", \" \")\n","  w = w.replace(\"„\", \" \")\n","  w = w.replace(\"─\", \" \")\n","  w = w.replace(\"♪\", \" \")\n","  w = w.replace(\"#\", \" \")\n","  w = w.replace(\"/\", \" \")\n","  w = w.replace(\"=\", \" \")\n","  w = w.replace(\">\", \" \")\n","  w = w.replace(\"\\\\\", \" \")\n","  w = w.replace(\"`\", \" \")\n","  w = w.replace(\"¡\", \" \")\n","  w = w.replace(\"¿\", \" \")\n","  w = w.replace(\"œ\", \" \")\n","  w = w.replace(\"♗\", \" \")\n","  w = w.replace(\"♘\", \" \")\n","  w = w.replace(\"《\", \" \")\n","  w = w.replace(\"》\", \" \")\n","  # w = w.replace(\"\", \" \")\n","  # w = w.replace(\"\", \" \")\n","\n","  # inserimento di uno spazio dopo apostrofo\n","  w = re.sub(r\"(['])\", r\"\\1 \", w) \n","\n","  w = w.replace(\" ' \", \" '\")\n","\n","  w = re.sub(r'[\" \"]+', \" \", w) # rimozione di più spazi consecutivi\n","  return w"],"metadata":{"id":"Jm_Up6gyOTgW","executionInfo":{"status":"ok","timestamp":1680176340912,"user_tz":-120,"elapsed":11,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["df = pd.read_csv(\n","  train_data_filenamepath,\n","  usecols=[ORIGINAL_COLUMN, TRANSLATE_COLUMN, TYPE_COLUMN],\n",")\n","\n","# Preprocessing dei dati di Input\n","df[ORIGINAL_COLUMN] = df[ORIGINAL_COLUMN].apply(lambda x : preprocess_sentence(x))\n","\n","# Preprocessing dei dati Target con aggiunta del token di fine frase\n","df[TRANSLATE_COLUMN] = df[TRANSLATE_COLUMN].apply(lambda x : preprocess_sentence(x))\n","\n","if debug:\n","  print(f'Dati totali presenti nel Dataset               : {len(df)}')\n","  print('----------------------------------- TRAIN SET -----------------------------------------')\n","  print((df[ORIGINAL_COLUMN].tolist())[-1:])\n","  print((df[TRANSLATE_COLUMN].tolist())[-1:])\n","  print((df[ORIGINAL_COLUMN].tolist())[:1])\n","  print((df[TRANSLATE_COLUMN].tolist())[:1])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"duGPhZ_jgPVI","executionInfo":{"status":"ok","timestamp":1680176383804,"user_tz":-120,"elapsed":42903,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}},"outputId":"2b44ca9d-1334-4adc-dd59-59ce1773c6fe"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Dati totali presenti nel Dataset               : 379582\n","----------------------------------- TRAIN SET -----------------------------------------\n","['Min önskan och vilja styrdes av gudomlig kärlek som driver solen och andra stjärnor framåt som ett hjul flyttade regelbundet . ']\n","[\" ma già volgeva il mio disio e 'l velle , sì come rota ch' igualmente è mossa , l' amor che move il sole e l' altre stelle\"]\n","[\"De même que , en temps de guerre , officiers et soldats se sentent autorisès par l' opinion gènèrale à commettre des actes qui , en temps de paix , sont tenus pour criminels , de même les rèvolutionnaires , dans leur lutte , se regardaient comme couverts par l' opinion de leur cercle , en vertu de laquelle les actes de cruautè qu' ils commettaient ètaient nobles et moraux , ètant commis par eux au prix de leur libertè , de leur vie , de tout ce qui est cher à la plupart des hommes . Ainsi s' expliquait , que des personnes excellentes , incapables non seulement de causer une souffrance , mais même d' en supporter la vue , pussent se prèparer tranquillement à la violence et au meurtre , et professer la saintetè de tels actes , considèrès comme moyens de dèfense , ou encore comme instrument utile à la rèalisation d' un idèal de bonheur pour l' humanitè . \"]\n","[\"Così come in tempo di guerra , ufficiali e soldati si sentono responsabilizzati dall' opinione generale a commettere atti che , in tempo di pace , sono necessari per i criminali , anche rivoluzionari nella loro lotta , considerati coperti dal parere del loro circolo , secondo cui gli atti di crudeltà che hanno commesso erano nobili e morali , essendo commessi da loro nel prezzo della loro libertà , della loro vita , di tutto ciò che è caro alla maggior parte degli uomini . Ciò ha spiegato che persone eccellenti , in grado non solo di causare sofferenza , ma anche di sopportarne la vista , potrebbero felicemente prepararsi alla violenza e all' omicidio , e professare la santità di tali atti , considerati come un mezzo di difesa , o come utili per la realizzazione di un ideale di felicità per l' umanità . \"]\n"]}]},{"cell_type":"markdown","source":["## Tokenizer\n","\n","Creo due differenti tokenizer che mi servizranno per la predisposizione dei dati di input:\n","\n","\n","*   EncTokenizer classe custom per la tokenizzazione dei dati di input al Layer di Encoder di Bert\n","*   DecTokenizer classe custom per la tokenizzazione dei dati di input al Layer di Decoder\n","\n"],"metadata":{"id":"njyY9RWlFMWu"}},{"cell_type":"code","source":["input_data_vocab = df[ORIGINAL_COLUMN].tolist()\n","target_data_vocab = df[TRANSLATE_COLUMN].tolist()\n","\n","dataset = tf.data.Dataset.from_tensor_slices((input_data_vocab, target_data_vocab))\n","dataset = dataset.shuffle(len(input_data_vocab)).batch(BATCH_SIZE, drop_remainder=True)\n","\n","train_multilingual = dataset.map(lambda multilingual, ita: multilingual)\n","train_ita = dataset.map(lambda multilingual, ita: ita)"],"metadata":{"id":"fUG1fTAYekOy","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1680176387263,"user_tz":-120,"elapsed":3464,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}},"outputId":"bee8a1f7-539f-4979-ffa0-09a29f453f85"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/tensorflow/python/data/ops/structured_function.py:256: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n","  warnings.warn(\n"]}]},{"cell_type":"code","source":["def write_vocab_file(filepath, vocab):\n","  with open(filepath, 'w') as f:\n","    for token in vocab:\n","      print(token, file=f)"],"metadata":{"id":"xWO-LrXJe0cF","executionInfo":{"status":"ok","timestamp":1680176387264,"user_tz":-120,"elapsed":19,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["def cleanup_text(reserved_tokens, token_txt):\n","\n","  # Drop the reserved tokens, except for \"[UNK]\".\n","  bad_tokens = [re.escape(tok) for tok in reserved_tokens if tok != \"[UNK]\"]\n","  bad_token_re = \"|\".join(bad_tokens)\n","\n","  bad_cells = tf.strings.regex_full_match(token_txt, bad_token_re)\n","  result = tf.ragged.boolean_mask(token_txt, ~bad_cells)\n","\n","  # Join them into strings.\n","  result = tf.strings.reduce_join(result, separator=' ', axis=-1)\n","\n","  return result"],"metadata":{"id":"yGdsrOoKiYUK","executionInfo":{"status":"ok","timestamp":1680176387264,"user_tz":-120,"elapsed":18,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["tokenizers = tf.Module()"],"metadata":{"id":"qbKNS_uQhHLz","executionInfo":{"status":"ok","timestamp":1680176387265,"user_tz":-120,"elapsed":19,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}}},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":["### Classe EncTokenizer\n","\n","Classe custom per la tokenizzazione dei dati di italiano e che crea i tre vettori necessari al layer di Encoder \n","Bert:\n","\n","\n","*   input_word_ids\n","*   input_type_ids\n","*   input_mask\n","\n","\n","\n"],"metadata":{"id":"0KUcCnjXVjt3"}},{"cell_type":"code","source":["bert_tokenizer_params=dict(lower_case=True)\n","reserved_tokens = {\n","  'start_of_sequence_id': 101,\n","  'end_of_segment_id': 102,\n","  'padding_id': 0,\n","  'mask_id': 103\n","}\n","\n","bert_vocab_args = dict(\n","  # The target vocabulary size\n","  vocab_size = MAX_VOCAB_SIZE,\n","  # Reserved tokens that must be included in the vocabulary\n","  reserved_tokens=reserved_tokens,\n","  # Arguments for `text.BertTokenizer`\n","  bert_tokenizer_params=bert_tokenizer_params,\n","  # Arguments for `wordpiece_vocab.wordpiece_tokenizer_learner_lib.learn`\n","  learn_params={},\n",")"],"metadata":{"id":"Yr0izOZLembx","executionInfo":{"status":"ok","timestamp":1680176387265,"user_tz":-120,"elapsed":18,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["exist_vocab = Path(multilingual_vocab_filenamepath)\n","\n","if not exist_vocab.exists():\n","  multilingual_vocab = bert_vocab.bert_vocab_from_dataset(\n","      train_multilingual.batch(MAX_VOCAB_SIZE).prefetch(tf.data.AUTOTUNE),\n","      **bert_vocab_args\n","  )\n","\n","  write_vocab_file(multilingual_vocab_filenamepath, multilingual_vocab)"],"metadata":{"id":"BwSKtlLSe7bH","executionInfo":{"status":"ok","timestamp":1680176387683,"user_tz":-120,"elapsed":436,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["class EncTokenizer(tf.Module):\n","  def __init__(self, tfhub_handle_preprocess):\n","    self.preprocessor = hub.KerasLayer(tfhub_handle_preprocess)\n","    \n","  @tf.function\n","  def tokenize(self, strings):\n","    return self.preprocessor(strings)"],"metadata":{"id":"WmsNdDLNf6vr","executionInfo":{"status":"ok","timestamp":1680176387684,"user_tz":-120,"elapsed":7,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["tokenizers.multilingual = EncTokenizer(tfhub_handle_preprocess)"],"metadata":{"id":"-4B-HWWcmsmz","executionInfo":{"status":"ok","timestamp":1680176400879,"user_tz":-120,"elapsed":13201,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}}},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":["### Classe DecTokenizer\n","\n","Classe custom per la tokenizzazione dei dati in lingua italiana per il layer di Decoder\n"],"metadata":{"id":"mICEGEzJVnvx"}},{"cell_type":"code","source":["bert_tokenizer_params=dict(lower_case=True)\n","reserved_tokens_vocab=[\"[PAD]\", \"[UNK]\", \"[START]\", \"[END]\"]\n","\n","bert_vocab_args = dict(\n","  # The target vocabulary size\n","  vocab_size = MAX_VOCAB_SIZE,\n","  # Reserved tokens that must be included in the vocabulary\n","  reserved_tokens=reserved_tokens_vocab,\n","  # Arguments for `text.BertTokenizer`\n","  bert_tokenizer_params=bert_tokenizer_params,\n","  # Arguments for `wordpiece_vocab.wordpiece_tokenizer_learner_lib.learn`\n","  learn_params={},\n",")"],"metadata":{"id":"abBEnJJGV0AD","executionInfo":{"status":"ok","timestamp":1680176400881,"user_tz":-120,"elapsed":46,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["exist_vocab = Path(ita_vocab_filenamepath)\n","\n","if not exist_vocab.exists():\n","  ita_vocab = bert_vocab.bert_vocab_from_dataset(\n","      train_ita.batch(MAX_VOCAB_SIZE).prefetch(tf.data.AUTOTUNE),\n","      **bert_vocab_args\n","  )\n","\n","  write_vocab_file(ita_vocab_filenamepath, ita_vocab)"],"metadata":{"id":"dGsP1V4nVz6S","executionInfo":{"status":"ok","timestamp":1680176400882,"user_tz":-120,"elapsed":45,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["START = tf.argmax(tf.constant(reserved_tokens_vocab) == \"[START]\")\n","END = tf.argmax(tf.constant(reserved_tokens_vocab) == \"[END]\")\n","\n","def add_start_end(ragged):\n","  count = ragged.bounding_shape(out_type=tf.int32)[0]\n","\n","  starts = tf.fill([count,1], START)\n","  starts = tf.cast(starts, tf.int32)\n","\n","  ends = tf.fill([count,1], END)\n","  ends = tf.cast(ends, tf.int32)\n","\n","  x = tf.concat([starts, ragged, ends], axis=1)\n","  return x"],"metadata":{"id":"BeaD2-uLWT50","executionInfo":{"status":"ok","timestamp":1680176400883,"user_tz":-120,"elapsed":44,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["class DecTokenizer(tf.Module):\n","  def __init__(self, reserved_tokens_vocab, vocab_path):\n","    self.tokenizer = text.BertTokenizer(vocab_path, lower_case=True, token_out_type=tf.int32)\n","    self._reserved_tokens_vocab = reserved_tokens_vocab\n","    self._vocab_path = tf.saved_model.Asset(vocab_path)\n","\n","    vocab = pathlib.Path(vocab_path).read_text().splitlines()\n","    self.vocab = tf.Variable(vocab)\n","\n","    ## Create the signatures for export:   \n","\n","    # Include a tokenize signature for a batch of strings. \n","    self.tokenize.get_concrete_function(\n","        tf.TensorSpec(shape=[None], dtype=tf.string))\n","    \n","    # Include `detokenize` and `lookup` signatures for:\n","    #   * `Tensors` with shapes [tokens] and [batch, tokens]\n","    #   * `RaggedTensors` with shape [batch, tokens]\n","    self.detokenize.get_concrete_function(\n","        tf.TensorSpec(shape=[None, None], dtype=tf.int32))\n","    self.detokenize.get_concrete_function(\n","          tf.RaggedTensorSpec(shape=[None, None], dtype=tf.int32))\n","\n","    self.lookup.get_concrete_function(\n","        tf.TensorSpec(shape=[None, None], dtype=tf.int32))\n","    self.lookup.get_concrete_function(\n","          tf.RaggedTensorSpec(shape=[None, None], dtype=tf.int32))\n","\n","    # These `get_*` methods take no arguments\n","    self.get_vocab_size.get_concrete_function()\n","    self.get_vocab_path.get_concrete_function()\n","    self.get_reserved_tokens.get_concrete_function()\n","    \n","  @tf.function\n","  def tokenize(self, strings):\n","    enc = self.tokenizer.tokenize(strings)\n","    # Merge the `word` and `word-piece` axes.\n","    enc = enc.merge_dims(-2,-1)\n","    enc = add_start_end(enc)\n","    return enc\n","\n","  @tf.function\n","  def detokenize(self, tokenized):\n","    words = self.tokenizer.detokenize(tokenized)\n","    return cleanup_text(self._reserved_tokens_vocab, words)\n","\n","  @tf.function\n","  def lookup(self, token_ids):\n","    return tf.gather(self.vocab, token_ids)\n","\n","  @tf.function\n","  def get_vocab_size(self):\n","    return tf.shape(self.vocab)[0]\n","\n","  @tf.function\n","  def get_vocab_path(self):\n","    return self._vocab_path\n","\n","  @tf.function\n","  def get_reserved_tokens(self):\n","    return tf.constant(self._reserved_tokens_vocab)"],"metadata":{"id":"iaAW-xm5WT1_","executionInfo":{"status":"ok","timestamp":1680176400884,"user_tz":-120,"elapsed":44,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["tokenizers.ita = DecTokenizer(reserved_tokens_vocab, ita_vocab_filenamepath)"],"metadata":{"id":"svlLobM4WTzC","executionInfo":{"status":"ok","timestamp":1680176406134,"user_tz":-120,"elapsed":5293,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}}},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":["### Analisi Dati Tokenizzati"],"metadata":{"id":"pKZxiQ5_Whmw"}},{"cell_type":"code","source":["print(f'Vocabolario Italiano : {tokenizers.ita.get_vocab_size()}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Jrg6TwQzW5LN","executionInfo":{"status":"ok","timestamp":1680176406134,"user_tz":-120,"elapsed":24,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}},"outputId":"21233984-1484-4e7e-b3fb-fa26dbef2316"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["Vocabolario Italiano : 23120\n"]}]},{"cell_type":"markdown","source":["## Creazione dataset\n","Utilizzo della libreria tf.data per la gestione del dataset da utilizzare.\n","Verranno creati batch di esempi che verranno utilizzati durante l'addestramento."],"metadata":{"id":"5QIDajkEsVU1"}},{"cell_type":"code","source":["def split_dataset(df: pd.DataFrame,\n","                  filter_column: str, \n","                  debug: bool = False) -> Tuple:\n","\n","  print(f'Lunghezza df {len(df)}')\n","  dataset = (df.loc[df[TYPE_COLUMN] == filter_column]).copy() \n","  print(f'Lunghezza dataset {len(dataset)}')\n","  \n","  if NUM_SAMPLES > 0:\n","    dataset = dataset[:NUM_SAMPLES]\n","\n","  input_data = dataset[ORIGINAL_COLUMN].tolist()\n","  target_data = dataset[TRANSLATE_COLUMN].tolist()\n","\n","  train_input_data, validation_input_data, train_target_data, validation_target_data = train_test_split(\n","    input_data[:-TEST], \n","    target_data[:-TEST], \n","    test_size=TEST_SIZE, \n","    random_state=42,\n","    shuffle=True\n","  ) \n","\n","  train_input_data = train_input_data[:(int((len(train_input_data) / BATCH_SIZE)) * BATCH_SIZE)]\n","  train_target_data = train_target_data[:(int((len(train_target_data) / BATCH_SIZE)) * BATCH_SIZE)]\n","  \n","  validation_input_data = validation_input_data[:(int((len(validation_input_data) / BATCH_SIZE)) * BATCH_SIZE)]\n","  validation_target_data = validation_target_data[:(int((len(validation_target_data) / BATCH_SIZE)) * BATCH_SIZE)]\n","\n","  test_input_data = input_data[len(train_input_data)+len(validation_input_data):]\n","  test_target_data = target_data[len(train_target_data)+len(validation_target_data):]\n","\n","  if debug:\n","    print(f'Dati totali presenti nel Dataset               : {len(df)}')\n","    print(f'Dati totali presenti nel Dataset di Train      : {len(train_input_data)}')\n","    print(f'Dati totali presenti nel Dataset di Validation : {len(validation_input_data)}')\n","    print(f'Dati totali presenti nel Dataset di Test       : {len(test_input_data)}\\n')\n","\n","\n","    print('----------------------------------- TRAIN SET -----------------------------------------')\n","    print(train_input_data[-4:])\n","    print(train_target_data[-4:])\n","    print('--------------------------------- VALIDATION SET --------------------------------------')\n","    print(validation_input_data[-4:])\n","    print(validation_target_data[-4:])\n","    print('----------------------------------- TEST SET ------------------------------------------')\n","    print(test_input_data[-4:])\n","    print(test_target_data[-4:])\n","\n","    print('-------------------------------- ANALISI DATI -----------------------------------------')\n","    print(f'Esempi nel Dataset di Train                            : {len(train_input_data)}')\n","    print(f'Frase più corta nel Dataset Input di Train             : {min(train_input_data, key = len)}')\n","    print(f'Frase più corta nel Dataset Target di Train            : {min(train_target_data, key = len)}')\n","    print(f'Frase più lunga nel Dataset Input di Train             : {max(train_input_data, key = len)}')\n","    print(f'Frase più lunga nel Dataset Target di Train            : {max(train_target_data, key = len)}')\n","    print('---------------------------------------------------------------------------------------')\n","    print(f'Esempi nel Dataset di Validation                       : {len(validation_input_data)}')\n","    print(f'Frase più corta nel Dataset Input di Validation        : {min(validation_input_data, key = len)}')\n","    print(f'Frase più corta nel Dataset Target di Validation       : {min(validation_target_data, key = len)}')\n","    print(f'Frase più lunga nel Dataset Input di Validation        : {max(validation_input_data, key = len)}')\n","    print(f'Frase più lunga nel Dataset Target di Validation       : {max(validation_target_data, key = len)}')\n","    print('---------------------------------------------------------------------------------------')\n","    print(f'Esempi nel Dataset di Test                             : {len(test_input_data)}')\n","    print(f'Frase più corta nel Dataset Input di Test              : {min(test_input_data, key = len)}')\n","    print(f'Frase più corta nel Dataset Target di Test             : {min(test_target_data, key = len)}')\n","    print(f'Frase più lunga nel Dataset Input di Test              : {max(test_input_data, key = len)}')\n","    print(f'Frase più lunga nel Dataset Target di Test             : {max(test_target_data, key = len)}')    \n","\n","    print('\\n--------------------------------- EXAMPLE ---------------------------------------------')\n","    print([min(train_input_data, key = len)])\n","    print(tokenizers.multilingual.tokenize([min(train_input_data, key = len)])['input_word_ids'][:, :32])\n","    print('------------------------------------------------------------------')\n","    print([min(train_target_data, key = len)])\n","    print(tokenizers.ita.tokenize([min(train_target_data, key = len)]))\n","    print('\\n')\n","    print([max(train_input_data, key = len)])\n","    print(tokenizers.multilingual.tokenize([max(train_input_data, key = len)])['input_word_ids'])\n","    print('------------------------------------------------------------------')\n","    print([max(train_target_data, key = len)])\n","    print(tokenizers.ita.tokenize([max(train_target_data, key = len)]))  \n","  \n","  return train_input_data, validation_input_data, test_input_data, train_target_data, validation_target_data, test_target_data "],"metadata":{"id":"ESHUcQtthhd2","executionInfo":{"status":"ok","timestamp":1680176406135,"user_tz":-120,"elapsed":22,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","source":["def prepare_batch(multilingual, ita):\n","  zero = tf.zeros([BATCH_SIZE, MAX_SEQ_LENGTH], tf.int32)\n","\n","  # Tokenizzo l'input per l'Encoder\n","  encoder = tokenizers.multilingual.tokenize(multilingual)          \n","\n","  # Tokenizzo l'input per il Decder e creo la variabile Target\n","  ita = tokenizers.ita.tokenize(ita)\n","  decoder = ita[:, :-1].to_tensor()  # Drop the [END] tokens\n","  target = ita[:, 1:].to_tensor()   # Drop the [START] tokens\n","  \n","  decoder = tf.concat([decoder, zero], 1)\n","  decoder = decoder[:, :(MAX_SEQ_LENGTH)]\n","\n","  target = tf.concat([target, zero], 1)\n","  target = target[:, :(MAX_SEQ_LENGTH)]\n","\n","  return (encoder, decoder), target"],"metadata":{"id":"ccH3jHoABPzV","executionInfo":{"status":"ok","timestamp":1680176406135,"user_tz":-120,"elapsed":21,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}}},"execution_count":26,"outputs":[]},{"cell_type":"code","source":["def make_batches(ds):\n","  return (\n","    ds\n","    .shuffle(BUFFER_SIZE)\n","    .batch(BATCH_SIZE)\n","    .map(prepare_batch, tf.data.AUTOTUNE)\n","    .prefetch(buffer_size=tf.data.AUTOTUNE))"],"metadata":{"id":"l_dswlCiBTdR","executionInfo":{"status":"ok","timestamp":1680176406136,"user_tz":-120,"elapsed":22,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}}},"execution_count":27,"outputs":[]},{"cell_type":"code","source":["def train_val_test_dataset(df: pd.DataFrame, \n","                          filter_column: str, \n","                          debug: bool = False) -> Tuple:\n","\n","  # Recupero il dataset \n","  train_input_data, validation_input_data, test_input_data, train_target_data, validation_target_data, test_target_data = split_dataset(df=df, filter_column=filter_column, debug=debug)\n","\n","  # Definizione del dataset\n","  # [from_tensor_slices] permette di recuperare batch\n","  # di esempi dai dataset di riferimento\n","  train_dataset = tf.data.Dataset.from_tensor_slices((train_input_data, train_target_data))\n","  validation_dataset = tf.data.Dataset.from_tensor_slices((validation_input_data, validation_target_data))\n","  test_dataset = tf.data.Dataset.from_tensor_slices((test_input_data, test_target_data))\n","\n","  # impostazione del recupero di esempi presi in maniera\n","  # casuale in gruppi di [BATCH_SIZE] tra quelli disponibili\n","  train_dataset = make_batches(train_dataset)\n","  validation_dataset = make_batches(validation_dataset)\n","\n","  return train_dataset, validation_dataset, test_dataset"],"metadata":{"id":"tktJ5YuIsYe3","executionInfo":{"status":"ok","timestamp":1680176406136,"user_tz":-120,"elapsed":21,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}}},"execution_count":28,"outputs":[]},{"cell_type":"code","source":["train_dataset_ita, validation_dataset_ita, test_dataset = train_val_test_dataset(df=df,\n","                                                                                 filter_column='ITA',\n","                                                                                 debug=debug)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nkcyLV1qqQHL","executionInfo":{"status":"ok","timestamp":1680176411528,"user_tz":-120,"elapsed":5413,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}},"outputId":"3d69d9c9-0226-4e62-9222-dff95013dbeb"},"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["Lunghezza df 379582\n","Lunghezza dataset 244398\n","Dati totali presenti nel Dataset               : 379582\n","Dati totali presenti nel Dataset di Train      : 17344\n","Dati totali presenti nel Dataset di Validation : 7424\n","Dati totali presenti nel Dataset di Test       : 232\n","\n","----------------------------------- TRAIN SET -----------------------------------------\n","[\"C' est le braquage de banque le plus sanglant qu' a connu ce pays . \", \"Il s' est converti au christianisme . \", 'Vous pouvez ècrire dans la langue que vous voulez . Sur Tatoeba , toutes les langues sont ègales . ', 'Elle a trois s urs une est infirmière et les autres sont enseignantes . ']\n","['È la rapina in banca più sanguinosa della storia di questo paese . ', 'Si è convertito al Cristianesimo . ', 'Puoi scrivere in qualsiasi lingua desideri . Su Tatoeba tutte le lingue sono uguali . ', 'Lei ha tre sorelle una è infermiera e le altre sono insegnanti . ']\n","--------------------------------- VALIDATION SET --------------------------------------\n","['Pourquoi la chance vous haït elle ? ', \"Le gouvernement des États Unis a taxè plusieurs pays d' États voyous , mais l' ironie du sort est qu' aujourd' hui , et après des dècennies de politiques agressives , d' interventions et d' invasions , ce sont les États Unis eux mêmes qui sont considèrès , dans le monde , comme l' État voyou par excellence . \", \"Je m' inquiète des rèsultats de l' examen . \", 'Vous allez marcher tous les matins . ']\n","['Perchè la fortuna vi odia ? ', \"Il governo americano ha tacciato diversi paesi come Stati canaglia , ma l' ironia è che oggi , dopo decenni di politiche aggressive , interventi e invasioni , sono gli Stati Uniti sono considerati in tutto il mondo come lo Stato canaglia per eccellenza . \", \"Mi preoccupo per i risultati dell' esame . \", 'Va a camminare ogni mattina . ']\n","----------------------------------- TEST SET ------------------------------------------\n","['Je ne vois aucun problème avec ça . ', 'Vous devez travailler , pas penser . ', \"Tatoeba n' est pas un dictionnaire . \", \"L' orthographe est très importante . \"]\n","['Non vedo dove stia il problema . ', 'Dovete lavorare , non pensare . ', 'Tatoeba non è un dizionario . ', \"L' ortografia è molto importante . \"]\n","-------------------------------- ANALISI DATI -----------------------------------------\n","Esempi nel Dataset di Train                            : 17344\n","Frase più corta nel Dataset Input di Train             :  Veux tu l' acheter ? Oui . \n","Frase più corta nel Dataset Target di Train            : Oggi offro io . \n","Frase più lunga nel Dataset Input di Train             : De même que , en temps de guerre , officiers et soldats se sentent autorisès par l' opinion gènèrale à commettre des actes qui , en temps de paix , sont tenus pour criminels , de même les rèvolutionnaires , dans leur lutte , se regardaient comme couverts par l' opinion de leur cercle , en vertu de laquelle les actes de cruautè qu' ils commettaient ètaient nobles et moraux , ètant commis par eux au prix de leur libertè , de leur vie , de tout ce qui est cher à la plupart des hommes . Ainsi s' expliquait , que des personnes excellentes , incapables non seulement de causer une souffrance , mais même d' en supporter la vue , pussent se prèparer tranquillement à la violence et au meurtre , et professer la saintetè de tels actes , considèrès comme moyens de dèfense , ou encore comme instrument utile à la rèalisation d' un idèal de bonheur pour l' humanitè . \n","Frase più lunga nel Dataset Target di Train            : Così come in tempo di guerra , ufficiali e soldati si sentono responsabilizzati dall' opinione generale a commettere atti che , in tempo di pace , sono necessari per i criminali , anche rivoluzionari nella loro lotta , considerati coperti dal parere del loro circolo , secondo cui gli atti di crudeltà che hanno commesso erano nobili e morali , essendo commessi da loro nel prezzo della loro libertà , della loro vita , di tutto ciò che è caro alla maggior parte degli uomini . Ciò ha spiegato che persone eccellenti , in grado non solo di causare sofferenza , ma anche di sopportarne la vista , potrebbero felicemente prepararsi alla violenza e all' omicidio , e professare la santità di tali atti , considerati come un mezzo di difesa , o come utili per la realizzazione di un ideale di felicità per l' umanità . \n","---------------------------------------------------------------------------------------\n","Esempi nel Dataset di Validation                       : 7424\n","Frase più corta nel Dataset Input di Validation        :  Veux tu l' acheter ? Oui . \n","Frase più corta nel Dataset Target di Validation       : Vuoi farlo ora ? \n","Frase più lunga nel Dataset Input di Validation        : Les États Unis ont plusieurs fois justifiè des interventions dans d' autres pays au nom de la protection des sacro saints intèrêts amèricains ou des citoyens amèricains à travers le monde . Le jour où , en 2008 , la Gèorgie avait attaquè des civils et des militaires russes en Ossètie du Sud , les Russes sont ègalement intervenus pour la protection lègitime de ses citoyens et militaires qui n' ètaient pas seulement victimes d' une attaque , mais d' un massacre . Mais lorsque ce sont les autres pays qui dèfendent leurs intèrêts et leurs civils au delà de leurs frontières , ceci ne plaît èvidemment pas aux États Unis . \n","Frase più lunga nel Dataset Target di Validation       : Gli Stati Uniti hanno ripetutamente giustificato degli interventi in altri paesi in nome della tutela degli interessi sacrosanti americani o dei cittadini americani in tutto il mondo . Il giorno in cui , nel 2008 , la Georgia ha attaccato civili e soldati russi in Ossezia del Sud , i russi sono ugualmente intervenuti per la legittima tutela dei loro cittadini e soldati che non erano solo le vittime di un attacco , ma di un massacro . Ma quando gli altri paesi stanno difendendo i loro interessi e civili oltre i loro confini , questo ovviamente non piace agli Stati Uniti . \n","---------------------------------------------------------------------------------------\n","Esempi nel Dataset di Test                             : 232\n","Frase più corta nel Dataset Input di Test              :  J' aime voyager . Moi aussi . \n","Frase più corta nel Dataset Target di Test             : Oggi è venerdì . \n","Frase più lunga nel Dataset Input di Test              : L' un est rouge , l' autre est blanc . \n","Frase più lunga nel Dataset Target di Test             : Molte persone hanno partecipato alla riunione . \n","\n","--------------------------------- EXAMPLE ---------------------------------------------\n","[\" Veux tu l' acheter ? Oui . \"]\n","tf.Tensor(\n","[[  101 19561 11855 13055   180   112 33478 28647   136 47060 10116   119\n","    102     0     0     0     0     0     0     0     0     0     0     0\n","      0     0     0     0     0     0     0     0]], shape=(1, 32), dtype=int32)\n","------------------------------------------------------------------\n","['Oggi offro io . ']\n","<tf.RaggedTensor [[2, 260, 21120, 85, 11, 3]]>\n","\n","\n","[\"De même que , en temps de guerre , officiers et soldats se sentent autorisès par l' opinion gènèrale à commettre des actes qui , en temps de paix , sont tenus pour criminels , de même les rèvolutionnaires , dans leur lutte , se regardaient comme couverts par l' opinion de leur cercle , en vertu de laquelle les actes de cruautè qu' ils commettaient ètaient nobles et moraux , ètant commis par eux au prix de leur libertè , de leur vie , de tout ce qui est cher à la plupart des hommes . Ainsi s' expliquait , que des personnes excellentes , incapables non seulement de causer une souffrance , mais même d' en supporter la vue , pussent se prèparer tranquillement à la violence et au meurtre , et professer la saintetè de tels actes , considèrès comme moyens de dèfense , ou encore comme instrument utile à la rèalisation d' un idèal de bonheur pour l' humanitè . \"]\n","tf.Tensor(\n","[[   101  10190  11594  10121    117  10110  12358  10104  14158    117\n","   59973  10131  25734  10126  97705  10368  37882  10107  13230  10248\n","     180    112  32282    175  20276  37833  10284    254  10986  11527\n","   10246  10139  37481  10355    117  10110  12358  10104  41795    117\n","   10647  69323  10107  10322    171 102422  58798    117  10104  11594\n","   10152    186  13340  34381  30861  38260    117  10260  11807  43927\n","     117  10126  42047  32247  10986  11170  98095  10107  10248    180\n","     112  32282  10104  11807  57775    117  10110  20900  10138  10104\n","   20600  10152  37481  10104    171  60021  11159  13340  10608    112\n","   13178  10986  12201  15617    262  26812  11405  43657  10131  25528\n","   11855    117    262  19533  10212  15240  10248  22502  10257  18236\n","   10104  11807  72517  10123  13340    117  10104  11807  13772    117\n","   10104  13003  10794  10355  10176  10262  10129    102]], shape=(1, 128), dtype=int32)\n","------------------------------------------------------------------\n","[\"Così come in tempo di guerra , ufficiali e soldati si sentono responsabilizzati dall' opinione generale a commettere atti che , in tempo di pace , sono necessari per i criminali , anche rivoluzionari nella loro lotta , considerati coperti dal parere del loro circolo , secondo cui gli atti di crudeltà che hanno commesso erano nobili e morali , essendo commessi da loro nel prezzo della loro libertà , della loro vita , di tutto ciò che è caro alla maggior parte degli uomini . Ciò ha spiegato che persone eccellenti , in grado non solo di causare sofferenza , ma anche di sopportarne la vista , potrebbero felicemente prepararsi alla violenza e all' omicidio , e professare la santità di tali atti , considerati come un mezzo di difesa , o come utili per la realizzazione di un ideale di felicità per l' umanità . \"]\n","<tf.RaggedTensor [[2, 125, 99, 83, 172, 78, 575, 10, 11697, 5987, 31, 3991, 81, 5792, 6586,\n","  5661, 532, 8, 1488, 2750, 27, 6224, 1923, 76, 10, 83, 172, 78, 604, 10,\n","  91, 21111, 82, 35, 4450, 10, 281, 18720, 22435, 20890, 926, 206, 122,\n","  5619, 10, 11841, 6829, 158, 2737, 97, 122, 20964, 10, 409, 163, 128,\n","  1923, 78, 10810, 76, 134, 2985, 245, 10121, 31, 12939, 10, 3117, 11007,\n","  95, 122, 119, 1374, 141, 122, 1739, 10, 141, 122, 192, 10, 78, 130, 167,\n","  76, 31, 962, 153, 497, 189, 333, 708, 11, 167, 89, 4918, 76, 270, 20590,\n","  10, 83, 414, 79, 195, 78, 12719, 21200, 10, 104, 281, 78, 209, 20483,\n","  10185, 77, 329, 10, 10297, 417, 978, 11350, 153, 2474, 31, 229, 8, 2764,\n","  10, 31, 18116, 377, 77, 1241, 384, 78, 2481, 1923, 10, 11841, 99, 84,\n","  451, 78, 3976, 10, 41, 99, 6098, 82, 77, 13024, 78, 84, 7265, 78, 2322,\n","  82, 38, 8, 5381, 11, 3]]>\n"]}]},{"cell_type":"code","source":["# Recupero un batch di esempi per la verifica delle classi custom che andrò a creare\n","for (enc_input, dec_input), target in train_dataset_ita.take(1):\n","  print('----------------------- ENCODER  -------------------------------')\n","  print(f'Shape                    : {enc_input[\"input_word_ids\"].shape}')\n","  print(f'Word Ids                 : {enc_input[\"input_word_ids\"][0, :MAX_SEQ_LENGTH]}')\n","  print(f'Input Mask               : {enc_input[\"input_mask\"][0, :MAX_SEQ_LENGTH]}')\n","  print('--------------------- DECODER ----------------------------------')\n","  print(f'Shape it input           : {dec_input.shape}')\n","  print(f'Example it input         : {dec_input[0]}')  \n","  print('--------------------- TARGET -----------------------------------')\n","  print(f'Shape it input           : {target.shape}')\n","  print(f'Example it target        : {target[0]}')  "],"metadata":{"id":"VH_aKPlV_AWA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1680176414471,"user_tz":-120,"elapsed":2985,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}},"outputId":"b2cdeea8-6811-4074-9688-bbfa216fda49"},"execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["----------------------- ENCODER  -------------------------------\n","Shape                    : (32, 128)\n","Word Ids                 : [  101 52208 10830 34394 34595 10171 49641 10154   187   112 38425 14598\n","   119   102     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0]\n","Input Mask               : [1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n","--------------------- DECODER ----------------------------------\n","Shape it input           : (32, 128)\n","Example it input         : [   2  128 2670 1419  159  108   80  113  300   11    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0]\n","--------------------- TARGET -----------------------------------\n","Shape it input           : (32, 128)\n","Example it target        : [ 128 2670 1419  159  108   80  113  300   11    3    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0]\n"]}]},{"cell_type":"markdown","source":["## Encoder BERT\n","\n","Predispondo la classe necessaria per la costruzione di BERT\n"],"metadata":{"id":"8dtVuZGJpvXl"}},{"cell_type":"code","source":["embedding_dim = 32\n","\n","class MLPMixerLayer(tf.keras.layers.Layer):\n","  def __init__(self, num_patches, dropout_rate, *args, **kwargs):\n","    super().__init__(*args, **kwargs)\n","    print(f'num_patches {num_patches}')\n","    self.mlp = tf.keras.Sequential(\n","        [\n","            tf.keras.layers.Dense(units=num_patches, activation='relu'),\n","            tf.keras.layers.Dense(units=num_patches),\n","            tf.keras.layers.Dropout(rate=dropout_rate),\n","        ]\n","    )\n","    self.normalize = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n","\n","  def call(self, inputs):\n","    # Apply layer normalization.\n","    x = self.normalize(inputs)\n","    # Transpose inputs from [num_batches, num_patches, hidden_units] to [num_batches, hidden_units, num_patches].\n","    x_channels = tf.linalg.matrix_transpose(x)\n","    # Apply mlp on each channel independently.\n","    mlp_outputs = self.mlp(x_channels)\n","    # Transpose mlp_outputs from [num_batches, hidden_dim, num_patches] to [num_batches, num_patches, hidden_units].\n","    mlp_outputs = tf.linalg.matrix_transpose(mlp_outputs)\n","    return mlp_outputs"],"metadata":{"id":"L0OniBSyW-rF","executionInfo":{"status":"ok","timestamp":1680179738747,"user_tz":-120,"elapsed":510,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}}},"execution_count":71,"outputs":[]},{"cell_type":"code","source":["class EncoderBert(tf.keras.layers.Layer):\n","  def __init__(self, bert_encoder, embedding_dim, max_len, rate=0.5, trainable=False):\n","    super(EncoderBert, self).__init__()\n","\n","    self.encoder = hub.KerasLayer(bert_encoder, name='BERT_encoder', trainable=trainable)\n","\n","    self.conv_1 = tf.keras.layers.Conv1D(embedding_dim * 4, 1, activation='relu') \n","    self.conv_2 = tf.keras.layers.Conv1D(embedding_dim * 2, 1, activation='relu') \n","    self.conv_3 = tf.keras.layers.Conv1D(embedding_dim, 1, activation='relu') \n","    # self.lambda_layer = tf.keras.layers.Lambda(lambda x: x[:,:max_len])\n","    self.mlp_mixer = MLPMixerLayer(num_patches=embedding_dim // 4, dropout_rate=rate)\n","    self.max_len = max_len\n","\n","  def call(self, x, debug=False):\n","\n","    if debug:\n","      print(f'****************** DEBUG ENCODER BERT ******************')\n","      print(f\"First example\")\n","      print(f'Keys                         : {list(x.keys())}')\n","      print(f'Shape                        : {x[\"input_word_ids\"].shape}')\n","      print(f'Word Ids                     : {x[\"input_word_ids\"][0, :16]}')\n","      print(f'Input Mask                   : {x[\"input_mask\"][0, :16]}')\n","      \n","    x = self.encoder(x)['sequence_output'] \n","    # encoder_outputs stato intermedio di BERT prima che esegua la traduzione recuperare la metà della lunghezza\n","    # x = self.encoder(x)['encoder_outputs'] \n","    # x = x[int(len(x) / 2) - 1]\n","\n","    if debug:\n","      print()\n","      print(f'Encoder Outputs BERT Shape   : {x.shape}')\n","      print(f'Encoder Outputs BERT Values  : {x[0, :1, :16]}')\n","\n","    x = self.conv_1(x)\n","    if debug:\n","      print()\n","      print(f'Sequence Conv1 Shape         : {x.shape}')\n","\n","    x = self.conv_2(x)\n","    if debug:\n","      print(f'Sequence Conv2 Shape         : {x.shape}')\n","\n","    x = self.conv_3(x)\n","    if debug:\n","     print(f'Sequence Conv3 Shape          : {x.shape}')\n","      \n","    x = self.mlp_mixer(x)\n","    if debug:\n","      print(f'Sequence MLP-Mixer Shape     : {x.shape}')\n","      print()\n","      print(f'Sequence Outputs Values      : {x[0, 0, :16]}')      \n","      print('*********************************************************') \n","\n","    # x = self.lambda_layer(x)\n","    # if debug:\n","    #   print(f'Sequence Lambda Layer        : {x.shape}')\n","    #   print()\n","    #   print(f'Sequence Outputs Values      : {x[0, 0, :16]}')      \n","    #   print('*********************************************************') \n","\n","    return x"],"metadata":{"id":"m7v9Y-Lep4CD","executionInfo":{"status":"ok","timestamp":1680179800466,"user_tz":-120,"elapsed":402,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}}},"execution_count":75,"outputs":[]},{"cell_type":"code","source":["'''\n","128, 768 Bert\n","128, 128 conv1d\n","128, 128 Trasposto\n","128, 32 Dense\n","32, 128 Trasposto Uscita Bert Encoder\n","'''"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":53},"id":"E7YlC1JXPkYf","executionInfo":{"status":"ok","timestamp":1680179802727,"user_tz":-120,"elapsed":375,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}},"outputId":"0b8ad6a7-29f3-43be-cb2b-3cb8821394de"},"execution_count":76,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'\\n128, 768 Bert\\n128, 128 conv1d\\n128, 128 Trasposto\\n128, 32 Dense\\n32, 128 Trasposto Uscita Bert Encoder\\n'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":76}]},{"cell_type":"code","source":["encoder_bert = EncoderBert(bert_encoder=tfhub_handle_encoder, \n","                           embedding_dim=EMBEDDING_DIM, \n","                           max_len=MAX_SEQ_LENGTH,\n","                           rate=DROPUOT,\n","                           trainable=trainable)\n","\n","bert_outputs = encoder_bert(enc_input, debug) "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Q08luTkusEfn","executionInfo":{"status":"ok","timestamp":1680179818815,"user_tz":-120,"elapsed":16098,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}},"outputId":"0a9d9c09-cf3c-433e-8103-4e5232a42830"},"execution_count":77,"outputs":[{"output_type":"stream","name":"stdout","text":["num_patches 32\n","****************** DEBUG ENCODER BERT ******************\n","First example\n","Keys                         : ['input_word_ids', 'input_mask']\n","Shape                        : (32, 128)\n","Word Ids                     : [  101 52208 10830 34394 34595 10171 49641 10154   187   112 38425 14598\n","   119   102     0     0]\n","Input Mask                   : [1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0]\n","\n","Encoder Outputs BERT Shape   : (32, 128, 768)\n","Encoder Outputs BERT Values  : [[ 0.05340564 -0.00303204 -0.1578381   0.23718458 -0.10183904  0.11595948\n","  -0.10829279  0.00831296 -0.06592342  0.51070666  0.35922247 -0.24354595\n","  -0.07508986  0.12717839 -0.52456385  0.04772909]]\n","\n","Sequence Conv1 Shape         : (32, 128, 512)\n","Sequence Conv2 Shape         : (32, 128, 256)\n","Sequence Conv3 Shape          : (32, 128, 128)\n","Sequence MLP-Mixer Shape     : (32, 32, 128)\n","\n","Sequence Outputs Values      : [ 0.8292772   0.15414067  0.34332967  0.28950003  1.7654581   0.201365\n","  0.567627    0.21004419  0.60983044  0.21004419  0.21004419  0.21004419\n","  0.63928384 -0.36713088  0.5865338   0.44362423]\n","*********************************************************\n"]}]},{"cell_type":"code","source":["num_patches = 32\n","\n","bert_outputs = mlp_mixer(bert_outputs) "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"g-jNn4-jY0Vb","executionInfo":{"status":"ok","timestamp":1680178427005,"user_tz":-120,"elapsed":30,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}},"outputId":"d63550da-5a6b-44da-f7df-aa1a7d25b9e3"},"execution_count":46,"outputs":[{"output_type":"stream","name":"stdout","text":["inputs shape (32, 128, 256)\n","x shape (32, 128, 256)\n","x_channels shape (32, 256, 128)\n","mlp1_outputs shape (32, 256, 32)\n","mlp1_outputs shape (32, 32, 256)\n"]}]},{"cell_type":"markdown","source":["## Decoder\n","\n","Predispondo la classe necessaria per la costruzione di un Layer di Decoder"],"metadata":{"id":"ReEQ5rX7aGtl"}},{"cell_type":"markdown","source":["### TOKEN AND POSITION EMBEDDING\n","\n","Implementazione del blocco Embedding per l'utilizzo di vettori posizionali insieme ai vettori di token di parole tramite estensione della classe Layer di Keras. "],"metadata":{"id":"gAu1IXlRZzlq"}},{"cell_type":"code","source":["class TokenAndPositionEmbedding(tf.keras.layers.Layer):\n","  def __init__(self, maxlen, vocab_size, embed_dim):\n","    super(TokenAndPositionEmbedding, self).__init__()\n","    self.maxlen = maxlen\n","    self.token_emb = tf.keras.layers.Embedding(input_dim=vocab_size, output_dim=embed_dim)\n","    self.pos_emb = tf.keras.layers.Embedding(input_dim=maxlen, output_dim=embed_dim)\n","\n","  def call(self, x, debug=False):\n","    x = tf.keras.preprocessing.sequence.pad_sequences(x, maxlen=self.maxlen, padding='post')\n","    maxlen = tf.shape(x)[-1]\n","\n","    if debug:\n","      print('********** DEBUG TOKEN AND POSITION EMBEDDING ***********')\n","      print(f'Sequence Max len                          : {maxlen}')\n","      print(f'Sequence Shape                            : {tf.shape(x)}')\n","\n","    positions = tf.range(start=0, limit=maxlen, delta=1)\n","    positions = self.pos_emb(positions)\n","    x = self.token_emb(x)\n","    output = x + positions\n","\n","    if debug:\n","      print(f'Shape TokenAndPositionEmbedding           : {output.shape}')\n","      print('*********************************************************')\n","\n","    return output"],"metadata":{"id":"o9-RSKTqsmUC","executionInfo":{"status":"ok","timestamp":1680071156177,"user_tz":-120,"elapsed":33,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}}},"execution_count":33,"outputs":[]},{"cell_type":"code","source":["token_position_it = TokenAndPositionEmbedding(MAX_SEQ_LENGTH, tokenizers.ita.get_vocab_size(), EMBEDDING_DIM)\n","\n","inputs_decoder = token_position_it(dec_input, debug)"],"metadata":{"id":"rr_EWQUX8EWP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1680071156177,"user_tz":-120,"elapsed":30,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}},"outputId":"b5d1fb7e-7df1-4ce2-de05-e2001391a148"},"execution_count":34,"outputs":[{"output_type":"stream","name":"stdout","text":["********** DEBUG TOKEN AND POSITION EMBEDDING ***********\n","Sequence Max len                          : 128\n","Sequence Shape                            : [ 32 128]\n","Shape TokenAndPositionEmbedding           : (32, 128, 128)\n","*********************************************************\n"]}]},{"cell_type":"markdown","source":["### LAYER DECODER\n","\n","Implementazione di un blocco di DecoderTransformer tramite estensione della classe Layer di Keras"],"metadata":{"id":"XdLv-6nidKGK"}},{"cell_type":"markdown","source":["#### DecodeBert\n","\n","Implmentazione di un blocco di  decodifica custom per decodificare l'output dal layer EncoderBert prima di passarlo al Decoder del Transformer tramite estensione della classe Layer di Keras"],"metadata":{"id":"_iq7Y-d4eRd8"}},{"cell_type":"code","source":["class DecodeBert(tf.keras.layers.Layer):\n","  def __init__(self, max_len, embed_dim, num_heads, ff_dim, rate=0.5, name='DecodeBert'):\n","    super(DecodeBert, self).__init__()\n","    self.att = tf.keras.layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n","    self.ffn = tf.keras.Sequential(\n","      [tf.keras.layers.Dense(ff_dim, activation='relu'), \n","       tf.keras.layers.Dense(embed_dim),]\n","    )\n","    self.layernorm1 = tf.keras.layers.LayerNormalization()\n","    self.layernorm2 = tf.keras.layers.LayerNormalization()\n","    self.dropout1 = tf.keras.layers.Dropout(rate)\n","    self.dropout2 = tf.keras.layers.Dropout(rate)\n","    self._name = name\n","\n","  def call(self, bert_outputs, training=False, debug=False):\n","    attn_output = self.att(query=bert_outputs,\n","                           value=bert_outputs, \n","                           key=bert_outputs)\n","    \n","    attn_output = self.dropout1(attn_output)\n","    out1 = self.layernorm1(bert_outputs + attn_output)\n","\n","    ffn_output = self.ffn(out1)\n","    ffn_output = self.dropout2(ffn_output, training=training)\n","\n","    output = self.layernorm2(out1 + ffn_output)\n","\n","    if debug:\n","      print('********************* DEBUG DECODE-BERT *********************')\n","      print(f'Shape Input Layer Decode-Bert       : {bert_outputs.shape}')\n","      print(f'Shape Output Layer Decode-Bert      : {output.shape}')\n","      print('*********************************************************')\n","\n","    return output"],"metadata":{"id":"joTBTlWF8ETD","executionInfo":{"status":"ok","timestamp":1680071156178,"user_tz":-120,"elapsed":29,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}}},"execution_count":35,"outputs":[]},{"cell_type":"code","source":["encoder = DecodeBert(MAX_SEQ_LENGTH, \n","                  EMBEDDING_DIM, \n","                  NUM_HEADS, \n","                  FF_DIM, \n","                  DROPUOT)\n","\n","outputs_encoder = encoder(bert_outputs=bert_outputs,\n","                          training=training, \n","                          debug=debug)"],"metadata":{"id":"JaIzBxFCfKe9","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1680071157143,"user_tz":-120,"elapsed":992,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}},"outputId":"59ae83f8-b191-4738-8b5f-5c8810b525e7"},"execution_count":36,"outputs":[{"output_type":"stream","name":"stdout","text":["********************* DEBUG DECODE-BERT *********************\n","Shape Input Layer Decode-Bert       : (32, 128, 128)\n","Shape Output Layer Decode-Bert      : (32, 128, 128)\n","*********************************************************\n"]}]},{"cell_type":"markdown","source":["#### Layer Decoder"],"metadata":{"id":"dMTKLwd3dRw5"}},{"cell_type":"code","source":["class Decoder(tf.keras.layers.Layer):\n","  def __init__(self, max_len, embed_dim, num_heads, ff_dim, rate=0.5, name='DEC'):\n","    super(Decoder, self).__init__()\n","    self.decode_bert = DecodeBert(max_len=max_len, embed_dim=embed_dim, num_heads=num_heads, ff_dim=ff_dim, rate=rate)\n","    self.att1 = tf.keras.layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n","    self.att2 = tf.keras.layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n","    self.ffn = tf.keras.Sequential(\n","      [tf.keras.layers.Dense(ff_dim, activation='relu'), \n","       tf.keras.layers.Dense(embed_dim),]\n","    )\n","    self.layernorm1 = tf.keras.layers.LayerNormalization()\n","    self.layernorm2 = tf.keras.layers.LayerNormalization()\n","    self.layernorm3 = tf.keras.layers.LayerNormalization()\n","    self.dropout1 = tf.keras.layers.Dropout(rate)\n","    self.dropout2 = tf.keras.layers.Dropout(rate)\n","    self.dropout3 = tf.keras.layers.Dropout(rate)\n","    self._name = name\n","\n","  def call(self, inputs, bert_outputs, training=False, debug=False):\n","    attn_output1 = self.att1(query=inputs,\n","                             value=inputs, \n","                             key=inputs, \n","                             use_causal_mask=True)\n","    \n","    attn_output1 = self.dropout1(attn_output1)\n","    out1 = self.layernorm1(inputs + attn_output1)\n","\n","    dec_bert = self.decode_bert(bert_outputs=bert_outputs, training=training, debug=debug)\n","\n","    attn_output2 = self.att2(key=dec_bert, \n","                             value=dec_bert, \n","                             query=out1)\n","    \n","    attn_output2 = self.dropout2(attn_output2, training=training)\n","    out2 = self.layernorm2(out1 + attn_output2)\n","\n","    ffn_output = self.ffn(out2)\n","    ffn_output = self.dropout3(ffn_output, training=training)\n","\n","    output = self.layernorm3(out2 + ffn_output)\n","\n","    if debug:\n","      print('******************* DEBUG DECODER ***********************')\n","      print(f'Input Shape                       : {inputs.shape}')\n","      print(f'Shape Outputs Decoder             : {output.shape}')\n","      print('*********************************************************')\n","\n","    return output"],"metadata":{"id":"SO5rYsFpfFS_","executionInfo":{"status":"ok","timestamp":1680071157144,"user_tz":-120,"elapsed":12,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}}},"execution_count":37,"outputs":[]},{"cell_type":"code","source":["decoder = Decoder(MAX_SEQ_LENGTH, \n","                  EMBEDDING_DIM, \n","                  NUM_HEADS, \n","                  FF_DIM, \n","                  DROPUOT)\n","\n","outputs_decoder = decoder(inputs=inputs_decoder, \n","                          bert_outputs=bert_outputs,  \n","                          training=training,\n","                          debug=debug)"],"metadata":{"id":"yysVdkHH8EPH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1680071159617,"user_tz":-120,"elapsed":2483,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}},"outputId":"c382e366-1fed-4abd-d582-4b95adb551de"},"execution_count":38,"outputs":[{"output_type":"stream","name":"stdout","text":["********************* DEBUG DECODE-BERT *********************\n","Shape Input Layer Decode-Bert       : (32, 128, 128)\n","Shape Output Layer Decode-Bert      : (32, 128, 128)\n","*********************************************************\n","******************* DEBUG DECODER ***********************\n","Input Shape                       : (32, 128, 128)\n","Shape Outputs Decoder             : (32, 128, 128)\n","*********************************************************\n"]}]},{"cell_type":"markdown","source":["## TRANSFORMER\n","\n","Implementazione del blocco Transformer tramite estensione della classe Layer di Keras."],"metadata":{"id":"ne4zTOG_NKfV"}},{"cell_type":"code","execution_count":39,"metadata":{"pycharm":{"name":"#%%\n"},"id":"lw2xMCAMC_4M","executionInfo":{"status":"ok","timestamp":1680071159618,"user_tz":-120,"elapsed":5,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}}},"outputs":[],"source":["class TransformerBlock(tf.keras.Model):\n","  def __init__(self, \n","               num_layers, \n","               embed_dim, \n","               num_heads, \n","               ff_dim, \n","               max_len,\n","               vocab_size,\n","               tfhub_handle_encoder,\n","               trainable,\n","               rate=0.5):\n","    \n","    super(TransformerBlock, self).__init__()\n","\n","    self.num_layers = num_layers\n","\n","    self.token_pos_dec = TokenAndPositionEmbedding(max_len, vocab_size, embed_dim)\n","\n","    self.encoder = EncoderBert(tfhub_handle_encoder, embed_dim, max_len, trainable=trainable)\n","    self.decoder = [Decoder(max_len, embed_dim, num_heads, ff_dim, rate) for _ in range(num_layers)]\n","\n","    self.dropout = tf.keras.layers.Dropout(rate)\n","    self.final_layer = tf.keras.layers.Dense(vocab_size)\n","\n","  def call(self, inputs, training=False, debug=False):\n","    inputs_encoder, inputs_decoder  = inputs\n","\n","    encoder_output = self.encoder(inputs_encoder, debug) \n","\n","    inputs_decoder = self.token_pos_dec(inputs_decoder, debug)\n","\n","    if debug:\n","      print(f'---------------- DEBUG TRANSFORMER BLOCK ----------------')\n","      print(f'inputs_encoder       : {inputs_encoder[\"input_word_ids\"].shape}')\n","      print(f'inputs_decoder       : {inputs_decoder.shape}')      \n","\n","    transformer_output = inputs_decoder\n","      \n","    for i in range(self.num_layers):\n","      transformer_output = self.decoder[i](inputs=transformer_output, \n","                                           bert_outputs=encoder_output, \n","                                           training=training,\n","                                           debug=debug)\n","\n","    transformer_output = self.dropout(transformer_output)\n","    logits = self.final_layer(transformer_output)\n","\n","    if debug:\n","      print(f'Output Shape       : {logits.shape}')\n","      print(f'Output Transformer : {logits[0, :1, :12]}')    \n","      print(f'---------------------------------------------------------')\n","\n","    return logits"]},{"cell_type":"code","source":["transformer = TransformerBlock(NUM_LAYERS, \n","                               EMBEDDING_DIM, \n","                               NUM_HEADS, \n","                               FF_DIM,\n","                               MAX_SEQ_LENGTH,\n","                               tokenizers.ita.get_vocab_size(),\n","                               tfhub_handle_encoder,\n","                               trainable,\n","                               DROPUOT)\n","\n","transformer_output = transformer((enc_input, dec_input), \n","                                 training=training,\n","                                 debug=debug)"],"metadata":{"id":"pr--G0ZZVAMi","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1680071179917,"user_tz":-120,"elapsed":20304,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}},"outputId":"84a32611-5b42-4376-edf7-3a53c77dc2a1"},"execution_count":40,"outputs":[{"output_type":"stream","name":"stdout","text":["****************** DEBUG ENCODER BERT ******************\n","First example\n","Keys                         : ['input_mask', 'input_word_ids']\n","Shape                        : (32, 128)\n","Word Ids                     : [  101 10159 24239   187   112 45754   100 10110 21096   119   102     0\n","     0     0     0     0]\n","Input Mask                   : [1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0]\n","\n","Encoder Outputs BERT Shape   : (32, 128, 768)\n","Encoder Outputs BERT Values  : [[ 0.03327592  0.05808669  0.13086411  0.1270645  -0.05396995 -0.02335626\n","  -0.18837294  0.14862062  0.00092175  0.48506987  0.2808432  -0.19578753\n","  -0.4992058   0.13423905 -0.6468562   0.02476236]]\n","\n","Sequence Conv1 Shape         : (32, 128, 512)\n","Sequence Conv2 Shape         : (32, 128, 128)\n","Sequence Lambda Layer        : (32, 128, 128)\n","\n","Sequence Outputs Values      : [0.9901202  0.04264219 0.18161763 0.31579095 0.31039956 0.83884466\n"," 0.01011574 0.         0.18807004 0.19593099 0.2832985  0.\n"," 0.11893892 0.         0.         0.        ]\n","*********************************************************\n","********** DEBUG TOKEN AND POSITION EMBEDDING ***********\n","Sequence Max len                          : 128\n","Sequence Shape                            : [ 32 128]\n","Shape TokenAndPositionEmbedding           : (32, 128, 128)\n","*********************************************************\n","---------------- DEBUG TRANSFORMER BLOCK ----------------\n","inputs_encoder       : (32, 128)\n","inputs_decoder       : (32, 128, 128)\n","********************* DEBUG DECODE-BERT *********************\n","Shape Input Layer Decode-Bert       : (32, 128, 128)\n","Shape Output Layer Decode-Bert      : (32, 128, 128)\n","*********************************************************\n","******************* DEBUG DECODER ***********************\n","Input Shape                       : (32, 128, 128)\n","Shape Outputs Decoder             : (32, 128, 128)\n","*********************************************************\n","Output Shape       : (32, 128, 23120)\n","Output Transformer : [[-0.35840845 -0.18481414  0.10328046  0.08279054  0.04938171  0.03443662\n","  -0.10705946 -0.11085636  0.00130221  0.1549049  -0.09602828 -0.06056103]]\n","---------------------------------------------------------\n"]}]},{"cell_type":"code","source":["transformer.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0kYt6ehvh-8B","executionInfo":{"status":"ok","timestamp":1680071180593,"user_tz":-120,"elapsed":697,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}},"outputId":"006a84ac-4c21-4a6a-e819-060afcd5ea36"},"execution_count":41,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"transformer_block\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," token_and_position_embeddin  multiple                 2975744   \n"," g_1 (TokenAndPositionEmbedd                                     \n"," ing)                                                            \n","                                                                 \n"," encoder_bert_1 (EncoderBert  multiple                 135193472 \n"," )                                                               \n","                                                                 \n"," DEC (Decoder)               multiple                  1592224   \n","                                                                 \n"," dropout_16 (Dropout)        multiple                  0         \n","                                                                 \n"," dense_10 (Dense)            multiple                  2982480   \n","                                                                 \n","=================================================================\n","Total params: 142,743,920\n","Trainable params: 8,009,840\n","Non-trainable params: 134,734,080\n","_________________________________________________________________\n"]}]},{"cell_type":"markdown","source":["## Addestramento Modello"],"metadata":{"id":"IFmcHTSDTvYk"}},{"cell_type":"markdown","source":["### Compilazione"],"metadata":{"id":"tiuqPlHo0Z0n"}},{"cell_type":"code","source":["transformer.compile(\n","  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n","  optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE_ADAM, \n","                                     beta_1=BETA_1, \n","                                     beta_2=BETA_2),\n","  metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])"],"metadata":{"id":"bOyqCyjIr-L2","executionInfo":{"status":"ok","timestamp":1680071180594,"user_tz":-120,"elapsed":7,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}}},"execution_count":42,"outputs":[]},{"cell_type":"markdown","source":["### Callbacks"],"metadata":{"id":"-z6qj1uclHRa"}},{"cell_type":"code","source":["# Create a callback that saves the model's weights\n","cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n","                                                 save_weights_only=True,\n","                                                 save_best_only=True)\n","\n","# Create a callback Tensorboard\n","tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir)\n","\n","# Create a callback save the log history\n","json_logging_callback = tf.keras.callbacks.LambdaCallback(\n","  on_epoch_end=lambda epoch, logs: json_log.write(\n","    json.dumps({'epoch': epoch, \n","                'loss': logs['loss'],\n","                'sparse_categorical_accuracy': logs['sparse_categorical_accuracy'],\n","                'val_loss': logs['val_loss'],\n","                'val_sparse_categorical_accuracy': logs['val_sparse_categorical_accuracy']}) + '\\n'),\n","  on_train_end=lambda logs: json_log.close()\n",")"],"metadata":{"id":"3hurmpSjJ_dT","executionInfo":{"status":"ok","timestamp":1680071180595,"user_tz":-120,"elapsed":7,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}}},"execution_count":43,"outputs":[]},{"cell_type":"markdown","source":["### Train Ita"],"metadata":{"id":"Day7C7Qh0b4G"}},{"cell_type":"code","source":["start = datetime.datetime.now()\n","json_log = open(log_history, mode='a', buffering=1, encoding='utf-8')\n","\n","transformer.fit(train_dataset_ita,\n","                initial_epoch=0,\n","                epochs=EPOCHS_ADAM,\n","                shuffle=True,\n","                validation_data=validation_dataset_ita,\n","                callbacks=[tensorboard_callback,\n","                           json_logging_callback, \n","                           cp_callback])\n","\n","end = datetime.datetime.now()\n","print(f'Tempo necessario per l\\'addestramento: {end - start}')"],"metadata":{"id":"etOGtBcer9yi","colab":{"base_uri":"https://localhost:8080/"},"outputId":"f7ddb51b-935c-4f8e-ec59-dff8c3785f3a","executionInfo":{"status":"ok","timestamp":1679850560281,"user_tz":-120,"elapsed":6139307,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/20\n","542/542 [==============================] - 458s 834ms/step - loss: 3.6724 - sparse_categorical_accuracy: 0.9028 - val_loss: 0.6827 - val_sparse_categorical_accuracy: 0.9160\n","Epoch 2/20\n","542/542 [==============================] - 424s 783ms/step - loss: 0.6110 - sparse_categorical_accuracy: 0.9252 - val_loss: 0.5135 - val_sparse_categorical_accuracy: 0.9321\n","Epoch 3/20\n","542/542 [==============================] - 454s 838ms/step - loss: 0.5083 - sparse_categorical_accuracy: 0.9327 - val_loss: 0.4689 - val_sparse_categorical_accuracy: 0.9353\n","Epoch 4/20\n","542/542 [==============================] - 454s 838ms/step - loss: 0.4673 - sparse_categorical_accuracy: 0.9352 - val_loss: 0.4408 - val_sparse_categorical_accuracy: 0.9377\n","Epoch 5/20\n","542/542 [==============================] - 454s 837ms/step - loss: 0.4369 - sparse_categorical_accuracy: 0.9376 - val_loss: 0.4137 - val_sparse_categorical_accuracy: 0.9403\n","Epoch 6/20\n","542/542 [==============================] - 452s 834ms/step - loss: 0.4100 - sparse_categorical_accuracy: 0.9406 - val_loss: 0.3911 - val_sparse_categorical_accuracy: 0.9432\n","Epoch 7/20\n","542/542 [==============================] - 451s 832ms/step - loss: 0.3865 - sparse_categorical_accuracy: 0.9432 - val_loss: 0.3708 - val_sparse_categorical_accuracy: 0.9458\n","Epoch 8/20\n","542/542 [==============================] - 422s 779ms/step - loss: 0.3668 - sparse_categorical_accuracy: 0.9454 - val_loss: 0.3552 - val_sparse_categorical_accuracy: 0.9475\n","Epoch 9/20\n","542/542 [==============================] - 452s 834ms/step - loss: 0.3496 - sparse_categorical_accuracy: 0.9473 - val_loss: 0.3418 - val_sparse_categorical_accuracy: 0.9490\n","Epoch 10/20\n","542/542 [==============================] - 423s 780ms/step - loss: 0.3349 - sparse_categorical_accuracy: 0.9488 - val_loss: 0.3303 - val_sparse_categorical_accuracy: 0.9503\n","Epoch 11/20\n","542/542 [==============================] - 451s 833ms/step - loss: 0.3215 - sparse_categorical_accuracy: 0.9503 - val_loss: 0.3217 - val_sparse_categorical_accuracy: 0.9515\n","Epoch 12/20\n","542/542 [==============================] - 451s 832ms/step - loss: 0.3095 - sparse_categorical_accuracy: 0.9516 - val_loss: 0.3134 - val_sparse_categorical_accuracy: 0.9526\n","Epoch 13/20\n","542/542 [==============================] - 421s 777ms/step - loss: 0.2985 - sparse_categorical_accuracy: 0.9528 - val_loss: 0.3063 - val_sparse_categorical_accuracy: 0.9534\n","Epoch 14/20\n","542/542 [==============================] - 451s 832ms/step - loss: 0.2882 - sparse_categorical_accuracy: 0.9540 - val_loss: 0.2985 - val_sparse_categorical_accuracy: 0.9544\n","Epoch 15/20\n","542/542 [==============================] - 451s 832ms/step - loss: 0.2785 - sparse_categorical_accuracy: 0.9551 - val_loss: 0.2944 - val_sparse_categorical_accuracy: 0.9551\n","Epoch 16/20\n","542/542 [==============================] - 421s 776ms/step - loss: 0.2697 - sparse_categorical_accuracy: 0.9561 - val_loss: 0.2880 - val_sparse_categorical_accuracy: 0.9559\n","Epoch 17/20\n","542/542 [==============================] - 420s 776ms/step - loss: 0.2612 - sparse_categorical_accuracy: 0.9571 - val_loss: 0.2843 - val_sparse_categorical_accuracy: 0.9567\n","Epoch 18/20\n","542/542 [==============================] - 452s 834ms/step - loss: 0.2527 - sparse_categorical_accuracy: 0.9580 - val_loss: 0.2805 - val_sparse_categorical_accuracy: 0.9574\n","Epoch 19/20\n","542/542 [==============================] - 452s 834ms/step - loss: 0.2449 - sparse_categorical_accuracy: 0.9589 - val_loss: 0.2759 - val_sparse_categorical_accuracy: 0.9582\n","Epoch 20/20\n","542/542 [==============================] - 452s 834ms/step - loss: 0.2380 - sparse_categorical_accuracy: 0.9597 - val_loss: 0.2723 - val_sparse_categorical_accuracy: 0.9588\n","Tempo necessario per l'addestramento: 2:35:02.303992\n"]}]},{"cell_type":"code","source":["# Carico i pesi modello\n","latest = tf.train.latest_checkpoint(PATH_WEIGHTS)\n","transformer.load_weights(latest)"],"metadata":{"id":"5KeU08tmS3UK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1679864302962,"user_tz":-120,"elapsed":10589,"user":{"displayName":"Dan Bad","userId":"09439284819205921448"}},"outputId":"35d6faad-a4f1-40ba-be03-6a52844fca95"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x7f1c28524eb0>"]},"metadata":{},"execution_count":44}]},{"cell_type":"code","source":["start = datetime.datetime.now()\n","json_log = open(log_history, mode='a', buffering=1, encoding='utf-8')\n","\n","transformer.fit(train_dataset_ita,\n","                initial_epoch=EPOCHS_ADAM,\n","                epochs=EPOCHS_ADAM+EPOCHS_ADAM,\n","                shuffle=True,\n","                validation_data=validation_dataset_ita,\n","                callbacks=[tensorboard_callback,\n","                           json_logging_callback, \n","                           cp_callback])\n","\n","end = datetime.datetime.now()\n","print(f'Tempo necessario per l\\'addestramento: {end - start}')"],"metadata":{"id":"PLZGGXQxS9V5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1679873525914,"user_tz":-120,"elapsed":9222974,"user":{"displayName":"Dan Bad","userId":"09439284819205921448"}},"outputId":"054a4e36-b5d4-4cef-c4d2-22308d8c115c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 21/40\n","542/542 [==============================] - 433s 789ms/step - loss: 0.2309 - sparse_categorical_accuracy: 0.9607 - val_loss: 0.2706 - val_sparse_categorical_accuracy: 0.9595\n","Epoch 22/40\n","542/542 [==============================] - 461s 851ms/step - loss: 0.2239 - sparse_categorical_accuracy: 0.9615 - val_loss: 0.2663 - val_sparse_categorical_accuracy: 0.9599\n","Epoch 23/40\n","542/542 [==============================] - 463s 854ms/step - loss: 0.2181 - sparse_categorical_accuracy: 0.9623 - val_loss: 0.2649 - val_sparse_categorical_accuracy: 0.9606\n","Epoch 24/40\n","542/542 [==============================] - 430s 793ms/step - loss: 0.2119 - sparse_categorical_accuracy: 0.9630 - val_loss: 0.2618 - val_sparse_categorical_accuracy: 0.9613\n","Epoch 25/40\n","542/542 [==============================] - 429s 792ms/step - loss: 0.2058 - sparse_categorical_accuracy: 0.9638 - val_loss: 0.2594 - val_sparse_categorical_accuracy: 0.9618\n","Epoch 26/40\n","542/542 [==============================] - 460s 849ms/step - loss: 0.2001 - sparse_categorical_accuracy: 0.9645 - val_loss: 0.2581 - val_sparse_categorical_accuracy: 0.9623\n","Epoch 27/40\n","542/542 [==============================] - 426s 787ms/step - loss: 0.1949 - sparse_categorical_accuracy: 0.9652 - val_loss: 0.2559 - val_sparse_categorical_accuracy: 0.9630\n","Epoch 28/40\n","542/542 [==============================] - 459s 847ms/step - loss: 0.1895 - sparse_categorical_accuracy: 0.9660 - val_loss: 0.2535 - val_sparse_categorical_accuracy: 0.9632\n","Epoch 29/40\n","542/542 [==============================] - 454s 838ms/step - loss: 0.1848 - sparse_categorical_accuracy: 0.9667 - val_loss: 0.2521 - val_sparse_categorical_accuracy: 0.9638\n","Epoch 30/40\n","542/542 [==============================] - 457s 844ms/step - loss: 0.1796 - sparse_categorical_accuracy: 0.9674 - val_loss: 0.2511 - val_sparse_categorical_accuracy: 0.9642\n","Epoch 31/40\n","542/542 [==============================] - 459s 847ms/step - loss: 0.1755 - sparse_categorical_accuracy: 0.9679 - val_loss: 0.2490 - val_sparse_categorical_accuracy: 0.9646\n","Epoch 32/40\n","542/542 [==============================] - 455s 840ms/step - loss: 0.1712 - sparse_categorical_accuracy: 0.9685 - val_loss: 0.2492 - val_sparse_categorical_accuracy: 0.9649\n","Epoch 33/40\n","542/542 [==============================] - 453s 835ms/step - loss: 0.1669 - sparse_categorical_accuracy: 0.9691 - val_loss: 0.2472 - val_sparse_categorical_accuracy: 0.9652\n","Epoch 34/40\n","542/542 [==============================] - 453s 837ms/step - loss: 0.1629 - sparse_categorical_accuracy: 0.9697 - val_loss: 0.2467 - val_sparse_categorical_accuracy: 0.9656\n","Epoch 35/40\n","542/542 [==============================] - 428s 790ms/step - loss: 0.1590 - sparse_categorical_accuracy: 0.9701 - val_loss: 0.2462 - val_sparse_categorical_accuracy: 0.9661\n","Epoch 36/40\n","542/542 [==============================] - 457s 844ms/step - loss: 0.1552 - sparse_categorical_accuracy: 0.9706 - val_loss: 0.2448 - val_sparse_categorical_accuracy: 0.9663\n","Epoch 37/40\n","542/542 [==============================] - 423s 781ms/step - loss: 0.1517 - sparse_categorical_accuracy: 0.9712 - val_loss: 0.2449 - val_sparse_categorical_accuracy: 0.9667\n","Epoch 38/40\n","542/542 [==============================] - 455s 839ms/step - loss: 0.1482 - sparse_categorical_accuracy: 0.9717 - val_loss: 0.2436 - val_sparse_categorical_accuracy: 0.9670\n","Epoch 39/40\n","542/542 [==============================] - 454s 838ms/step - loss: 0.1452 - sparse_categorical_accuracy: 0.9721 - val_loss: 0.2435 - val_sparse_categorical_accuracy: 0.9672\n","Epoch 40/40\n","542/542 [==============================] - 450s 830ms/step - loss: 0.1419 - sparse_categorical_accuracy: 0.9725 - val_loss: 0.2441 - val_sparse_categorical_accuracy: 0.9676\n","Tempo necessario per l'addestramento: 2:33:42.680984\n"]}]},{"cell_type":"markdown","source":["### Train Dante"],"metadata":{"id":"GhBGzbvrh2Rw"}},{"cell_type":"code","source":["train_dataset_dante, validation_dataset_dante, test_dataset = train_val_test_dataset(df=df, filter_column='DANTE', debug=debug)"],"metadata":{"id":"kndzuk5XVnmM","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1680071348777,"user_tz":-120,"elapsed":6331,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}},"outputId":"d31e535f-a547-4bb6-8795-d7cc00b2c3e3"},"execution_count":48,"outputs":[{"output_type":"stream","name":"stdout","text":["Lunghezza df 379582\n","Lunghezza dataset 135184\n","Dati totali presenti nel Dataset               : 379582\n","Dati totali presenti nel Dataset di Train      : 17344\n","Dati totali presenti nel Dataset di Validation : 7424\n","Dati totali presenti nel Dataset di Test       : 232\n","\n","----------------------------------- TRAIN SET -----------------------------------------\n","['E al pelare conviene avere maniera , ', 'essayer , comprendre et ècouter', 'e così si pentirà della sua follia . ', 'mostrando di fare vita agreste , ']\n","['E al pelar convien aver maniera , ', 'A ritenere intendi , e a udire , ', 'Sì ssi ripentirà di sua follia . ', \"Mostrando ched i' faccia vita agresta;\"]\n","--------------------------------- VALIDATION SET --------------------------------------\n","['Si je le dis pour le tromper . ', \"con tutt' altro che nobile e vero amore . \", 'ihren Status und ihren Zustand;', \"Et il n' a jamais dit un vrai mot . \"]\n","[\"Ched i' non dica ciò per inghanarlo . \", 'Se non di fino e di leal amore . ', 'Di loro stato e di lor condizione;', 'Nè non diciea giamai parola vera . ']\n","----------------------------------- TEST SET ------------------------------------------\n","['Bien sûr , si Dieu vous accorde la vie , ', \"Que vous aurez de l' èducation et apprendre . \", 'Tu as commencè à apprendre de moi . ', 'Regarde toi , tu es bien rassurèe . ']\n","['Ciertana son , se Dio ti dona vita , ', 'Che ttu terai scuola , e legierai . ', \"Di legierne da me congìo tu n' ài;\", 'Ma guardati , che ttu sie ben fornita']\n","-------------------------------- ANALISI DATI -----------------------------------------\n","Esempi nel Dataset di Train                            : 17344\n","Frase più corta nel Dataset Input di Train             : kühn , kühn , \n","Frase più corta nel Dataset Target di Train            : E gli giurai a le sante\n","Frase più lunga nel Dataset Input di Train             : Auch die Erscheinung des Menschen nicht zu schätzen , der mit seiner eigenen Schönheit ausgestattet ist\n","Frase più lunga nel Dataset Target di Train            : Chè 'l cuor , che nn' ama un sol , non val un fico . \n","---------------------------------------------------------------------------------------\n","Esempi nel Dataset di Validation                       : 7424\n","Frase più corta nel Dataset Input di Validation        : Trotz Neid . \n","Frase più corta nel Dataset Target di Validation       : E gli giurai a le sante\n","Frase più lunga nel Dataset Input di Validation        : Er ist vielleicht nicht feindseliger gegen mich , aber er wird vielleicht auf den Boden abgeschossen . \n","Frase più lunga nel Dataset Target di Validation       : Chè 'l cuor , che nn' ama un sol , non val un fico . \n","---------------------------------------------------------------------------------------\n","Esempi nel Dataset di Test                             : 232\n","Frase più corta nel Dataset Input di Test              : hardiment , hardiment , \n","Frase più corta nel Dataset Target di Test             : A gran pena può femina venire\n","Frase più lunga nel Dataset Input di Test              : Cependant , il est prèfèrable pour lui de savoir comment les gèrer avec compètence . \n","Frase più lunga nel Dataset Target di Test             : Chè 'l cuor , che nn' ama un sol , non val un fico . \n","\n","--------------------------------- EXAMPLE ---------------------------------------------\n","['kühn , kühn , ']\n","tf.Tensor(\n","[[  101   179 12369 15797   117   179 12369 15797   117   102     0     0\n","      0     0     0     0     0     0     0     0     0     0     0     0\n","      0     0     0     0     0     0     0     0]], shape=(1, 32), dtype=int32)\n","------------------------------------------------------------------\n","['E gli giurai a le sante']\n","<tf.RaggedTensor [[2, 31, 128, 16179, 27, 88, 1593, 3]]>\n","\n","\n","['Auch die Erscheinung des Menschen nicht zu schätzen , der mit seiner eigenen Schönheit ausgestattet ist']\n","tf.Tensor(\n","[[   101  14427  10128 101457  10139  16352  10726  10304    187  10269\n","   81293    117  10118  10221  11411  21111  55260  90929  15543  57862\n","   10298    102      0      0      0      0      0      0      0      0\n","       0      0      0      0      0      0      0      0      0      0\n","       0      0      0      0      0      0      0      0      0      0\n","       0      0      0      0      0      0      0      0      0      0\n","       0      0      0      0      0      0      0      0      0      0\n","       0      0      0      0      0      0      0      0      0      0\n","       0      0      0      0      0      0      0      0      0      0\n","       0      0      0      0      0      0      0      0      0      0\n","       0      0      0      0      0      0      0      0      0      0\n","       0      0      0      0      0      0      0      0      0      0\n","       0      0      0      0      0      0      0      0]], shape=(1, 128), dtype=int32)\n","------------------------------------------------------------------\n","[\"Chè 'l cuor , che nn' ama un sol , non val un fico . \"]\n","<tf.RaggedTensor [[2, 76, 8, 38, 896, 10, 76, 5114, 8, 754, 84, 291, 10, 79, 2173, 84,\n","  5917, 11, 3]]>\n"]}]},{"cell_type":"code","source":["# Carico i pesi modello\n","latest = tf.train.latest_checkpoint(PATH_WEIGHTS)\n","transformer.load_weights(latest)"],"metadata":{"id":"4ejTGcN8h4we","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1680027975142,"user_tz":-120,"elapsed":12179,"user":{"displayName":"daniele badiali","userId":"08100546172874775759"}},"outputId":"f14e0b8d-b9c6-42d3-971b-498bacea881a"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x7f2f4482e040>"]},"metadata":{},"execution_count":45}]},{"cell_type":"code","source":["start = datetime.datetime.now()\n","\n","json_log = open(log_history, mode='a', buffering=1, encoding='utf-8')\n","\n","transformer.fit(train_dataset_dante,\n","                initial_epoch=EPOCHS_ADAM+EPOCHS_ADAM,\n","                epochs=EPOCHS_ADAM+EPOCHS_ADAM+EPOCHS_ADAM,\n","                shuffle=True,\n","                validation_data=validation_dataset_dante,\n","                callbacks=[tensorboard_callback,\n","                           json_logging_callback, \n","                           cp_callback])\n","\n","end = datetime.datetime.now()\n","print(f'Tempo necessario per l\\'addestramento: {end - start}')"],"metadata":{"id":"UZ0iTUOXh70W","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1679902544822,"user_tz":-120,"elapsed":508497,"user":{"displayName":"Daniele Badiali","userId":"14842026096794501907"}},"outputId":"dfb0e984-a287-4028-d29c-274052f37ce9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 41/60\n","542/542 [==============================] - 470s 854ms/step - loss: 0.4691 - sparse_categorical_accuracy: 0.9411 - val_loss: 0.3584 - val_sparse_categorical_accuracy: 0.9483\n","Epoch 42/60\n","542/542 [==============================] - 428s 789ms/step - loss: 0.3769 - sparse_categorical_accuracy: 0.9473 - val_loss: 0.3192 - val_sparse_categorical_accuracy: 0.9515\n","Epoch 43/60\n","542/542 [==============================] - 457s 843ms/step - loss: 0.3390 - sparse_categorical_accuracy: 0.9501 - val_loss: 0.2929 - val_sparse_categorical_accuracy: 0.9536\n","Epoch 44/60\n","542/542 [==============================] - 427s 788ms/step - loss: 0.3114 - sparse_categorical_accuracy: 0.9521 - val_loss: 0.2727 - val_sparse_categorical_accuracy: 0.9555\n","Epoch 45/60\n","542/542 [==============================] - 454s 838ms/step - loss: 0.2888 - sparse_categorical_accuracy: 0.9539 - val_loss: 0.2554 - val_sparse_categorical_accuracy: 0.9571\n","Epoch 46/60\n","542/542 [==============================] - 428s 789ms/step - loss: 0.2701 - sparse_categorical_accuracy: 0.9555 - val_loss: 0.2384 - val_sparse_categorical_accuracy: 0.9588\n","Epoch 47/60\n","542/542 [==============================] - 455s 840ms/step - loss: 0.2545 - sparse_categorical_accuracy: 0.9570 - val_loss: 0.2252 - val_sparse_categorical_accuracy: 0.9600\n","Epoch 48/60\n","542/542 [==============================] - 454s 838ms/step - loss: 0.2406 - sparse_categorical_accuracy: 0.9582 - val_loss: 0.2149 - val_sparse_categorical_accuracy: 0.9610\n","Epoch 49/60\n","542/542 [==============================] - 452s 834ms/step - loss: 0.2285 - sparse_categorical_accuracy: 0.9592 - val_loss: 0.2044 - val_sparse_categorical_accuracy: 0.9619\n","Epoch 50/60\n","542/542 [==============================] - 454s 838ms/step - loss: 0.2175 - sparse_categorical_accuracy: 0.9604 - val_loss: 0.1953 - val_sparse_categorical_accuracy: 0.9629\n","Epoch 51/60\n","542/542 [==============================] - 422s 778ms/step - loss: 0.2075 - sparse_categorical_accuracy: 0.9613 - val_loss: 0.1884 - val_sparse_categorical_accuracy: 0.9635\n","Epoch 52/60\n","542/542 [==============================] - 453s 836ms/step - loss: 0.1986 - sparse_categorical_accuracy: 0.9622 - val_loss: 0.1803 - val_sparse_categorical_accuracy: 0.9646\n","Epoch 53/60\n","542/542 [==============================] - 424s 783ms/step - loss: 0.1912 - sparse_categorical_accuracy: 0.9630 - val_loss: 0.1743 - val_sparse_categorical_accuracy: 0.9653\n","Epoch 54/60\n","542/542 [==============================] - 452s 834ms/step - loss: 0.1837 - sparse_categorical_accuracy: 0.9638 - val_loss: 0.1673 - val_sparse_categorical_accuracy: 0.9661\n","Epoch 55/60\n","542/542 [==============================] - 455s 839ms/step - loss: 0.1774 - sparse_categorical_accuracy: 0.9646 - val_loss: 0.1625 - val_sparse_categorical_accuracy: 0.9668\n","Epoch 56/60\n","542/542 [==============================] - 423s 780ms/step - loss: 0.1713 - sparse_categorical_accuracy: 0.9653 - val_loss: 0.1575 - val_sparse_categorical_accuracy: 0.9676\n","Epoch 57/60\n","542/542 [==============================] - 457s 843ms/step - loss: 0.1654 - sparse_categorical_accuracy: 0.9661 - val_loss: 0.1543 - val_sparse_categorical_accuracy: 0.9683\n","Epoch 58/60\n","542/542 [==============================] - 456s 841ms/step - loss: 0.1600 - sparse_categorical_accuracy: 0.9668 - val_loss: 0.1498 - val_sparse_categorical_accuracy: 0.9688\n","Epoch 59/60\n","542/542 [==============================] - 453s 836ms/step - loss: 0.1555 - sparse_categorical_accuracy: 0.9675 - val_loss: 0.1476 - val_sparse_categorical_accuracy: 0.9693\n","Epoch 60/60\n","542/542 [==============================] - 450s 831ms/step - loss: 0.1506 - sparse_categorical_accuracy: 0.9682 - val_loss: 0.1425 - val_sparse_categorical_accuracy: 0.9703\n","Tempo necessario per l'addestramento: 2:36:16.764225\n"]}]},{"cell_type":"code","source":["start = datetime.datetime.now()\n","\n","json_log = open(log_history, mode='a', buffering=1, encoding='utf-8')\n","\n","transformer.fit(train_dataset_dante,\n","                initial_epoch=EPOCHS_ADAM+EPOCHS_ADAM+EPOCHS_ADAM,\n","                epochs=EPOCHS_ADAM+EPOCHS_ADAM+EPOCHS_ADAM+EPOCHS_ADAM,\n","                shuffle=True,\n","                validation_data=validation_dataset_dante,\n","                callbacks=[tensorboard_callback,\n","                           json_logging_callback, \n","                           cp_callback])\n","\n","end = datetime.datetime.now()\n","print(f'Tempo necessario per l\\'addestramento: {end - start}')"],"metadata":{"id":"3yZ-Zq0xJIZX","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1679961715381,"user_tz":-120,"elapsed":9239599,"user":{"displayName":"Daniele Badiali","userId":"15682358814001311695"}},"outputId":"3c642054-9a67-452e-946c-9e43f8ebf9b6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 61/80\n","542/542 [==============================] - 459s 838ms/step - loss: 0.1464 - sparse_categorical_accuracy: 0.9687 - val_loss: 0.1401 - val_sparse_categorical_accuracy: 0.9709\n","Epoch 62/80\n","542/542 [==============================] - 454s 838ms/step - loss: 0.1416 - sparse_categorical_accuracy: 0.9695 - val_loss: 0.1367 - val_sparse_categorical_accuracy: 0.9715\n","Epoch 63/80\n","542/542 [==============================] - 456s 842ms/step - loss: 0.1380 - sparse_categorical_accuracy: 0.9701 - val_loss: 0.1337 - val_sparse_categorical_accuracy: 0.9720\n","Epoch 64/80\n","542/542 [==============================] - 423s 781ms/step - loss: 0.1343 - sparse_categorical_accuracy: 0.9707 - val_loss: 0.1300 - val_sparse_categorical_accuracy: 0.9725\n","Epoch 65/80\n","542/542 [==============================] - 453s 836ms/step - loss: 0.1306 - sparse_categorical_accuracy: 0.9713 - val_loss: 0.1291 - val_sparse_categorical_accuracy: 0.9728\n","Epoch 66/80\n","542/542 [==============================] - 424s 783ms/step - loss: 0.1275 - sparse_categorical_accuracy: 0.9718 - val_loss: 0.1264 - val_sparse_categorical_accuracy: 0.9733\n","Epoch 67/80\n","542/542 [==============================] - 451s 832ms/step - loss: 0.1238 - sparse_categorical_accuracy: 0.9723 - val_loss: 0.1237 - val_sparse_categorical_accuracy: 0.9738\n","Epoch 68/80\n","542/542 [==============================] - 451s 832ms/step - loss: 0.1213 - sparse_categorical_accuracy: 0.9728 - val_loss: 0.1224 - val_sparse_categorical_accuracy: 0.9742\n","Epoch 69/80\n","542/542 [==============================] - 422s 779ms/step - loss: 0.1181 - sparse_categorical_accuracy: 0.9733 - val_loss: 0.1221 - val_sparse_categorical_accuracy: 0.9746\n","Epoch 70/80\n","542/542 [==============================] - 451s 833ms/step - loss: 0.1157 - sparse_categorical_accuracy: 0.9738 - val_loss: 0.1190 - val_sparse_categorical_accuracy: 0.9750\n","Epoch 71/80\n","542/542 [==============================] - 419s 772ms/step - loss: 0.1127 - sparse_categorical_accuracy: 0.9741 - val_loss: 0.1169 - val_sparse_categorical_accuracy: 0.9755\n","Epoch 72/80\n","542/542 [==============================] - 451s 832ms/step - loss: 0.1102 - sparse_categorical_accuracy: 0.9746 - val_loss: 0.1157 - val_sparse_categorical_accuracy: 0.9756\n","Epoch 73/80\n","542/542 [==============================] - 452s 833ms/step - loss: 0.1076 - sparse_categorical_accuracy: 0.9751 - val_loss: 0.1148 - val_sparse_categorical_accuracy: 0.9759\n","Epoch 74/80\n","542/542 [==============================] - 423s 780ms/step - loss: 0.1055 - sparse_categorical_accuracy: 0.9756 - val_loss: 0.1130 - val_sparse_categorical_accuracy: 0.9763\n","Epoch 75/80\n","542/542 [==============================] - 455s 839ms/step - loss: 0.1031 - sparse_categorical_accuracy: 0.9760 - val_loss: 0.1123 - val_sparse_categorical_accuracy: 0.9766\n","Epoch 76/80\n","542/542 [==============================] - 426s 785ms/step - loss: 0.1012 - sparse_categorical_accuracy: 0.9762 - val_loss: 0.1112 - val_sparse_categorical_accuracy: 0.9768\n","Epoch 77/80\n","542/542 [==============================] - 456s 842ms/step - loss: 0.0992 - sparse_categorical_accuracy: 0.9766 - val_loss: 0.1090 - val_sparse_categorical_accuracy: 0.9772\n","Epoch 78/80\n","542/542 [==============================] - 454s 838ms/step - loss: 0.0967 - sparse_categorical_accuracy: 0.9771 - val_loss: 0.1082 - val_sparse_categorical_accuracy: 0.9775\n","Epoch 79/80\n","542/542 [==============================] - 454s 839ms/step - loss: 0.0948 - sparse_categorical_accuracy: 0.9774 - val_loss: 0.1093 - val_sparse_categorical_accuracy: 0.9775\n","Epoch 80/80\n","542/542 [==============================] - 427s 788ms/step - loss: 0.0930 - sparse_categorical_accuracy: 0.9777 - val_loss: 0.1080 - val_sparse_categorical_accuracy: 0.9776\n","Tempo necessario per l'addestramento: 2:33:59.968229\n"]}]},{"cell_type":"code","source":["start = datetime.datetime.now()\n","\n","json_log = open(log_history, mode='a', buffering=1, encoding='utf-8')\n","\n","transformer.fit(train_dataset_dante,\n","                initial_epoch=EPOCHS_ADAM+EPOCHS_ADAM+EPOCHS_ADAM+EPOCHS_ADAM,\n","                epochs=EPOCHS_ADAM+EPOCHS_ADAM+EPOCHS_ADAM+EPOCHS_ADAM+EPOCHS_ADAM,\n","                shuffle=True,\n","                validation_data=validation_dataset_dante,\n","                callbacks=[tensorboard_callback,\n","                           json_logging_callback, \n","                           cp_callback])\n","\n","end = datetime.datetime.now()\n","print(f'Tempo necessario per l\\'addestramento: {end - start}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7yibFj-xkgRP","executionInfo":{"status":"ok","timestamp":1679988668497,"user_tz":-120,"elapsed":9079306,"user":{"displayName":"Daniele Badiali","userId":"07880650122235290376"}},"outputId":"d19121ca-fe7e-4772-e61b-4e7011b5e11e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 81/100\n","542/542 [==============================] - 455s 821ms/step - loss: 0.0919 - sparse_categorical_accuracy: 0.9779 - val_loss: 0.1066 - val_sparse_categorical_accuracy: 0.9780\n","Epoch 82/100\n","542/542 [==============================] - 441s 814ms/step - loss: 0.0898 - sparse_categorical_accuracy: 0.9783 - val_loss: 0.1068 - val_sparse_categorical_accuracy: 0.9780\n","Epoch 83/100\n","542/542 [==============================] - 442s 815ms/step - loss: 0.0884 - sparse_categorical_accuracy: 0.9787 - val_loss: 0.1052 - val_sparse_categorical_accuracy: 0.9784\n","Epoch 84/100\n","542/542 [==============================] - 438s 808ms/step - loss: 0.0863 - sparse_categorical_accuracy: 0.9790 - val_loss: 0.1053 - val_sparse_categorical_accuracy: 0.9787\n","Epoch 85/100\n","542/542 [==============================] - 443s 818ms/step - loss: 0.0849 - sparse_categorical_accuracy: 0.9792 - val_loss: 0.1050 - val_sparse_categorical_accuracy: 0.9786\n","Epoch 86/100\n","542/542 [==============================] - 408s 754ms/step - loss: 0.0837 - sparse_categorical_accuracy: 0.9795 - val_loss: 0.1059 - val_sparse_categorical_accuracy: 0.9788\n","Epoch 87/100\n","542/542 [==============================] - 443s 818ms/step - loss: 0.0821 - sparse_categorical_accuracy: 0.9798 - val_loss: 0.1023 - val_sparse_categorical_accuracy: 0.9791\n","Epoch 88/100\n","542/542 [==============================] - 441s 814ms/step - loss: 0.0806 - sparse_categorical_accuracy: 0.9801 - val_loss: 0.1031 - val_sparse_categorical_accuracy: 0.9793\n","Epoch 89/100\n","542/542 [==============================] - 442s 815ms/step - loss: 0.0792 - sparse_categorical_accuracy: 0.9803 - val_loss: 0.1020 - val_sparse_categorical_accuracy: 0.9793\n","Epoch 90/100\n","542/542 [==============================] - 410s 757ms/step - loss: 0.0780 - sparse_categorical_accuracy: 0.9807 - val_loss: 0.1020 - val_sparse_categorical_accuracy: 0.9797\n","Epoch 91/100\n","542/542 [==============================] - 439s 810ms/step - loss: 0.0766 - sparse_categorical_accuracy: 0.9809 - val_loss: 0.1027 - val_sparse_categorical_accuracy: 0.9797\n","Epoch 92/100\n","542/542 [==============================] - 443s 817ms/step - loss: 0.0757 - sparse_categorical_accuracy: 0.9811 - val_loss: 0.1017 - val_sparse_categorical_accuracy: 0.9798\n","Epoch 93/100\n","542/542 [==============================] - 443s 817ms/step - loss: 0.0740 - sparse_categorical_accuracy: 0.9814 - val_loss: 0.1026 - val_sparse_categorical_accuracy: 0.9800\n","Epoch 94/100\n","542/542 [==============================] - 438s 807ms/step - loss: 0.0730 - sparse_categorical_accuracy: 0.9816 - val_loss: 0.1021 - val_sparse_categorical_accuracy: 0.9799\n","Epoch 95/100\n","542/542 [==============================] - 439s 810ms/step - loss: 0.0720 - sparse_categorical_accuracy: 0.9818 - val_loss: 0.1012 - val_sparse_categorical_accuracy: 0.9803\n","Epoch 96/100\n","542/542 [==============================] - 409s 755ms/step - loss: 0.0709 - sparse_categorical_accuracy: 0.9820 - val_loss: 0.1018 - val_sparse_categorical_accuracy: 0.9804\n","Epoch 97/100\n","542/542 [==============================] - 440s 811ms/step - loss: 0.0696 - sparse_categorical_accuracy: 0.9822 - val_loss: 0.1005 - val_sparse_categorical_accuracy: 0.9804\n","Epoch 98/100\n","542/542 [==============================] - 409s 754ms/step - loss: 0.0687 - sparse_categorical_accuracy: 0.9825 - val_loss: 0.1012 - val_sparse_categorical_accuracy: 0.9805\n","Epoch 99/100\n","542/542 [==============================] - 436s 805ms/step - loss: 0.0675 - sparse_categorical_accuracy: 0.9827 - val_loss: 0.1011 - val_sparse_categorical_accuracy: 0.9805\n","Epoch 100/100\n","542/542 [==============================] - 442s 815ms/step - loss: 0.0668 - sparse_categorical_accuracy: 0.9828 - val_loss: 0.1004 - val_sparse_categorical_accuracy: 0.9808\n","Tempo necessario per l'addestramento: 2:31:18.600566\n"]}]},{"cell_type":"code","source":["start = datetime.datetime.now()\n","\n","json_log = open(log_history, mode='a', buffering=1, encoding='utf-8')\n","\n","transformer.fit(train_dataset_dante,\n","                initial_epoch=EPOCHS_ADAM+EPOCHS_ADAM+EPOCHS_ADAM+EPOCHS_ADAM+EPOCHS_ADAM,\n","                epochs=EPOCHS_ADAM+EPOCHS_ADAM+EPOCHS_ADAM+EPOCHS_ADAM+EPOCHS_ADAM+EPOCHS_ADAM,\n","                shuffle=True,\n","                validation_data=validation_dataset_dante,\n","                callbacks=[tensorboard_callback,\n","                           json_logging_callback, \n","                           cp_callback])\n","\n","end = datetime.datetime.now()\n","print(f'Tempo necessario per l\\'addestramento: {end - start}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9HtFRuW6dDEE","executionInfo":{"status":"ok","timestamp":1680037480635,"user_tz":-120,"elapsed":5831448,"user":{"displayName":"daniele badiali","userId":"08100546172874775759"}},"outputId":"6ddcb8c5-e814-4462-8bf9-0cc6c68b330d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 101/120\n","542/542 [==============================] - 463s 839ms/step - loss: 0.0660 - sparse_categorical_accuracy: 0.9831 - val_loss: 0.1000 - val_sparse_categorical_accuracy: 0.9807\n","Epoch 102/120\n","542/542 [==============================] - 473s 873ms/step - loss: 0.0649 - sparse_categorical_accuracy: 0.9832 - val_loss: 0.0999 - val_sparse_categorical_accuracy: 0.9811\n","Epoch 103/120\n","542/542 [==============================] - 447s 825ms/step - loss: 0.0639 - sparse_categorical_accuracy: 0.9835 - val_loss: 0.0998 - val_sparse_categorical_accuracy: 0.9810\n","Epoch 104/120\n","542/542 [==============================] - 440s 812ms/step - loss: 0.0628 - sparse_categorical_accuracy: 0.9837 - val_loss: 0.0993 - val_sparse_categorical_accuracy: 0.9812\n","Epoch 105/120\n","542/542 [==============================] - 447s 825ms/step - loss: 0.0620 - sparse_categorical_accuracy: 0.9839 - val_loss: 0.0983 - val_sparse_categorical_accuracy: 0.9814\n","Epoch 106/120\n","542/542 [==============================] - 469s 866ms/step - loss: 0.0610 - sparse_categorical_accuracy: 0.9841 - val_loss: 0.0996 - val_sparse_categorical_accuracy: 0.9812\n","Epoch 107/120\n","542/542 [==============================] - 469s 866ms/step - loss: 0.0603 - sparse_categorical_accuracy: 0.9843 - val_loss: 0.0996 - val_sparse_categorical_accuracy: 0.9814\n","Epoch 108/120\n","542/542 [==============================] - 465s 857ms/step - loss: 0.0596 - sparse_categorical_accuracy: 0.9844 - val_loss: 0.1000 - val_sparse_categorical_accuracy: 0.9815\n","Epoch 109/120\n","542/542 [==============================] - 431s 794ms/step - loss: 0.0587 - sparse_categorical_accuracy: 0.9846 - val_loss: 0.1002 - val_sparse_categorical_accuracy: 0.9815\n","Epoch 110/120\n","542/542 [==============================] - 464s 857ms/step - loss: 0.0577 - sparse_categorical_accuracy: 0.9847 - val_loss: 0.0993 - val_sparse_categorical_accuracy: 0.9818\n","Epoch 111/120\n","542/542 [==============================] - 465s 858ms/step - loss: 0.0570 - sparse_categorical_accuracy: 0.9849 - val_loss: 0.0989 - val_sparse_categorical_accuracy: 0.9819\n","Epoch 112/120\n","542/542 [==============================] - 434s 800ms/step - loss: 0.0564 - sparse_categorical_accuracy: 0.9851 - val_loss: 0.0990 - val_sparse_categorical_accuracy: 0.9818\n","Epoch 113/120\n","542/542 [==============================] - 462s 854ms/step - loss: 0.0559 - sparse_categorical_accuracy: 0.9852 - val_loss: 0.0990 - val_sparse_categorical_accuracy: 0.9819\n","Epoch 114/120\n","542/542 [==============================] - 465s 858ms/step - loss: 0.0548 - sparse_categorical_accuracy: 0.9855 - val_loss: 0.1004 - val_sparse_categorical_accuracy: 0.9820\n","Epoch 115/120\n","542/542 [==============================] - 461s 850ms/step - loss: 0.0539 - sparse_categorical_accuracy: 0.9856 - val_loss: 0.0994 - val_sparse_categorical_accuracy: 0.9821\n","Epoch 116/120\n","542/542 [==============================] - 436s 805ms/step - loss: 0.0537 - sparse_categorical_accuracy: 0.9857 - val_loss: 0.0985 - val_sparse_categorical_accuracy: 0.9823\n","Epoch 117/120\n","542/542 [==============================] - 437s 807ms/step - loss: 0.0530 - sparse_categorical_accuracy: 0.9859 - val_loss: 0.1001 - val_sparse_categorical_accuracy: 0.9822\n","Epoch 118/120\n","542/542 [==============================] - 469s 865ms/step - loss: 0.0520 - sparse_categorical_accuracy: 0.9861 - val_loss: 0.1001 - val_sparse_categorical_accuracy: 0.9822\n","Epoch 119/120\n","542/542 [==============================] - 438s 808ms/step - loss: 0.0513 - sparse_categorical_accuracy: 0.9863 - val_loss: 0.1011 - val_sparse_categorical_accuracy: 0.9823\n","Epoch 120/120\n","542/542 [==============================] - 470s 868ms/step - loss: 0.0510 - sparse_categorical_accuracy: 0.9863 - val_loss: 0.1003 - val_sparse_categorical_accuracy: 0.9824\n","Tempo necessario per l'addestramento: 2:38:25.610550\n"]}]},{"cell_type":"markdown","source":["## Valutazione dell'addestramento\n","Avendo in output il log ed i risultati dell'addestramento, possiamo visualizzare\n","queste informazioni relativamente alle metriche di interesse."],"metadata":{"id":"L0w4wF79UhAp"}},{"cell_type":"code","source":["# Recupero il log di addestramento\n","df_history = pd.read_json(log_history, lines=True)\n","\n","# visualizzazione andamento addestramento\n","# su un grafico composto da due sub-plot\n","# uno per il loss, l'altro per l'accuracy\n","fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15,5))\n","\n","# Errore durante l'addestramento\n","ax1.plot(df_history['loss'], label='Loss')\n","ax1.plot(df_history['val_loss'], label='Validation Loss')\n","ax1.set_title('Training Loss')\n","ax1.legend()\n","\n","# Accuratezza durante l'addestramento\n","ax2.plot(df_history['sparse_categorical_accuracy'], label='Accuracy')\n","ax2.plot(df_history['val_sparse_categorical_accuracy'], label='Validation Accuracy')\n","ax2.set_title('Training Accuracy')\n","ax2.legend()\n","\n","plt.show()"],"metadata":{"id":"RpXR2p5VAdoG","colab":{"base_uri":"https://localhost:8080/","height":336},"executionInfo":{"status":"ok","timestamp":1680037482737,"user_tz":-120,"elapsed":2103,"user":{"displayName":"daniele badiali","userId":"08100546172874775759"}},"outputId":"140be4b2-f687-4803-9a3d-541ac202b8c8"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 1080x360 with 2 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","source":["## Test del modello\n","La seguente cella permette di caricare l'ultimo checkpoint dell'addestramento\n","precedentemente salvato."],"metadata":{"id":"ReOkcBp2WHWW"}},{"cell_type":"code","source":["trainable = False\n","\n","transformer = TransformerBlock(NUM_LAYERS, \n","                               EMBEDDING_DIM, \n","                               NUM_HEADS, \n","                               FF_DIM,\n","                               MAX_SEQ_LENGTH,\n","                               tokenizers.ita.get_vocab_size(),\n","                               tfhub_handle_encoder,\n","                               trainable,\n","                               DROPUOT)"],"metadata":{"id":"RN0mnV8Wd92H","executionInfo":{"status":"ok","timestamp":1680071355319,"user_tz":-120,"elapsed":6552,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}}},"execution_count":49,"outputs":[]},{"cell_type":"code","source":["# Carico i pesi modello\n","latest = tf.train.latest_checkpoint(PATH_WEIGHTS)\n","transformer.load_weights(latest)"],"metadata":{"id":"5PIf_6-RSBb1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1680071357857,"user_tz":-120,"elapsed":2567,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}},"outputId":"49717920-febe-408f-938d-cc0f65095877"},"execution_count":50,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x7fd371946d90>"]},"metadata":{},"execution_count":50}]},{"cell_type":"code","source":["class Translate:\n","  def __init__(self, transformer_block, tokenizers):\n","    self.transformer = transformer_block\n","    self.tokenizers = tokenizers\n","\n","  def predict(self, input_text, max_length):\n","    if input_text is None:\n","      input_text = (df[ORIGINAL_COLUMN].tolist())[np.random.choice(len(df[ORIGINAL_COLUMN].tolist()))]\n","      print(input_text)\n","\n","    inputs_bert = self.tokenizers.multilingual.tokenize(input_text)\n","\n","    start_end = self.tokenizers.ita.tokenize([''])[0]\n","    start = (start_end[0][tf.newaxis]).numpy()[0]\n","    end = (start_end[1][tf.newaxis]).numpy()[0]\n","\n","    output_array = tf.TensorArray(dtype=tf.int32, size=max_length, dynamic_size=True)\n","    output_array = output_array.write(0, tf.constant([start]))     \n","\n","    out_words = []\n","\n","    for i in tf.range(max_length):\n","      # decodifica e recupero probabilità di output\n","      output = tf.transpose(output_array.stack())\n","\n","      transformer_output = transformer((inputs_bert, output), \n","                                        training=False,\n","                                        debug=False)\n","\n","      predictions = transformer_output[:, -1:, :]\n","\n","      # selezione della parola più probabile\n","      predict = tf.argmax(predictions, -1)\n","      pred_values = (tf.keras.backend.argmax(transformer_output, axis=-1)).numpy()\n","    \n","      # inserimento della parola nella sequenza di output\n","      output_array = output_array.write(i+1, [pred_values[0][i]])\n","\n","      if pred_values[0][i] == end:\n","        break\n","\n","    output = tf.transpose(output_array.stack())\n","    text = tokenizers.ita.detokenize(output)[0]  \n","    tokens = tokenizers.ita.lookup(output)[0]\n","\n","    return text, tokens"],"metadata":{"id":"L2PEoJVb1V8x","executionInfo":{"status":"ok","timestamp":1680071357859,"user_tz":-120,"elapsed":17,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}}},"execution_count":51,"outputs":[]},{"cell_type":"code","source":["translate = Translate(transformer_block=transformer,\n","                      tokenizers=tokenizers)\n","\n","# Recupero un batch di esempi per la verifica delle classi custom che andrò a creare\n","for test_input_data, test_target_data in test_dataset.take(50):\n","  test_input_data = test_input_data.numpy().decode()\n","  test_target_data = test_target_data.numpy().decode()\n","\n","  text, token = translate.predict(tf.constant([test_input_data]), MAX_SEQ_LENGTH)\n","\n","  print(f'{\"Input\":15s}: {test_input_data}')\n","  print(f'{\"Target\":15s}: {test_target_data}')\n","  print(f'{\"Prediction\":15s}: {text.numpy().decode(\"utf-8\")}')  \n","  print('---------------------------------------------')"],"metadata":{"id":"udIjI2jZWR6g","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1680072092462,"user_tz":-120,"elapsed":254248,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}},"outputId":"347441fd-7509-4148-dd8b-d6a8093eea18"},"execution_count":53,"outputs":[{"output_type":"stream","name":"stdout","text":["Input          : Je lui ai fait croire que son bien être\n","Target         : A chui intender faciea , che 'l su' disdotto\n","Prediction     : a chui intender faciea , che ' l su ' disdotto\n","---------------------------------------------\n","Input          : J' ètais plus excitèe que tout . \n","Target         : Mi piaciea più che null' altro , ch' e' ssia . \n","Prediction     : e piu arditamente contr ' a llui piu che fele ;\n","---------------------------------------------\n","Input          : J' ètais sèduisante , jeune et drôle . \n","Target         : I' era bella , e giovane , e folletta , \n","Prediction     : e ' fu fondato per folle e fornita\n","---------------------------------------------\n","Input          : Mais il n' ètait pas à l' ècole d' affection . \n","Target         : Ma non era a la scuola de l' Amore\n","Prediction     : ma non era a l ' amor unquanche conosciuto ,\n","---------------------------------------------\n","Input          : C' ètait; cependant , je le sais maintenant en profondeur par c ur . \n","Target         : Istata; ma i' so or ben per cuore\n","Prediction     : istata ; ma i ' so or ben per cuore\n","---------------------------------------------\n","Input          : L' exercice qui sera prèsentè ici . \n","Target         : La pratica , la qual ti fie qui detta . \n","Prediction     : la qual sapranno ben sua malatia .\n","---------------------------------------------\n","Input          : L' habitude m' a rendu si expèrimentèe . \n","Target         : Usanza me n' à fatta sì savietta , \n","Prediction     : vergognia si mi mise per richiamo ,\n","---------------------------------------------\n","Input          : Je ne pouvais pas tromper les lecteurs . \n","Target         : Ched i' non dotterei nessun lettore , \n","Prediction     : ched i ' non dotterei nessun lettore ,\n","---------------------------------------------\n","Input          : qu' il m' a donnè une mauvaise opinion de ça . \n","Target         : Che di ciò mi faciesse desinore , \n","Prediction     : che di lui mi richiamo a pietanza ,\n","---------------------------------------------\n","Input          : Mais parce que j' ètais sèduisante et jeune . \n","Target         : Ma' ched i' fosse bella e giovanetta \n","Prediction     : ma ' ched i ' fu fondato .\n","---------------------------------------------\n","Input          : Parce que ce que j' ai fait est gènial . \n","Target         : Chèd egli è tanto ched i' non finai , \n","Prediction     : ched i ' si piacie d ' ben cio ,\n","---------------------------------------------\n","Input          : que l' apprentissage ou dans mon audace . \n","Target         : Che lla scienza i' ò nel mi' coragio . \n","Prediction     : che lla scienza i ' o nel mi ' coragio .\n","---------------------------------------------\n","Input          : Si vous l' aimez , vous l' ècouterez . \n","Target         : Sed e' ti piacie , tu l' ascholterai , \n","Prediction     : se ttu lo vi piacie , tu ' l ' intenda ,\n","---------------------------------------------\n","Input          : mais je ne l' aurais pas obtenue sans un grand sacrifice;\n","Target         : Ma i' no l' ebi sanza gran damagio \n","Prediction     : ma i ' non vi richegio ch ' e ' soccorra durante .\n","---------------------------------------------\n","Input          : J' ai souffert intensèment et j' ai travaillè dur . \n","Target         : Molta pen' e travaglio vi durai;\n","Prediction     : molta pen ' e travaglio vi durai ;\n","---------------------------------------------\n","Input          : Cependant , maintenant la douleur a disparu et j' ai gagnè la sagesse . \n","Target         : Ma pur e 'l mal se n' è mess' , e l' usagio . \n","Prediction     : ma pur e ' l mal se n ' e mess ' , e l ' usagio .\n","---------------------------------------------\n","Input          : J' ai conniquè beaucoup d' hommes . \n","Target         : Molti buon' uomini i' ò già 'nghannati , \n","Prediction     : ed i ' si vidi molto gran fretta ,\n","---------------------------------------------\n","Input          : Quand je les ai gardès coincès dans mes cravates . \n","Target         : Quand' i' gli tenni ne mie' lacci presi , \n","Prediction     : quand ' i ' gli tenni ne mie ' lacci presi ,\n","---------------------------------------------\n","Input          : Mais avant cela , j' ai ètè trompè pendant tant de mois . \n","Target         : Ma prima fu' 'ngannata tanti mesi\n","Prediction     : ma prima , ched i ' fu ' ' n asiglio ,\n","---------------------------------------------\n","Input          : que mes amusements avaient dèjà disparu . \n","Target         : Che ' più de' mie' sollazi eran passati . \n","Prediction     : che ' piu de ' mie ' sollazi eran passati .\n","---------------------------------------------\n","Input          : Cent mille d' entre eux ont ètè èchangès . \n","Target         : Cientomilia cotanti e' barattati\n","Prediction     : cientomilia cotanti e ' barattati\n","---------------------------------------------\n","Input          : Je le ferais , si je les avais acquises rapidement . \n","Target         : N' avrei , s' i' a buon' ora gli avesse tesi \n","Prediction     : si ' l faro , se tanta viltanza\n","---------------------------------------------\n","Input          : et compte , noble et riche bourgeois , \n","Target         : E conti , e cavalieri , e gran borgesi , \n","Prediction     : e conti , e cavalieri , e gran borgesi ,\n","---------------------------------------------\n","Input          : ça me donnerait beaucoup de florins d' or . \n","Target         : Ch' e' molti fiorin d' oro m' avrian dati . \n","Prediction     : che molte volte mi gastigava\n","---------------------------------------------\n","Input          : Quand j' ai rèalisè , il ètait dèjà trop tard . \n","Target         : Ma , quand' i' me n' avidi , egli era tardi , \n","Prediction     : quand ' i ' vidi venir un poco il fante ,\n","---------------------------------------------\n","Input          : parce que j' avais dèjà dèpassè l' adolescence\n","Target         : Chèd i' era già fuor di Giovaneza , \n","Prediction     : ched i ' avea per me ne trasale\n","---------------------------------------------\n","Input          : Et mes yeux tendres ètaient vides . \n","Target         : Ed eranmi falliti i dolzi isguardi , \n","Prediction     : e suo ' lodar suo ' eran caritevoli ,\n","---------------------------------------------\n","Input          : parce que ma maturitè m' a tenu sous son contrôle . \n","Target         : Perchè 'n sua balia mi tenea Vechieza . \n","Prediction     : ched i ' mi riguardai dal su ' arte ,\n","---------------------------------------------\n","Input          : Il convient maintenant , ma chère , que vous vous occupiez de vous même . \n","Target         : Or convien , figluola mia , che tu ti guardi , \n","Prediction     : or convien , figluola mia , che ti sai\n","---------------------------------------------\n","Input          : Que tu ne te comportes pas comme ça . \n","Target         : Chettu non ti conduchi a tale streza . \n","Prediction     : che ttu non troverai i nulla parte\n","---------------------------------------------\n","Input          : Mon c ur a souffert profondèment quand j' ai regardè\n","Target         : Molto mi dolea il cuor , quand' i' vedea\n","Prediction     : molto mi dolea il cuor , quand ' i ' vedea\n","---------------------------------------------\n","Input          : que ma porte ètait dans un endroit comme celui ci . \n","Target         : Chell' uscio mio stava in tal sogiorno , \n","Prediction     : che lla mia via era gia cio era .\n","---------------------------------------------\n","Input          : C' ètait tellement bondè autour d' elle . \n","Target         : Ch' e' vi solea aver tal pressa 'ntorno\n","Prediction     : si forte a llei atare ,\n","---------------------------------------------\n","Input          : que l' ensemble de la règion est nègatif . \n","Target         : Che tutta la contrada ne dolea . \n","Prediction     : che tutto ' l valletto , ch ' e fera ,\n","---------------------------------------------\n","Input          : Cependant , je m' en fichais . \n","Target         : Ma , quanto a me , e' no me ne calea , \n","Prediction     : ma ' si mi riguardai dal dritto lato ,\n","---------------------------------------------\n","Input          : parce que c' ètait trop agrèable pour eux , \n","Target         : Chè troppo più piaciea loro quel torno , \n","Prediction     : che troppo fu troppo tosto per lor podere ,\n","---------------------------------------------\n","Input          : que j' ètais alors si ènorme . \n","Target         : Ch' i' era allora di sì grande attorno , \n","Prediction     : che io fu messa la vo ' si troveria .\n","---------------------------------------------\n","Input          : que tout l' univers m' est apparu . \n","Target         : Che tutto quanto il mondo mi' parea . \n","Prediction     : che tutto ' l mondo i ' era ricordata ,\n","---------------------------------------------\n","Input          : Maintenant , il me convient de mourir de tristesse . \n","Target         : Or convenia che di dolor morisse , \n","Prediction     : or si trovai ver ' me fedel ,\n","---------------------------------------------\n","Input          : Quand j' ai vu ces enfants passer , \n","Target         : Quand' i' vedea que' giovani passare , \n","Prediction     : quand ' i ' udi ' valletti d ' antecristo ,\n","---------------------------------------------\n","Input          : Et tout le monde semblait se moquer de moi . \n","Target         : E ciaschedun parea che mi schernisse . \n","Prediction     : e ciaschedun parea che mi schernisse .\n","---------------------------------------------\n","Input          : Ils m' ont appelè Vieille dame gorgèe . \n","Target         :  Vechia increspata mi faciean chiamare\n","Prediction     : molto mi fecier dispett ' anno ,\n","---------------------------------------------\n","Input          : Pour qui seulement , c' est une fois\n","Target         : A colu' solamente , che giadisse\n","Prediction     : a che le potesse , e ' ntendimento ;\n","---------------------------------------------\n","Input          : Il m' aimait plus sensuellement . \n","Target         : Più carnalmente mi solea amare . \n","Prediction     : piu carnalmente mi solea amare .\n","---------------------------------------------\n","Input          : D' un autre point de vue , le c ur humain\n","Target         : Ancora d' altra parte cuore humano\n","Prediction     : ancor ' n altra parte cuore humano\n","---------------------------------------------\n","Input          : Tu n' imagines pas la profonde tristesse que je ressens . \n","Target         : Non penserebe il gran dolor , ch' i' sento , \n","Prediction     : tu metta inpaccio , ch ' i ' o perpensato ,\n","---------------------------------------------\n","Input          : De tous les moments où j' ai mèditè\n","Target         : Tratutte l' ore ch' i' ò pensamento\n","Prediction     : per tutti i tutti i nulla faglia ,\n","---------------------------------------------\n","Input          : Aux doux baisers qu' ils m' ont donnès . \n","Target         : De' be' basciar' , che m' ànno dato mano . \n","Prediction     : ma apressoche tutte le sante gloriose ,\n","---------------------------------------------\n","Input          : Tous les plaisirs sont maintenant à distance pour moi , \n","Target         : Ogni' Sollazo m' è ogi lontano , \n","Prediction     : tutti gli giurai a le sante\n","---------------------------------------------\n","Input          : mais pas l' indignation et la souffrance et une grande agonie\n","Target         : Ma non Ira e Dolori e Gran Tormento \n","Prediction     : ma non ira e dolori e gran tormento\n","---------------------------------------------\n"]}]},{"cell_type":"code","source":["  text_input_data = 'Ieri sono andato al supermercato'\n","\n","  text, token = translate.predict(tf.constant([text_input_data]), MAX_SEQ_LENGTH)\n","  print(f'{\"Input\":15s}: {text_input_data}')\n","  print(f'{\"Prediction\":15s}: {text.numpy().decode(\"utf-8\")}')  \n","  print('---------------------------------------------')"],"metadata":{"id":"Qex8JVqvJxzp","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1680072300037,"user_tz":-120,"elapsed":7618,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}},"outputId":"58ca9ac9-d032-45f1-8515-e44305d4b9cc"},"execution_count":58,"outputs":[{"output_type":"stream","name":"stdout","text":["Input          : Ieri sono andato al supermercato\n","Prediction     : i ' van cherendo lor vita ,\n","---------------------------------------------\n"]}]},{"cell_type":"code","source":["  text_input_data = 'ho comprato la cocacolo'\n","\n","  text, token = translate.predict(tf.constant([text_input_data]), MAX_SEQ_LENGTH)\n","  print(f'{\"Input\":15s}: {text_input_data}')\n","  print(f'{\"Prediction\":15s}: {text.numpy().decode(\"utf-8\")}')  \n","  print('---------------------------------------------')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"s9Dun8NnGaXd","executionInfo":{"status":"ok","timestamp":1680072336039,"user_tz":-120,"elapsed":8370,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}},"outputId":"efd28f2d-c1c2-47a0-8b68-126447c92c56"},"execution_count":59,"outputs":[{"output_type":"stream","name":"stdout","text":["Input          : ho comprato la cocacolo\n","Prediction     : i ' potre ' ben tosto confortato ,\n","---------------------------------------------\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"UONyLudWHYCr"},"execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"},"colab":{"provenance":[]},"gpuClass":"standard"},"nbformat":4,"nbformat_minor":0}