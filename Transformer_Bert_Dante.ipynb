{"cells":[{"cell_type":"markdown","source":["## Pacchetti da installare"],"metadata":{"id":"yDKuSNBd92YI"}},{"cell_type":"code","source":["!pip install -q -U 'tensorflow-text==2.8.*'"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NE4enZGpvMRX","executionInfo":{"status":"ok","timestamp":1679779447435,"user_tz":-60,"elapsed":76535,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}},"outputId":"fab4ab1c-f49f-4a8f-8a93-70bdf2a88f82"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m498.1/498.1 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m462.3/462.3 KB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 KB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m30.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}]},{"cell_type":"code","source":["!pip install -q tf-models-official"],"metadata":{"id":"FPtWz_qHuofc","executionInfo":{"status":"ok","timestamp":1679779510530,"user_tz":-60,"elapsed":63109,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"be441224-2f5c-4304-c8f1-e6011c1c406a"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m588.3/588.3 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.9/118.9 KB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m67.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m87.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 KB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m630.1/630.1 KB\u001b[0m \u001b[31m36.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m238.9/238.9 KB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m50.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m439.2/439.2 KB\u001b[0m \u001b[31m32.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m53.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m59.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n"]}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"hJy-juNOpUOY","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1679779545274,"user_tz":-60,"elapsed":34755,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}},"outputId":"c1f55e02-2f07-41f3-d823-13dc03a3e797"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","source":["## Import notebook"],"metadata":{"id":"xXYm-Qqw-ANh"}},{"cell_type":"code","execution_count":4,"metadata":{"collapsed":true,"id":"UaAiWsEuC_4K","executionInfo":{"status":"ok","timestamp":1679779550391,"user_tz":-60,"elapsed":5125,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}}},"outputs":[],"source":["import os\n","import re\n","import datetime\n","import pathlib\n","import json\n","from pathlib import Path\n","\n","import pandas as pd\n","import numpy as np\n","\n","from sklearn.model_selection import train_test_split\n","\n","import tensorflow as tf\n","import tensorflow_hub as hub\n","import tensorflow_text as text\n","from tensorflow_text.tools.wordpiece_vocab import bert_vocab_from_dataset as bert_vocab\n","\n","import matplotlib.pyplot as plt\n","\n","from typing import Tuple\n"]},{"cell_type":"code","source":["tf.get_logger().setLevel('ERROR')\n","tf.config.run_functions_eagerly(True)"],"metadata":{"id":"uKEqRlKowOQS","executionInfo":{"status":"ok","timestamp":1679779550393,"user_tz":-60,"elapsed":35,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["## Variabili Globali"],"metadata":{"id":"HRe16D-rUBLA"}},{"cell_type":"code","source":["# PARAMETRI GLOBALI\n","root_folder = 'drive/MyDrive/BERT/'\n","\n","# DATI\n","data_folder_name = 'data'\n","train_filename = 'train_data.csv'\n","\n","DATA_PATH = os.path.abspath(os.path.join(root_folder, data_folder_name))\n","train_data_filenamepath = os.path.abspath(os.path.join(DATA_PATH, train_filename))\n","\n","# PATH LOG Tensorboard\n","PATH_LOG = 'logs/fit/transformer_multi_bert_dante'\n","PATH_LOG = os.path.abspath(os.path.join(root_folder, PATH_LOG))\n","log_dir =  os.path.abspath(os.path.join(PATH_LOG, datetime.datetime.now().strftime('%Y%m%d-%H%M%S'))) \n","log_history = os.path.abspath(os.path.join(PATH_LOG, 'histrory.json'))\n","\n","# PATH WEIGHTS Tensorboard\n","PATH_WEIGHTS = 'weights/transformer_multi_bert_dante'\n","PATH_WEIGHTS = os.path.abspath(os.path.join(root_folder, PATH_WEIGHTS))\n","checkpoint_path = os.path.abspath(os.path.join(PATH_WEIGHTS, 'cp.ckpt'))\n","\n","# VOCABOLARIO\n","vocab_folder = 'vocab'\n","multilingual_vocab_finalname = 'multilingual_vocab.txt'\n","ita_vocab_finalname = 'ita_dante_vocab.txt'\n","\n","VOCAB_PATH = os.path.abspath(os.path.join(root_folder, vocab_folder))\n","multilingual_vocab_filenamepath = os.path.abspath(os.path.join(VOCAB_PATH, multilingual_vocab_finalname))\n","ita_vocab_filenamepath = os.path.abspath(os.path.join(VOCAB_PATH, ita_vocab_finalname))\n","\n","# parametri per il modello\n","ORIGINAL_COLUMN = 'Original'\n","TRANSLATE_COLUMN = 'Translate'\n","TYPE_COLUMN ='Type'"],"metadata":{"id":"ewLgCIuEpczO","executionInfo":{"status":"ok","timestamp":1679779550395,"user_tz":-60,"elapsed":33,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}}},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":["## Iper Parametri Modello"],"metadata":{"id":"LCiP6wT05k6j"}},{"cell_type":"code","source":["NUM_SAMPLES = 0\n","TEST = 200\n","TEST_SIZE = 0.3\n","\n","MAX_VOCAB_SIZE = 30000 \n","EMBEDDING_DIM = 128\n","HIDDEN_DIM = 1024 # numero di celle nei layer ricorrenti nascosti\n","\n","BATCH_SIZE = 32\n","BUFFER_SIZE = 2000\n","MAX_SEQ_LENGTH = 128\n","\n","NUM_LAYERS = 1 # Numero di layer di Decoder del Transformer\n","NUM_HEADS = 8 # Numero di meccanismi di multi-head attention\n","FF_DIM = 16 # Numero di celle dei Layer Feed Forward\n","DROPUOT = 0.5\n","\n","# Ottimizzatore Adam\n","LEARNING_RATE_ADAM = 1e-4\n","BETA_1 = 0.66\n","BETA_2 = 0.999\n","EPOCHS_ADAM = 20\n","\n","# IMPOSTO IL DEBUG A TRUE \n","debug = True\n","trainable = True\n","training = True"],"metadata":{"id":"8CN-4Uzoqbjl","executionInfo":{"status":"ok","timestamp":1679779550397,"user_tz":-60,"elapsed":30,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}}},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":["## Parametri BERT"],"metadata":{"id":"BehZY4rETECN"}},{"cell_type":"code","source":["bert_model_name = 'distilbert_multi_cased_L-6_H-768_A-12/1'  \n","tfhub_handle_preprocess = 'https://tfhub.dev/jeongukjae/distilbert_multi_cased_preprocess/2'\n","tfhub_handle_encoder =  'https://tfhub.dev/jeongukjae/distilbert_multi_cased_L-6_H-768_A-12/1'\n","\n","if debug:\n","  print('BERT model name                    : ', bert_model_name)\n","  print('BERT model selected                : ', tfhub_handle_encoder)\n","  print('BERT preprocess                    : ', tfhub_handle_preprocess)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fodDcY6sm392","executionInfo":{"status":"ok","timestamp":1679779550400,"user_tz":-60,"elapsed":31,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}},"outputId":"07863fa0-850b-4571-bede-41997c2e7744"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["BERT model name                    :  distilbert_multi_cased_L-6_H-768_A-12/1\n","BERT model selected                :  https://tfhub.dev/jeongukjae/distilbert_multi_cased_L-6_H-768_A-12/1\n","BERT preprocess                    :  https://tfhub.dev/jeongukjae/distilbert_multi_cased_preprocess/2\n"]}]},{"cell_type":"markdown","source":["## DATASET"],"metadata":{"id":"5DPeN9Vanbvv"}},{"cell_type":"markdown","source":["### Caricamento Dati"],"metadata":{"id":"LU7AorKXT8K7"}},{"cell_type":"code","source":["def preprocess_sentence(w):\n","  '''\n","  Preprocessing dei testi di input, impostando tutti i caratteri\n","  minuscoli, aggiungendo uno spazio prima di ogni punto e sostituendo\n","  qualsiasi carattere con uno spazio se non è compreso nel seguente elenco:\n","  (a-z, A-Z, \".\", \"?\", \"!\", \",\", \"'\", \"’\")\n","  '''\n","  # inserimento di uno spazio tra ogni parola e il successivo punto,\n","  # punto esclamativo, punto interrogativo e virgola\n","  # esempio: \"ciao, come và?\" => \"ciao , come và ?\"\n","  w = re.sub(r\"([?.!,])\", r\" \\1 \", w) # inserimento di uno spazio\n","\n","  # sostituzione dei caratteri apostrofo\n","  w = re.sub(r\"([’]+)\", \"'\", w)\n","\n","  w = w.replace(\"á\", \"à\")\n","  w = w.replace(\"é\", \"è\")\n","  w = w.replace(\"í\", \"ì\")\n","  w = w.replace(\"ó\", \"ò\")\n","  w = w.replace(\"ú\", \"ù\")\n","  w = w.replace('\"', \" \")\n","  w = w.replace(':', \" \")\n","  w = w.replace('«', \" \")\n","  w = w.replace('»', \" \")\n","  w = w.replace('‘', \" \")\n","  w = w.replace('-', \" \")\n","  w = w.replace('[', \" \")\n","  w = w.replace(']', \" \")\n","  w = w.replace('(', \" \")\n","  w = w.replace(')', \" \")\n","  w = w.replace(\"•\", \" \")\n","  w = w.replace(\"..\", \".\")\n","  w = w.replace(\"...\", \".\")\n","  w = w.replace(\"\\xa0\", \" \")\n","  w = w.replace(\"\\xc3\\xa8\", \" \")\n","  w = w.replace(\"\\xe2\\x80\\xaf\", \" \")\n","  w = w.replace(\"   \", \" \")\n","  w = w.replace(\"–\", \" \")\n","  w = w.replace(\"“\", \" \")\n","  w = w.replace(\"”\", \" \")\n","  w = w.replace(\"„\", \" \")\n","  w = w.replace(\"─\", \" \")\n","  w = w.replace(\"♪\", \" \")\n","  w = w.replace(\"#\", \" \")\n","  w = w.replace(\"/\", \" \")\n","  w = w.replace(\"=\", \" \")\n","  w = w.replace(\">\", \" \")\n","  w = w.replace(\"\\\\\", \" \")\n","  w = w.replace(\"`\", \" \")\n","  w = w.replace(\"¡\", \" \")\n","  w = w.replace(\"¿\", \" \")\n","  w = w.replace(\"œ\", \" \")\n","  w = w.replace(\"♗\", \" \")\n","  w = w.replace(\"♘\", \" \")\n","  w = w.replace(\"《\", \" \")\n","  w = w.replace(\"》\", \" \")\n","  # w = w.replace(\"\", \" \")\n","  # w = w.replace(\"\", \" \")\n","\n","  # inserimento di uno spazio dopo apostrofo\n","  w = re.sub(r\"(['])\", r\"\\1 \", w) \n","\n","  w = w.replace(\" ' \", \" '\")\n","\n","  w = re.sub(r'[\" \"]+', \" \", w) # rimozione di più spazi consecutivi\n","  return w"],"metadata":{"id":"Jm_Up6gyOTgW","executionInfo":{"status":"ok","timestamp":1679779550402,"user_tz":-60,"elapsed":28,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["df = pd.read_csv(\n","  train_data_filenamepath,\n","  usecols=[ORIGINAL_COLUMN, TRANSLATE_COLUMN, TYPE_COLUMN],\n",")\n","\n","# Preprocessing dei dati di Input\n","df[ORIGINAL_COLUMN] = df[ORIGINAL_COLUMN].apply(lambda x : preprocess_sentence(x))\n","\n","# Preprocessing dei dati Target con aggiunta del token di fine frase\n","df[TRANSLATE_COLUMN] = df[TRANSLATE_COLUMN].apply(lambda x : preprocess_sentence(x))\n","\n","if debug:\n","  print(f'Dati totali presenti nel Dataset               : {len(df)}')\n","  print('----------------------------------- TRAIN SET -----------------------------------------')\n","  print((df[ORIGINAL_COLUMN].tolist())[-1:])\n","  print((df[TRANSLATE_COLUMN].tolist())[-1:])\n","  print((df[ORIGINAL_COLUMN].tolist())[:1])\n","  print((df[TRANSLATE_COLUMN].tolist())[:1])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"duGPhZ_jgPVI","executionInfo":{"status":"ok","timestamp":1679779592102,"user_tz":-60,"elapsed":41727,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}},"outputId":"ea2476bc-8c86-436e-aab7-338d61581c5c"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Dati totali presenti nel Dataset               : 379582\n","----------------------------------- TRAIN SET -----------------------------------------\n","['Min önskan och vilja styrdes av gudomlig kärlek som driver solen och andra stjärnor framåt som ett hjul flyttade regelbundet . ']\n","[\" ma già volgeva il mio disio e 'l velle , sì come rota ch' igualmente è mossa , l' amor che move il sole e l' altre stelle\"]\n","[\"De même que , en temps de guerre , officiers et soldats se sentent autorisès par l' opinion gènèrale à commettre des actes qui , en temps de paix , sont tenus pour criminels , de même les rèvolutionnaires , dans leur lutte , se regardaient comme couverts par l' opinion de leur cercle , en vertu de laquelle les actes de cruautè qu' ils commettaient ètaient nobles et moraux , ètant commis par eux au prix de leur libertè , de leur vie , de tout ce qui est cher à la plupart des hommes . Ainsi s' expliquait , que des personnes excellentes , incapables non seulement de causer une souffrance , mais même d' en supporter la vue , pussent se prèparer tranquillement à la violence et au meurtre , et professer la saintetè de tels actes , considèrès comme moyens de dèfense , ou encore comme instrument utile à la rèalisation d' un idèal de bonheur pour l' humanitè . \"]\n","[\"Così come in tempo di guerra , ufficiali e soldati si sentono responsabilizzati dall' opinione generale a commettere atti che , in tempo di pace , sono necessari per i criminali , anche rivoluzionari nella loro lotta , considerati coperti dal parere del loro circolo , secondo cui gli atti di crudeltà che hanno commesso erano nobili e morali , essendo commessi da loro nel prezzo della loro libertà , della loro vita , di tutto ciò che è caro alla maggior parte degli uomini . Ciò ha spiegato che persone eccellenti , in grado non solo di causare sofferenza , ma anche di sopportarne la vista , potrebbero felicemente prepararsi alla violenza e all' omicidio , e professare la santità di tali atti , considerati come un mezzo di difesa , o come utili per la realizzazione di un ideale di felicità per l' umanità . \"]\n"]}]},{"cell_type":"markdown","source":["## Tokenizer\n","\n","Creo due differenti tokenizer che mi servizranno per la predisposizione dei dati di input:\n","\n","\n","*   EncTokenizer classe custom per la tokenizzazione dei dati di input al Layer di Encoder di Bert\n","*   DecTokenizer classe custom per la tokenizzazione dei dati di input al Layer di Decoder\n","\n"],"metadata":{"id":"njyY9RWlFMWu"}},{"cell_type":"code","source":["input_data_vocab = df[ORIGINAL_COLUMN].tolist()\n","target_data_vocab = df[TRANSLATE_COLUMN].tolist()\n","\n","dataset = tf.data.Dataset.from_tensor_slices((input_data_vocab, target_data_vocab))\n","dataset = dataset.shuffle(len(input_data_vocab)).batch(BATCH_SIZE, drop_remainder=True)\n","\n","train_multilingual = dataset.map(lambda multilingual, ita: multilingual)\n","train_ita = dataset.map(lambda multilingual, ita: ita)"],"metadata":{"id":"fUG1fTAYekOy","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1679779596167,"user_tz":-60,"elapsed":4077,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}},"outputId":"d69154b3-54c0-4774-f784-4d352c3340ec"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/tensorflow/python/data/ops/structured_function.py:256: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n","  warnings.warn(\n"]}]},{"cell_type":"code","source":["def write_vocab_file(filepath, vocab):\n","  with open(filepath, 'w') as f:\n","    for token in vocab:\n","      print(token, file=f)"],"metadata":{"id":"xWO-LrXJe0cF","executionInfo":{"status":"ok","timestamp":1679779596168,"user_tz":-60,"elapsed":69,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["def cleanup_text(reserved_tokens, token_txt):\n","\n","  # Drop the reserved tokens, except for \"[UNK]\".\n","  bad_tokens = [re.escape(tok) for tok in reserved_tokens if tok != \"[UNK]\"]\n","  bad_token_re = \"|\".join(bad_tokens)\n","\n","  bad_cells = tf.strings.regex_full_match(token_txt, bad_token_re)\n","  result = tf.ragged.boolean_mask(token_txt, ~bad_cells)\n","\n","  # Join them into strings.\n","  result = tf.strings.reduce_join(result, separator=' ', axis=-1)\n","\n","  return result"],"metadata":{"id":"yGdsrOoKiYUK","executionInfo":{"status":"ok","timestamp":1679779596168,"user_tz":-60,"elapsed":65,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["tokenizers = tf.Module()"],"metadata":{"id":"qbKNS_uQhHLz","executionInfo":{"status":"ok","timestamp":1679779596169,"user_tz":-60,"elapsed":64,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}}},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":["### Classe EncTokenizer\n","\n","Classe custom per la tokenizzazione dei dati di italiano e che crea i tre vettori necessari al layer di Encoder \n","Bert:\n","\n","\n","*   input_word_ids\n","*   input_type_ids\n","*   input_mask\n","\n","\n","\n"],"metadata":{"id":"0KUcCnjXVjt3"}},{"cell_type":"code","source":["bert_tokenizer_params=dict(lower_case=True)\n","reserved_tokens = {\n","  'start_of_sequence_id': 101,\n","  'end_of_segment_id': 102,\n","  'padding_id': 0,\n","  'mask_id': 103\n","}\n","\n","bert_vocab_args = dict(\n","  # The target vocabulary size\n","  vocab_size = MAX_VOCAB_SIZE,\n","  # Reserved tokens that must be included in the vocabulary\n","  reserved_tokens=reserved_tokens,\n","  # Arguments for `text.BertTokenizer`\n","  bert_tokenizer_params=bert_tokenizer_params,\n","  # Arguments for `wordpiece_vocab.wordpiece_tokenizer_learner_lib.learn`\n","  learn_params={},\n",")"],"metadata":{"id":"Yr0izOZLembx","executionInfo":{"status":"ok","timestamp":1679779596170,"user_tz":-60,"elapsed":61,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["exist_vocab = Path(multilingual_vocab_filenamepath)\n","\n","if not exist_vocab.exists():\n","  multilingual_vocab = bert_vocab.bert_vocab_from_dataset(\n","      train_multilingual.batch(MAX_VOCAB_SIZE).prefetch(tf.data.AUTOTUNE),\n","      **bert_vocab_args\n","  )\n","\n","  write_vocab_file(multilingual_vocab_filenamepath, multilingual_vocab)"],"metadata":{"id":"BwSKtlLSe7bH","executionInfo":{"status":"ok","timestamp":1679779596648,"user_tz":-60,"elapsed":535,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["class EncTokenizer(tf.Module):\n","  def __init__(self, tfhub_handle_preprocess):\n","    self.preprocessor = hub.KerasLayer(tfhub_handle_preprocess)\n","    \n","  @tf.function\n","  def tokenize(self, strings):\n","    return self.preprocessor(strings)"],"metadata":{"id":"WmsNdDLNf6vr","executionInfo":{"status":"ok","timestamp":1679779596649,"user_tz":-60,"elapsed":6,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["tokenizers.multilingual = EncTokenizer(tfhub_handle_preprocess)"],"metadata":{"id":"-4B-HWWcmsmz","executionInfo":{"status":"ok","timestamp":1679779610022,"user_tz":-60,"elapsed":13378,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}}},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":["### Classe DecTokenizer\n","\n","Classe custom per la tokenizzazione dei dati in lingua italiana per il layer di Decoder\n"],"metadata":{"id":"mICEGEzJVnvx"}},{"cell_type":"code","source":["bert_tokenizer_params=dict(lower_case=True)\n","reserved_tokens_vocab=[\"[PAD]\", \"[UNK]\", \"[START]\", \"[END]\"]\n","\n","bert_vocab_args = dict(\n","  # The target vocabulary size\n","  vocab_size = MAX_VOCAB_SIZE,\n","  # Reserved tokens that must be included in the vocabulary\n","  reserved_tokens=reserved_tokens_vocab,\n","  # Arguments for `text.BertTokenizer`\n","  bert_tokenizer_params=bert_tokenizer_params,\n","  # Arguments for `wordpiece_vocab.wordpiece_tokenizer_learner_lib.learn`\n","  learn_params={},\n",")"],"metadata":{"id":"abBEnJJGV0AD","executionInfo":{"status":"ok","timestamp":1679779610023,"user_tz":-60,"elapsed":82,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["exist_vocab = Path(ita_vocab_filenamepath)\n","\n","if not exist_vocab.exists():\n","  ita_vocab = bert_vocab.bert_vocab_from_dataset(\n","      train_ita.batch(MAX_VOCAB_SIZE).prefetch(tf.data.AUTOTUNE),\n","      **bert_vocab_args\n","  )\n","\n","  write_vocab_file(ita_vocab_filenamepath, ita_vocab)"],"metadata":{"id":"dGsP1V4nVz6S","executionInfo":{"status":"ok","timestamp":1679779610024,"user_tz":-60,"elapsed":80,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["START = tf.argmax(tf.constant(reserved_tokens_vocab) == \"[START]\")\n","END = tf.argmax(tf.constant(reserved_tokens_vocab) == \"[END]\")\n","\n","def add_start_end(ragged):\n","  count = ragged.bounding_shape(out_type=tf.int32)[0]\n","\n","  starts = tf.fill([count,1], START)\n","  starts = tf.cast(starts, tf.int32)\n","\n","  ends = tf.fill([count,1], END)\n","  ends = tf.cast(ends, tf.int32)\n","\n","  x = tf.concat([starts, ragged, ends], axis=1)\n","  return x"],"metadata":{"id":"BeaD2-uLWT50","executionInfo":{"status":"ok","timestamp":1679779610024,"user_tz":-60,"elapsed":78,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["class DecTokenizer(tf.Module):\n","  def __init__(self, reserved_tokens_vocab, vocab_path):\n","    self.tokenizer = text.BertTokenizer(vocab_path, lower_case=True, token_out_type=tf.int32)\n","    self._reserved_tokens_vocab = reserved_tokens_vocab\n","    self._vocab_path = tf.saved_model.Asset(vocab_path)\n","\n","    vocab = pathlib.Path(vocab_path).read_text().splitlines()\n","    self.vocab = tf.Variable(vocab)\n","\n","    ## Create the signatures for export:   \n","\n","    # Include a tokenize signature for a batch of strings. \n","    self.tokenize.get_concrete_function(\n","        tf.TensorSpec(shape=[None], dtype=tf.string))\n","    \n","    # Include `detokenize` and `lookup` signatures for:\n","    #   * `Tensors` with shapes [tokens] and [batch, tokens]\n","    #   * `RaggedTensors` with shape [batch, tokens]\n","    self.detokenize.get_concrete_function(\n","        tf.TensorSpec(shape=[None, None], dtype=tf.int32))\n","    self.detokenize.get_concrete_function(\n","          tf.RaggedTensorSpec(shape=[None, None], dtype=tf.int32))\n","\n","    self.lookup.get_concrete_function(\n","        tf.TensorSpec(shape=[None, None], dtype=tf.int32))\n","    self.lookup.get_concrete_function(\n","          tf.RaggedTensorSpec(shape=[None, None], dtype=tf.int32))\n","\n","    # These `get_*` methods take no arguments\n","    self.get_vocab_size.get_concrete_function()\n","    self.get_vocab_path.get_concrete_function()\n","    self.get_reserved_tokens.get_concrete_function()\n","    \n","  @tf.function\n","  def tokenize(self, strings):\n","    enc = self.tokenizer.tokenize(strings)\n","    # Merge the `word` and `word-piece` axes.\n","    enc = enc.merge_dims(-2,-1)\n","    enc = add_start_end(enc)\n","    return enc\n","\n","  @tf.function\n","  def detokenize(self, tokenized):\n","    words = self.tokenizer.detokenize(tokenized)\n","    return cleanup_text(self._reserved_tokens_vocab, words)\n","\n","  @tf.function\n","  def lookup(self, token_ids):\n","    return tf.gather(self.vocab, token_ids)\n","\n","  @tf.function\n","  def get_vocab_size(self):\n","    return tf.shape(self.vocab)[0]\n","\n","  @tf.function\n","  def get_vocab_path(self):\n","    return self._vocab_path\n","\n","  @tf.function\n","  def get_reserved_tokens(self):\n","    return tf.constant(self._reserved_tokens_vocab)"],"metadata":{"id":"iaAW-xm5WT1_","executionInfo":{"status":"ok","timestamp":1679779610025,"user_tz":-60,"elapsed":76,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["tokenizers.ita = DecTokenizer(reserved_tokens_vocab, ita_vocab_filenamepath)"],"metadata":{"id":"svlLobM4WTzC","executionInfo":{"status":"ok","timestamp":1679779614950,"user_tz":-60,"elapsed":4997,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}}},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":["### Analisi Dati Tokenizzati"],"metadata":{"id":"pKZxiQ5_Whmw"}},{"cell_type":"code","source":["print(f'Vocabolario Italiano : {tokenizers.ita.get_vocab_size()}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Jrg6TwQzW5LN","executionInfo":{"status":"ok","timestamp":1679779614951,"user_tz":-60,"elapsed":26,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}},"outputId":"d3230c73-970f-4762-fb04-8c972a246bf8"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["Vocabolario Italiano : 23120\n"]}]},{"cell_type":"markdown","source":["## Creazione dataset\n","Utilizzo della libreria tf.data per la gestione del dataset da utilizzare.\n","Verranno creati batch di esempi che verranno utilizzati durante l'addestramento."],"metadata":{"id":"5QIDajkEsVU1"}},{"cell_type":"code","source":["def split_dataset(df: pd.DataFrame,\n","                  filter_column: str, \n","                  debug: bool = False) -> Tuple:\n","\n","  print(f'Lunghezza df {len(df)}')\n","  dataset = (df.loc[df[TYPE_COLUMN] == filter_column]).copy() \n","  print(f'Lunghezza dataset {len(dataset)}')\n","  \n","  if NUM_SAMPLES > 0:\n","    dataset = dataset[:NUM_SAMPLES]\n","\n","  input_data = dataset[ORIGINAL_COLUMN].tolist()\n","  target_data = dataset[TRANSLATE_COLUMN].tolist()\n","\n","  train_input_data, validation_input_data, train_target_data, validation_target_data = train_test_split(\n","    input_data[:-TEST], \n","    target_data[:-TEST], \n","    test_size=TEST_SIZE, \n","    random_state=42,\n","    shuffle=True\n","  ) \n","\n","  train_input_data = train_input_data[:(int((len(train_input_data) / BATCH_SIZE)) * BATCH_SIZE)]\n","  train_target_data = train_target_data[:(int((len(train_target_data) / BATCH_SIZE)) * BATCH_SIZE)]\n","  \n","  validation_input_data = validation_input_data[:(int((len(validation_input_data) / BATCH_SIZE)) * BATCH_SIZE)]\n","  validation_target_data = validation_target_data[:(int((len(validation_target_data) / BATCH_SIZE)) * BATCH_SIZE)]\n","\n","  test_input_data = input_data[len(train_input_data)+len(validation_input_data):]\n","  test_target_data = target_data[len(train_target_data)+len(validation_target_data):]\n","\n","  if debug:\n","    print(f'Dati totali presenti nel Dataset               : {len(df)}')\n","    print(f'Dati totali presenti nel Dataset di Train      : {len(train_input_data)}')\n","    print(f'Dati totali presenti nel Dataset di Validation : {len(validation_input_data)}')\n","    print(f'Dati totali presenti nel Dataset di Test       : {len(test_input_data)}\\n')\n","\n","\n","    print('----------------------------------- TRAIN SET -----------------------------------------')\n","    print(train_input_data[-4:])\n","    print(train_target_data[-4:])\n","    print('--------------------------------- VALIDATION SET --------------------------------------')\n","    print(validation_input_data[-4:])\n","    print(validation_target_data[-4:])\n","    print('----------------------------------- TEST SET ------------------------------------------')\n","    print(test_input_data[-4:])\n","    print(test_target_data[-4:])\n","\n","    print('-------------------------------- ANALISI DATI -----------------------------------------')\n","    print(f'Esempi nel Dataset di Train                            : {len(train_input_data)}')\n","    print(f'Frase più corta nel Dataset Input di Train             : {min(train_input_data, key = len)}')\n","    print(f'Frase più corta nel Dataset Target di Train            : {min(train_target_data, key = len)}')\n","    print(f'Frase più lunga nel Dataset Input di Train             : {max(train_input_data, key = len)}')\n","    print(f'Frase più lunga nel Dataset Target di Train            : {max(train_target_data, key = len)}')\n","    print('---------------------------------------------------------------------------------------')\n","    print(f'Esempi nel Dataset di Validation                       : {len(validation_input_data)}')\n","    print(f'Frase più corta nel Dataset Input di Validation        : {min(validation_input_data, key = len)}')\n","    print(f'Frase più corta nel Dataset Target di Validation       : {min(validation_target_data, key = len)}')\n","    print(f'Frase più lunga nel Dataset Input di Validation        : {max(validation_input_data, key = len)}')\n","    print(f'Frase più lunga nel Dataset Target di Validation       : {max(validation_target_data, key = len)}')\n","    print('---------------------------------------------------------------------------------------')\n","    print(f'Esempi nel Dataset di Test                             : {len(test_input_data)}')\n","    print(f'Frase più corta nel Dataset Input di Test              : {min(test_input_data, key = len)}')\n","    print(f'Frase più corta nel Dataset Target di Test             : {min(test_target_data, key = len)}')\n","    print(f'Frase più lunga nel Dataset Input di Test              : {max(test_input_data, key = len)}')\n","    print(f'Frase più lunga nel Dataset Target di Test             : {max(test_target_data, key = len)}')    \n","\n","    print('\\n--------------------------------- EXAMPLE ---------------------------------------------')\n","    print([min(train_input_data, key = len)])\n","    print(tokenizers.multilingual.tokenize([min(train_input_data, key = len)])['input_word_ids'][:, :32])\n","    print('------------------------------------------------------------------')\n","    print([min(train_target_data, key = len)])\n","    print(tokenizers.ita.tokenize([min(train_target_data, key = len)]))\n","    print('\\n')\n","    print([max(train_input_data, key = len)])\n","    print(tokenizers.multilingual.tokenize([max(train_input_data, key = len)])['input_word_ids'])\n","    print('------------------------------------------------------------------')\n","    print([max(train_target_data, key = len)])\n","    print(tokenizers.ita.tokenize([max(train_target_data, key = len)]))  \n","  \n","  return train_input_data, validation_input_data, test_input_data, train_target_data, validation_target_data, test_target_data "],"metadata":{"id":"ESHUcQtthhd2","executionInfo":{"status":"ok","timestamp":1679779614953,"user_tz":-60,"elapsed":23,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","source":["def prepare_batch(multilingual, ita):\n","  zero = tf.zeros([BATCH_SIZE, MAX_SEQ_LENGTH], tf.int32)\n","\n","  # Tokenizzo l'input per l'Encoder\n","  encoder = tokenizers.multilingual.tokenize(multilingual)          \n","\n","  # Tokenizzo l'input per il Decder e creo la variabile Target\n","  ita = tokenizers.ita.tokenize(ita)\n","  decoder = ita[:, :-1].to_tensor()  # Drop the [END] tokens\n","  target = ita[:, 1:].to_tensor()   # Drop the [START] tokens\n","  \n","  decoder = tf.concat([decoder, zero], 1)\n","  decoder = decoder[:, :(MAX_SEQ_LENGTH)]\n","\n","  target = tf.concat([target, zero], 1)\n","  target = target[:, :(MAX_SEQ_LENGTH)]\n","\n","  return (encoder, decoder), target"],"metadata":{"id":"ccH3jHoABPzV","executionInfo":{"status":"ok","timestamp":1679779614954,"user_tz":-60,"elapsed":22,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}}},"execution_count":26,"outputs":[]},{"cell_type":"code","source":["def make_batches(ds):\n","  return (\n","    ds\n","    .shuffle(BUFFER_SIZE)\n","    .batch(BATCH_SIZE)\n","    .map(prepare_batch, tf.data.AUTOTUNE)\n","    .prefetch(buffer_size=tf.data.AUTOTUNE))"],"metadata":{"id":"l_dswlCiBTdR","executionInfo":{"status":"ok","timestamp":1679779614955,"user_tz":-60,"elapsed":21,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}}},"execution_count":27,"outputs":[]},{"cell_type":"code","source":["def train_val_test_dataset(df: pd.DataFrame, \n","                          filter_column: str, \n","                          debug: bool = False) -> Tuple:\n","\n","  # Recupero il dataset \n","  train_input_data, validation_input_data, test_input_data, train_target_data, validation_target_data, test_target_data = split_dataset(df=df, filter_column=filter_column, debug=debug)\n","\n","  # Definizione del dataset\n","  # [from_tensor_slices] permette di recuperare batch\n","  # di esempi dai dataset di riferimento\n","  train_dataset = tf.data.Dataset.from_tensor_slices((train_input_data, train_target_data))\n","  validation_dataset = tf.data.Dataset.from_tensor_slices((validation_input_data, validation_target_data))\n","  test_dataset = tf.data.Dataset.from_tensor_slices((test_input_data, test_target_data))\n","\n","  # impostazione del recupero di esempi presi in maniera\n","  # casuale in gruppi di [BATCH_SIZE] tra quelli disponibili\n","  train_dataset = make_batches(train_dataset)\n","  validation_dataset = make_batches(validation_dataset)\n","\n","  return train_dataset, validation_dataset, test_dataset"],"metadata":{"id":"tktJ5YuIsYe3","executionInfo":{"status":"ok","timestamp":1679779614956,"user_tz":-60,"elapsed":21,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}}},"execution_count":28,"outputs":[]},{"cell_type":"code","source":["train_dataset_ita, validation_dataset_ita, test_dataset = train_val_test_dataset(df=df,\n","                                                                                 filter_column='ITA',\n","                                                                                 debug=debug)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nkcyLV1qqQHL","executionInfo":{"status":"ok","timestamp":1679779622805,"user_tz":-60,"elapsed":7869,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}},"outputId":"a0863233-8744-4162-c8f9-4df4caf5e96e"},"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["Lunghezza df 379582\n","Lunghezza dataset 244398\n","Dati totali presenti nel Dataset               : 379582\n","Dati totali presenti nel Dataset di Train      : 170912\n","Dati totali presenti nel Dataset di Validation : 73248\n","Dati totali presenti nel Dataset di Test       : 238\n","\n","----------------------------------- TRAIN SET -----------------------------------------\n","['Ik wil weten wat er met haar gebeurd is . ', ' Tom sabe bailar ? ', 'Wer bestimmt über die Zeit ? ', \"If you can' t have children , you could always adopt . \"]\n","['Voglio sapere cosa le è successo . ', 'Tom sa ballare ? ', 'Chi comanda il tempo ? ', 'Se non puoi avere bambini , puoi sempre adottarne . ']\n","--------------------------------- VALIDATION SET --------------------------------------\n","[\"Donnez moi un hamburger , s' il vous plaît . \", \"I' m not satisfied with my English ability . \", 'La casa està frìa . ', 'Deberìas comer màs fruta . ']\n","['Datemi un hamburger , per piacere . ', 'Non sono soddisfatto della mia padronanza della lingua inglese . ', 'La casa è fredda . ', 'Dovresti mangiare più frutta . ']\n","----------------------------------- TEST SET ------------------------------------------\n","['Nein ? ', 'Was ? ', 'Nie . ', 'Ja . ']\n","['No ? ', 'Cosa ? ', 'Mai . ', 'Sì . ']\n","-------------------------------- ANALISI DATI -----------------------------------------\n","Esempi nel Dataset di Train                            : 170912\n","Frase più corta nel Dataset Input di Train             : Où ? \n","Frase più corta nel Dataset Target di Train            : No ! \n","Frase più lunga nel Dataset Input di Train             : There is no such thing , at this stage of the world' s history in The United States of America , as an independent press . You know it and I know it . There is not one of you who dare write your honest opinions , and if you did , you know beforehand that it would never appear in print . I am paid weekly for keeping my honest opinions out of the paper I am connected with . Others of you are paid similar salaries for similar things , and any of you who would be foolish as to write honest opinions would be out on the streets looking for another job . If I allowed my honest opinions to appear in one issue of my papers , before twenty four hours my occupation would be gone . The business of the journalist is to destroy the truth , to lie outright , to pervert , to vilify , to fawn at the feet of Mammon , and to sell his country and his race for his daily bread . You know it and I know it , and what folly is this toasting an independent press ? We are the jumping jacks , they pull the strings and we dance . Our talents , our possibilities and our lives are all the property of other men . We are intellectual prostitutes . \n","Frase più lunga nel Dataset Target di Train            : Lasciando adunque indietro le cose circa un Principe immaginate , e discorrendo quelle che son vere , dico , che tutti gli uomini , quando se ne parla , e massime i Principi , per esser posti più alto , sono notati di alcune di queste qualità che arrecano loro o biasimo , o laude; e questo è che alcuno è tenuto liberale , alcuno misero , usando uno termine Toscano , perchè avaro in nostra lingua è ancor colui che per rapina desidera d' avere , e misero chiamiamo quello che si astiene dall' usare il suo alcuno è tenuto donatore , alcuno rapace; alcuno crudele , alcuno pietoso; l' uno fedifrago , l' altro fedele; l' uno effeminato e pusillanime , l' altro feroce e animoso; l' uno umano , l' altro superbo; l' uno lascivo , l' altro casto; l' uno intero , l' altro astuto; l' uno duro , l' altro facile; l' uno grave , l' altro leggiere; l' uno religioso , l' altro incredulo , e simili . Io so che ciascuno confesserà , che sarebbe laudabilissima cosa un Principe trovarsi di tutte le sopraddette qualità , quelle che sono tenute buone; ma perchè non si possono avere , nè interamente osservare per le condizioni umane che non lo consentono , gli è necessario essere tanto prudente , che sappia fuggire l' infamia di quelli vizi che li torrebbono lo Stato , e da quelli che non gliene tolgano , guardarsi , se egli è possibile; ma non potendosi , si può con minor rispetto lasciare andare . Ed ancora . . . \n","---------------------------------------------------------------------------------------\n","Esempi nel Dataset di Validation                       : 73248\n","Frase più corta nel Dataset Input di Validation        : Ja . \n","Frase più corta nel Dataset Target di Validation       : Sì . \n","Frase più lunga nel Dataset Input di Validation        : There is no such thing , at this stage of the world' s history in America , as an independent press . You know it and I know it . There is not one of you who dare write your honest opinions , and if you did , you know beforehand that it would never appear in print . I am paid weekly for keeping my honest opinions out of the paper I am connected with . Others of you are paid similar salaries for similar things , and any of you who would be foolish as to write honest opinions would be out on the streets looking for another job . If I allowed my honest opinions to appear in one issue of my papers , before twenty four hours my occupation would be gone . The business of the journalist is to destroy the truth , to lie outright , to pervert , to vilify , to fawn at the feet of Mammon , and to sell his country and his race for his daily bread . You know it and I know it , and what folly is this toasting an independent press ? We are the jumping jacks , they pull the strings and we dance . Our talents , our possibilities and our lives are all the property of other men . We are intellectual prostitutes . \n","Frase più lunga nel Dataset Target di Validation       : Non vi è nulla di simile , in questa fase della storia del mondo in America , come una stampa indipendente . Tu lo sai e io lo so . Non c' è nessuno di voi che osa scrivere le proprie opinioni oneste , e se l' avete fatto , si sa in anticipo che non apparirebbe mai in stampa Io sono pagato settimanalmente per tenere le mie opinioni oneste fuori dal giornale a cui sono collegato . Altri di voi sono pagati con stipendi simili per cose simili , e chiunque di voi che sarebbe sciocco da scrivere opinioni oneste sarebbe fuori per le strade in cerca di un altro lavoro . Se ho lasciato le mie opinioni oneste di apparire in una questione di mie carte , prima di 24 ore la mia occupazione sarebbe andato . L' attività del giornalista è quella di distruggere la verità , di mentire apertamente , di pervertire , di diffamare , di strisciare ai piedi di Mammona , e di vendere il suo paese e la sua razza per il suo pane quotidiano . Tu lo sai e io lo so , e che follia è questo brindare per una stampa indipendente ? Noi siamo i burattini , loro tirano i fili e noi balliamo . I nostri talenti , le nostre possibilità e le nostre vite sono tutte proprietà di altri uomini . Noi siamo delle prostitute intellettuali . \n","---------------------------------------------------------------------------------------\n","Esempi nel Dataset di Test                             : 238\n","Frase più corta nel Dataset Input di Test              : Ja . \n","Frase più corta nel Dataset Target di Test             : No ? \n","Frase più lunga nel Dataset Input di Test              : Interessant . \n","Frase più lunga nel Dataset Target di Test             : Tom sta facendo i bagagli . \n","\n","--------------------------------- EXAMPLE ---------------------------------------------\n","['Où ? ']\n","tf.Tensor(\n","[[  101   152 13580   136   102     0     0     0     0     0     0     0\n","      0     0     0     0     0     0     0     0     0     0     0     0\n","      0     0     0     0     0     0     0     0]], shape=(1, 32), dtype=int32)\n","------------------------------------------------------------------\n","['No ! ']\n","<tf.RaggedTensor [[2, 218, 4, 3]]>\n","\n","\n","[\"There is no such thing , at this stage of the world' s history in The United States of America , as an independent press . You know it and I know it . There is not one of you who dare write your honest opinions , and if you did , you know beforehand that it would never appear in print . I am paid weekly for keeping my honest opinions out of the paper I am connected with . Others of you are paid similar salaries for similar things , and any of you who would be foolish as to write honest opinions would be out on the streets looking for another job . If I allowed my honest opinions to appear in one issue of my papers , before twenty four hours my occupation would be gone . The business of the journalist is to destroy the truth , to lie outright , to pervert , to vilify , to fawn at the feet of Mammon , and to sell his country and his race for his daily bread . You know it and I know it , and what folly is this toasting an independent press ? We are the jumping jacks , they pull the strings and we dance . Our talents , our possibilities and our lives are all the property of other men . We are intellectual prostitutes . \"]\n","tf.Tensor(\n","[[  101 11723 10124 10192 11049 40414   117 10160 10531 15365 10108 10105\n","  11356   112   187 11486 10106 10117 10609 10859 10108 11440   117 10146\n","  10151 16584 21040   119 11065 21852 10271 10111   146 21852 10271   119\n","  11723 10124 10472 10464 10108 13028 10479 45476 28685 20442 14923 13051\n","  72773   117 10111 12277 13028 12172   117 13028 21852 11360 41137 10189\n","  10271 10894 14794 22641 10106 31210   119   146 10392 25938 33159 10142\n","  51318 15127 14923 13051 72773 10950 10108 10105 17895   146 10392 26989\n","  10169   119 64738 10108 13028 10301 25938 13213 20509 15388 10142 13213\n","  24682   117 10111 11178 10108 13028 10479 10894 10347   174 47195 15529\n","  10146 10114 28685 14923 13051 72773 10894 10347 10950 10135 10105 41969\n","  34279 10142 12864 23627   119 14535   146   102]], shape=(1, 128), dtype=int32)\n","------------------------------------------------------------------\n","[\"Lasciando adunque indietro le cose circa un Principe immaginate , e discorrendo quelle che son vere , dico , che tutti gli uomini , quando se ne parla , e massime i Principi , per esser posti più alto , sono notati di alcune di queste qualità che arrecano loro o biasimo , o laude; e questo è che alcuno è tenuto liberale , alcuno misero , usando uno termine Toscano , perchè avaro in nostra lingua è ancor colui che per rapina desidera d' avere , e misero chiamiamo quello che si astiene dall' usare il suo alcuno è tenuto donatore , alcuno rapace; alcuno crudele , alcuno pietoso; l' uno fedifrago , l' altro fedele; l' uno effeminato e pusillanime , l' altro feroce e animoso; l' uno umano , l' altro superbo; l' uno lascivo , l' altro casto; l' uno intero , l' altro astuto; l' uno duro , l' altro facile; l' uno grave , l' altro leggiere; l' uno religioso , l' altro incredulo , e simili . Io so che ciascuno confesserà , che sarebbe laudabilissima cosa un Principe trovarsi di tutte le sopraddette qualità , quelle che sono tenute buone; ma perchè non si possono avere , nè interamente osservare per le condizioni umane che non lo consentono , gli è necessario essere tanto prudente , che sappia fuggire l' infamia di quelli vizi che li torrebbono lo Stato , e da quelli che non gliene tolgano , guardarsi , se egli è possibile; ma non potendosi , si può con minor rispetto lasciare andare . Ed ancora . . . \"]\n","<tf.RaggedTensor [[2, 3626, 4079, 2931, 88, 240, 1163, 84, 5369, 35, 21307, 5595, 7046, 10,\n","  31, 15292, 630, 361, 76, 154, 2240, 10, 479, 10, 76, 147, 128, 708, 10,\n","  117, 96, 103, 407, 10, 31, 17030, 3027, 35, 2992, 10, 82, 217, 2465, 94,\n","  314, 10, 91, 1064, 413, 78, 1090, 78, 331, 2753, 76, 13841, 597, 9869,\n","  122, 41, 12702, 10, 41, 12910, 22, 31, 111, 31, 76, 2428, 31, 2537,\n","  2454, 775, 10, 2428, 3399, 10, 4674, 203, 2078, 13161, 10, 126, 5485,\n","  83, 267, 296, 31, 204, 286, 76, 82, 5282, 6258, 30, 8, 335, 10, 31,\n","  3399, 8064, 174, 76, 81, 27, 1662, 9871, 597, 532, 8, 1003, 80, 113,\n","  2428, 31, 2537, 4493, 377, 10, 2428, 44, 712, 10024, 2711, 22, 2428,\n","  2242, 10, 2428, 7948, 22, 38, 8, 203, 326, 2654, 7705, 965, 3338, 10,\n","  38, 8, 145, 3034, 22, 38, 8, 203, 31, 11187, 11724, 31, 42, 12620, 3277,\n","  950, 3027, 10, 38, 8, 145, 3844, 31, 1312, 1865, 22, 38, 8, 203, 1512,\n","  10, 38, 8, 145, 3075, 22, 38, 8, 203, 12349, 10, 38, 8, 145, 12718, 22,\n","  38, 8, 203, 1754, 10, 38, 8, 145, 27, 10351, 5725, 22, 38, 8, 203, 973,\n","  10, 38, 8, 145, 795, 22, 38, 8, 203, 1098, 10, 38, 8, 145, 1547, 6106,\n","  22, 38, 8, 203, 4404, 10, 38, 8, 145, 83, 3787, 377, 3077, 20499, 10,\n","  31, 3470, 11, 85, 209, 76, 1252, 92, 12579, 10953, 10, 76, 396, 16783,\n","  383, 10028, 137, 84, 5369, 11696, 78, 254, 88, 427, 3077, 20815, 2753,\n","  10, 361, 76, 91, 2422, 10191, 1727, 22, 104, 126, 79, 81, 753, 335, 10,\n","  103, 11060, 4827, 82, 88, 2286, 3692, 76, 79, 98, 8560, 265, 10, 128,\n","  31, 1903, 155, 150, 5151, 10, 76, 1588, 3746, 38, 8, 4896, 78, 508,\n","  6104, 76, 102, 1297, 10526, 4476, 265, 98, 197, 10, 31, 95, 508, 76, 79,\n","  10844, 11691, 265, 10, 1397, 1008, 10, 96, 530, 31, 737, 22, 104, 79,\n","  3400, 11728, 10, 81, 200, 92, 2166, 1689, 1505, 196, 11, 184, 166, 11,\n","  11, 11, 3]]>\n"]}]},{"cell_type":"code","source":["# Recupero un batch di esempi per la verifica delle classi custom che andrò a creare\n","for (enc_input, dec_input), target in train_dataset_ita.take(1):\n","  print('----------------------- ENCODER  -------------------------------')\n","  print(f'Shape                    : {enc_input[\"input_word_ids\"].shape}')\n","  print(f'Word Ids                 : {enc_input[\"input_word_ids\"][0, :MAX_SEQ_LENGTH]}')\n","  print(f'Input Mask               : {enc_input[\"input_mask\"][0, :MAX_SEQ_LENGTH]}')\n","  print('--------------------- DECODER ----------------------------------')\n","  print(f'Shape it input           : {dec_input.shape}')\n","  print(f'Example it input         : {dec_input[0]}')  \n","  print('--------------------- TARGET -----------------------------------')\n","  print(f'Shape it input           : {target.shape}')\n","  print(f'Example it target        : {target[0]}')  "],"metadata":{"id":"VH_aKPlV_AWA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1679779624998,"user_tz":-60,"elapsed":2259,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}},"outputId":"226585c1-c118-4067-9895-667ccbf46261"},"execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["----------------------- ENCODER  -------------------------------\n","Shape                    : (32, 128)\n","Word Ids                 : [  101 12275 42047 10112 10109   188 22552 13340 62632 10110 10178 38154\n"," 12150   119   102     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0]\n","Input Mask               : [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n","--------------------- DECODER ----------------------------------\n","Shape it input           : (32, 128)\n","Example it input         : [   2   86  431   77 1204   83 1657   11    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0]\n","--------------------- TARGET -----------------------------------\n","Shape it input           : (32, 128)\n","Example it target        : [  86  431   77 1204   83 1657   11    3    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0]\n"]}]},{"cell_type":"markdown","source":["## Encoder BERT\n","\n","Predispondo la classe necessaria per la costruzione di BERT\n"],"metadata":{"id":"8dtVuZGJpvXl"}},{"cell_type":"code","source":["class EncoderBert(tf.keras.layers.Layer):\n","  def __init__(self, bert_encoder, embedding_dim, max_len, trainable):\n","    super(EncoderBert, self).__init__()\n","\n","    self.encoder = hub.KerasLayer(bert_encoder, name='BERT_encoder', trainable=trainable)\n","\n","    self.conv_1 = tf.keras.layers.Conv1D(embedding_dim * 4, 1, activation='relu') \n","    self.conv_2 = tf.keras.layers.Conv1D(embedding_dim, 1, activation='relu') \n","    self.lambda_layer = tf.keras.layers.Lambda(lambda x: x[:,:max_len])\n","    self.max_len = max_len\n","\n","  def call(self, x, debug=False):\n","\n","    if debug:\n","      print(f'****************** DEBUG ENCODER BERT ******************')\n","      print(f\"First example\")\n","      print(f'Keys                         : {list(x.keys())}')\n","      print(f'Shape                        : {x[\"input_word_ids\"].shape}')\n","      print(f'Word Ids                     : {x[\"input_word_ids\"][0, :16]}')\n","      print(f'Input Mask                   : {x[\"input_mask\"][0, :16]}')\n","      \n","    x = self.encoder(x)['sequence_output'] \n","    # encoder_outputs stato intermedio di BERT prima che esegua la traduzione recuperare la metà della lunghezza\n","    # x = self.encoder(x)['encoder_outputs'] \n","    # x = x[int(len(x) / 2) - 1]\n","\n","    if debug:\n","      print()\n","      print(f'Encoder Outputs BERT Shape   : {x.shape}')\n","      print(f'Encoder Outputs BERT Values  : {x[0, :1, :16]}')\n","\n","    x = self.conv_1(x)\n","    if debug:\n","      print()\n","      print(f'Sequence Conv1 Shape         : {x.shape}')\n","\n","    x = self.conv_2(x)\n","    if debug:\n","      print(f'Sequence Conv2 Shape         : {x.shape}')\n","\n","    x = self.lambda_layer(x)\n","    if debug:\n","      print(f'Sequence Lambda Layer        : {x.shape}')\n","      print()\n","      print(f'Sequence Outputs Values      : {x[0, 0, :16]}')      \n","      print('*********************************************************') \n","\n","    return x"],"metadata":{"id":"m7v9Y-Lep4CD","executionInfo":{"status":"ok","timestamp":1679779624999,"user_tz":-60,"elapsed":13,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}}},"execution_count":31,"outputs":[]},{"cell_type":"code","source":["encoder_bert = EncoderBert(tfhub_handle_encoder, \n","                           EMBEDDING_DIM, \n","                           MAX_SEQ_LENGTH,\n","                           trainable=trainable)\n","\n","bert_outputs = encoder_bert(enc_input, debug) "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Q08luTkusEfn","executionInfo":{"status":"ok","timestamp":1679779661438,"user_tz":-60,"elapsed":36450,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}},"outputId":"6b56d121-8793-45af-b5a1-b10ea3e6ce00"},"execution_count":32,"outputs":[{"output_type":"stream","name":"stdout","text":["****************** DEBUG ENCODER BERT ******************\n","First example\n","Keys                         : ['input_word_ids', 'input_mask']\n","Shape                        : (32, 128)\n","Word Ids                     : [  101 12275 42047 10112 10109   188 22552 13340 62632 10110 10178 38154\n"," 12150   119   102     0]\n","Input Mask                   : [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0]\n","\n","Encoder Outputs BERT Shape   : (32, 128, 768)\n","Encoder Outputs BERT Values  : [[ 0.04848604 -0.10759839 -0.01724488  0.09065826 -0.0623607   0.13858043\n","  -0.05283746  0.07721666 -0.04555628  0.37671697  0.25503743 -0.04761208\n","  -0.17173856  0.15402727 -0.66927457  0.10745171]]\n","\n","Sequence Conv1 Shape         : (32, 128, 512)\n","Sequence Conv2 Shape         : (32, 128, 128)\n","Sequence Lambda Layer        : (32, 128, 128)\n","\n","Sequence Outputs Values      : [0.         0.44339508 0.         0.         0.631033   0.\n"," 0.33922914 0.         0.         0.14248236 0.65473604 0.\n"," 0.         0.         0.55974555 0.        ]\n","*********************************************************\n"]}]},{"cell_type":"markdown","source":["## Decoder\n","\n","Predispondo la classe necessaria per la costruzione di un Layer di Decoder"],"metadata":{"id":"ReEQ5rX7aGtl"}},{"cell_type":"markdown","source":["### TOKEN AND POSITION EMBEDDING\n","\n","Implementazione del blocco Embedding per l'utilizzo di vettori posizionali insieme ai vettori di token di parole tramite estensione della classe Layer di Keras. "],"metadata":{"id":"gAu1IXlRZzlq"}},{"cell_type":"code","source":["class TokenAndPositionEmbedding(tf.keras.layers.Layer):\n","  def __init__(self, maxlen, vocab_size, embed_dim):\n","    super(TokenAndPositionEmbedding, self).__init__()\n","    self.maxlen = maxlen\n","    self.token_emb = tf.keras.layers.Embedding(input_dim=vocab_size, output_dim=embed_dim)\n","    self.pos_emb = tf.keras.layers.Embedding(input_dim=maxlen, output_dim=embed_dim)\n","\n","  def call(self, x, debug=False):\n","    x = tf.keras.preprocessing.sequence.pad_sequences(x, maxlen=self.maxlen, padding='post')\n","    maxlen = tf.shape(x)[-1]\n","\n","    if debug:\n","      print('********** DEBUG TOKEN AND POSITION EMBEDDING ***********')\n","      print(f'Sequence Max len                          : {maxlen}')\n","      print(f'Sequence Shape                            : {tf.shape(x)}')\n","\n","    positions = tf.range(start=0, limit=maxlen, delta=1)\n","    positions = self.pos_emb(positions)\n","    x = self.token_emb(x)\n","    output = x + positions\n","\n","    if debug:\n","      print(f'Shape TokenAndPositionEmbedding           : {output.shape}')\n","      print('*********************************************************')\n","\n","    return output"],"metadata":{"id":"o9-RSKTqsmUC","executionInfo":{"status":"ok","timestamp":1679779661439,"user_tz":-60,"elapsed":22,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}}},"execution_count":33,"outputs":[]},{"cell_type":"code","source":["token_position_it = TokenAndPositionEmbedding(MAX_SEQ_LENGTH, tokenizers.ita.get_vocab_size(), EMBEDDING_DIM)\n","\n","inputs_decoder = token_position_it(dec_input, debug)"],"metadata":{"id":"rr_EWQUX8EWP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1679779661440,"user_tz":-60,"elapsed":22,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}},"outputId":"c5c2c200-c718-4785-a8a7-b9f837b08ba9"},"execution_count":34,"outputs":[{"output_type":"stream","name":"stdout","text":["********** DEBUG TOKEN AND POSITION EMBEDDING ***********\n","Sequence Max len                          : 128\n","Sequence Shape                            : [ 32 128]\n","Shape TokenAndPositionEmbedding           : (32, 128, 128)\n","*********************************************************\n"]}]},{"cell_type":"markdown","source":["### LAYER DECODER\n","\n","Implementazione di un blocco di DecoderTransformer tramite estensione della classe Layer di Keras"],"metadata":{"id":"XdLv-6nidKGK"}},{"cell_type":"markdown","source":["#### DecodeBert\n","\n","Implmentazione di un blocco di  decodifica custom per decodificare l'output dal layer EncoderBert prima di passarlo al Decoder del Transformer tramite estensione della classe Layer di Keras"],"metadata":{"id":"_iq7Y-d4eRd8"}},{"cell_type":"code","source":["class DecodeBert(tf.keras.layers.Layer):\n","  def __init__(self, max_len, embed_dim, num_heads, ff_dim, rate=0.5, name='DecodeBert'):\n","    super(DecodeBert, self).__init__()\n","    self.att = tf.keras.layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n","    self.ffn = tf.keras.Sequential(\n","      [tf.keras.layers.Dense(ff_dim, activation='relu'), \n","       tf.keras.layers.Dense(embed_dim),]\n","    )\n","    self.layernorm1 = tf.keras.layers.LayerNormalization()\n","    self.layernorm2 = tf.keras.layers.LayerNormalization()\n","    self.dropout1 = tf.keras.layers.Dropout(rate)\n","    self.dropout2 = tf.keras.layers.Dropout(rate)\n","    self._name = name\n","\n","  def call(self, bert_outputs, training=False, debug=False):\n","    attn_output = self.att(query=bert_outputs,\n","                           value=bert_outputs, \n","                           key=bert_outputs)\n","    \n","    attn_output = self.dropout1(attn_output)\n","    out1 = self.layernorm1(bert_outputs + attn_output)\n","\n","    ffn_output = self.ffn(out1)\n","    ffn_output = self.dropout2(ffn_output, training=training)\n","\n","    output = self.layernorm2(out1 + ffn_output)\n","\n","    if debug:\n","      print('********************* DEBUG DECODE-BERT *********************')\n","      print(f'Shape Input Layer Decode-Bert       : {bert_outputs.shape}')\n","      print(f'Shape Output Layer Decode-Bert      : {output.shape}')\n","      print('*********************************************************')\n","\n","    return output"],"metadata":{"id":"joTBTlWF8ETD","executionInfo":{"status":"ok","timestamp":1679779661440,"user_tz":-60,"elapsed":20,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}}},"execution_count":35,"outputs":[]},{"cell_type":"code","source":["encoder = DecodeBert(MAX_SEQ_LENGTH, \n","                  EMBEDDING_DIM, \n","                  NUM_HEADS, \n","                  FF_DIM, \n","                  DROPUOT)\n","\n","outputs_encoder = encoder(bert_outputs=bert_outputs,\n","                          training=training, \n","                          debug=debug)"],"metadata":{"id":"JaIzBxFCfKe9","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1679779661969,"user_tz":-60,"elapsed":549,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}},"outputId":"a317d033-c3a0-42d6-ed28-f2c528cee199"},"execution_count":36,"outputs":[{"output_type":"stream","name":"stdout","text":["********************* DEBUG DECODE-BERT *********************\n","Shape Input Layer Decode-Bert       : (32, 128, 128)\n","Shape Output Layer Decode-Bert      : (32, 128, 128)\n","*********************************************************\n"]}]},{"cell_type":"markdown","source":["#### Layer Decoder"],"metadata":{"id":"dMTKLwd3dRw5"}},{"cell_type":"code","source":["class Decoder(tf.keras.layers.Layer):\n","  def __init__(self, max_len, embed_dim, num_heads, ff_dim, rate=0.5, name='DEC'):\n","    super(Decoder, self).__init__()\n","    self.decode_bert = DecodeBert(max_len=max_len, embed_dim=embed_dim, num_heads=num_heads, ff_dim=ff_dim, rate=rate)\n","    self.att1 = tf.keras.layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n","    self.att2 = tf.keras.layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n","    self.ffn = tf.keras.Sequential(\n","      [tf.keras.layers.Dense(ff_dim, activation='relu'), \n","       tf.keras.layers.Dense(embed_dim),]\n","    )\n","    self.layernorm1 = tf.keras.layers.LayerNormalization()\n","    self.layernorm2 = tf.keras.layers.LayerNormalization()\n","    self.layernorm3 = tf.keras.layers.LayerNormalization()\n","    self.dropout1 = tf.keras.layers.Dropout(rate)\n","    self.dropout2 = tf.keras.layers.Dropout(rate)\n","    self.dropout3 = tf.keras.layers.Dropout(rate)\n","    self._name = name\n","\n","  def call(self, inputs, bert_outputs, training=False, debug=False):\n","    attn_output1 = self.att1(query=inputs,\n","                             value=inputs, \n","                             key=inputs, \n","                             use_causal_mask=True)\n","    \n","    attn_output1 = self.dropout1(attn_output1)\n","    out1 = self.layernorm1(inputs + attn_output1)\n","\n","    dec_bert = self.decode_bert(bert_outputs=bert_outputs, training=training, debug=debug)\n","\n","    attn_output2 = self.att2(key=dec_bert, \n","                             value=dec_bert, \n","                             query=out1)\n","    \n","    attn_output2 = self.dropout2(attn_output2, training=training)\n","    out2 = self.layernorm2(out1 + attn_output2)\n","\n","    ffn_output = self.ffn(out2)\n","    ffn_output = self.dropout3(ffn_output, training=training)\n","\n","    output = self.layernorm3(out2 + ffn_output)\n","\n","    if debug:\n","      print('******************* DEBUG DECODER ***********************')\n","      print(f'Input Shape                       : {inputs.shape}')\n","      print(f'Shape Outputs Decoder             : {output.shape}')\n","      print('*********************************************************')\n","\n","    return output"],"metadata":{"id":"SO5rYsFpfFS_","executionInfo":{"status":"ok","timestamp":1679779662440,"user_tz":-60,"elapsed":4,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}}},"execution_count":37,"outputs":[]},{"cell_type":"code","source":["decoder = Decoder(MAX_SEQ_LENGTH, \n","                  EMBEDDING_DIM, \n","                  NUM_HEADS, \n","                  FF_DIM, \n","                  DROPUOT)\n","\n","outputs_decoder = decoder(inputs=inputs_decoder, \n","                          bert_outputs=bert_outputs,  \n","                          training=training,\n","                          debug=debug)"],"metadata":{"id":"yysVdkHH8EPH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1679779664370,"user_tz":-60,"elapsed":1934,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}},"outputId":"bd329943-1cff-4c34-cbe8-4587e0248f66"},"execution_count":38,"outputs":[{"output_type":"stream","name":"stdout","text":["********************* DEBUG DECODE-BERT *********************\n","Shape Input Layer Decode-Bert       : (32, 128, 128)\n","Shape Output Layer Decode-Bert      : (32, 128, 128)\n","*********************************************************\n","******************* DEBUG DECODER ***********************\n","Input Shape                       : (32, 128, 128)\n","Shape Outputs Decoder             : (32, 128, 128)\n","*********************************************************\n"]}]},{"cell_type":"markdown","source":["## TRANSFORMER\n","\n","Implementazione del blocco Transformer tramite estensione della classe Layer di Keras."],"metadata":{"id":"ne4zTOG_NKfV"}},{"cell_type":"code","execution_count":39,"metadata":{"pycharm":{"name":"#%%\n"},"id":"lw2xMCAMC_4M","executionInfo":{"status":"ok","timestamp":1679779664370,"user_tz":-60,"elapsed":6,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}}},"outputs":[],"source":["class TransformerBlock(tf.keras.Model):\n","  def __init__(self, \n","               num_layers, \n","               embed_dim, \n","               num_heads, \n","               ff_dim, \n","               max_len,\n","               vocab_size,\n","               tfhub_handle_encoder,\n","               trainable,\n","               rate=0.5):\n","    \n","    super(TransformerBlock, self).__init__()\n","\n","    self.num_layers = num_layers\n","\n","    self.token_pos_dec = TokenAndPositionEmbedding(max_len, vocab_size, embed_dim)\n","\n","    self.encoder = EncoderBert(tfhub_handle_encoder, embed_dim, max_len, trainable=trainable)\n","    self.decoder = [Decoder(max_len, embed_dim, num_heads, ff_dim, rate) for _ in range(num_layers)]\n","\n","    self.dropout = tf.keras.layers.Dropout(rate)\n","    self.final_layer = tf.keras.layers.Dense(vocab_size)\n","\n","  def call(self, inputs, training=False, debug=False):\n","    inputs_encoder, inputs_decoder  = inputs\n","\n","    encoder_output = self.encoder(inputs_encoder, debug) \n","\n","    inputs_decoder = self.token_pos_dec(inputs_decoder, debug)\n","\n","    if debug:\n","      print(f'---------------- DEBUG TRANSFORMER BLOCK ----------------')\n","      print(f'inputs_encoder       : {inputs_encoder[\"input_word_ids\"].shape}')\n","      print(f'inputs_decoder       : {inputs_decoder.shape}')      \n","\n","    transformer_output = inputs_decoder\n","      \n","    for i in range(self.num_layers):\n","      transformer_output = self.decoder[i](inputs=transformer_output, \n","                                           bert_outputs=encoder_output, \n","                                           training=training,\n","                                           debug=debug)\n","\n","    transformer_output = self.dropout(transformer_output)\n","    logits = self.final_layer(transformer_output)\n","\n","    if debug:\n","      print(f'Output Shape       : {logits.shape}')\n","      print(f'Output Transformer : {logits[0, :1, :12]}')    \n","      print(f'---------------------------------------------------------')\n","\n","    return logits"]},{"cell_type":"code","source":["transformer = TransformerBlock(NUM_LAYERS, \n","                               EMBEDDING_DIM, \n","                               NUM_HEADS, \n","                               FF_DIM,\n","                               MAX_SEQ_LENGTH,\n","                               tokenizers.ita.get_vocab_size(),\n","                               tfhub_handle_encoder,\n","                               trainable,\n","                               DROPUOT)\n","\n","transformer_output = transformer((enc_input, dec_input), \n","                                 training=training,\n","                                 debug=debug)"],"metadata":{"id":"pr--G0ZZVAMi","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1679779683420,"user_tz":-60,"elapsed":19054,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}},"outputId":"1f834a4e-5fc4-45eb-f117-759a97e0200c"},"execution_count":40,"outputs":[{"output_type":"stream","name":"stdout","text":["****************** DEBUG ENCODER BERT ******************\n","First example\n","Keys                         : ['input_word_ids', 'input_mask']\n","Shape                        : (32, 128)\n","Word Ids                     : [  101 12275 42047 10112 10109   188 22552 13340 62632 10110 10178 38154\n"," 12150   119   102     0]\n","Input Mask                   : [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0]\n","\n","Encoder Outputs BERT Shape   : (32, 128, 768)\n","Encoder Outputs BERT Values  : [[ 0.07262096 -0.01234376  0.04837552  0.14048988 -0.04718706  0.15593298\n","  -0.02821947 -0.00989918 -0.04718901  0.40328535  0.2711571  -0.02822326\n","  -0.06814844  0.1053661  -0.67953503  0.13173525]]\n","\n","Sequence Conv1 Shape         : (32, 128, 512)\n","Sequence Conv2 Shape         : (32, 128, 128)\n","Sequence Lambda Layer        : (32, 128, 128)\n","\n","Sequence Outputs Values      : [0.         0.         0.         0.         0.61504394 0.\n"," 0.08375571 0.11049809 0.         0.         0.017312   0.\n"," 0.05015797 0.         0.25155354 0.09382032]\n","*********************************************************\n","********** DEBUG TOKEN AND POSITION EMBEDDING ***********\n","Sequence Max len                          : 128\n","Sequence Shape                            : [ 32 128]\n","Shape TokenAndPositionEmbedding           : (32, 128, 128)\n","*********************************************************\n","---------------- DEBUG TRANSFORMER BLOCK ----------------\n","inputs_encoder       : (32, 128)\n","inputs_decoder       : (32, 128, 128)\n","********************* DEBUG DECODE-BERT *********************\n","Shape Input Layer Decode-Bert       : (32, 128, 128)\n","Shape Output Layer Decode-Bert      : (32, 128, 128)\n","*********************************************************\n","******************* DEBUG DECODER ***********************\n","Input Shape                       : (32, 128, 128)\n","Shape Outputs Decoder             : (32, 128, 128)\n","*********************************************************\n","Output Shape       : (32, 128, 23120)\n","Output Transformer : [[-0.10267117  0.04374016  0.03808984 -0.29947582  0.04218493 -0.05982141\n","  -0.09493374  0.04365141  0.08810249  0.14079696  0.19349201  0.09492312]]\n","---------------------------------------------------------\n"]}]},{"cell_type":"code","source":["transformer.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0kYt6ehvh-8B","executionInfo":{"status":"ok","timestamp":1679779683421,"user_tz":-60,"elapsed":65,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}},"outputId":"875f466f-7a12-45ac-a788-a65d3d38f04e"},"execution_count":41,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"transformer_block\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," token_and_position_embeddin  multiple                 2975744   \n"," g_1 (TokenAndPositionEmbedd                                     \n"," ing)                                                            \n","                                                                 \n"," encoder_bert_1 (EncoderBert  multiple                 135193472 \n"," )                                                               \n","                                                                 \n"," DEC (Decoder)               multiple                  1592224   \n","                                                                 \n"," dropout_16 (Dropout)        multiple                  0         \n","                                                                 \n"," dense_10 (Dense)            multiple                  2982480   \n","                                                                 \n","=================================================================\n","Total params: 142,743,920\n","Trainable params: 142,743,920\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"markdown","source":["## Addestramento Modello"],"metadata":{"id":"IFmcHTSDTvYk"}},{"cell_type":"markdown","source":["### Compilazione"],"metadata":{"id":"tiuqPlHo0Z0n"}},{"cell_type":"code","source":["transformer.compile(\n","  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n","  optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE_ADAM, \n","                                     beta_1=BETA_1, \n","                                     beta_2=BETA_2),\n","  metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])"],"metadata":{"id":"bOyqCyjIr-L2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Callbacks"],"metadata":{"id":"-z6qj1uclHRa"}},{"cell_type":"code","source":["# Create a callback that saves the model's weights\n","cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n","                                                 save_weights_only=True,\n","                                                 save_best_only=True)\n","\n","# Create a callback Tensorboard\n","tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir)\n","\n","# Create a callback save the log history\n","json_logging_callback = tf.keras.callbacks.LambdaCallback(\n","  on_epoch_end=lambda epoch, logs: json_log.write(\n","    json.dumps({'epoch': epoch, \n","                'loss': logs['loss'],\n","                'sparse_categorical_accuracy': logs['sparse_categorical_accuracy'],\n","                'val_loss': logs['val_loss'],\n","                'val_sparse_categorical_accuracy': logs['val_sparse_categorical_accuracy']}) + '\\n'),\n","  on_train_end=lambda logs: json_log.close()\n",")"],"metadata":{"id":"3hurmpSjJ_dT"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Train Ita"],"metadata":{"id":"Day7C7Qh0b4G"}},{"cell_type":"code","source":["start = datetime.datetime.now()\n","json_log = open(log_history, mode='a', buffering=1, encoding='utf-8')\n","\n","transformer.fit(train_dataset_ita,\n","                initial_epoch=0,\n","                epochs=EPOCHS_ADAM,\n","                shuffle=True,\n","                validation_data=validation_dataset_ita,\n","                callbacks=[tensorboard_callback,\n","                           json_logging_callback, \n","                           cp_callback])\n","\n","end = datetime.datetime.now()\n","print(f'Tempo necessario per l\\'addestramento: {end - start}')"],"metadata":{"id":"etOGtBcer9yi","colab":{"base_uri":"https://localhost:8080/"},"outputId":"04663486-4e59-43f1-b28d-eda32778355d","executionInfo":{"status":"ok","timestamp":1679617258039,"user_tz":-60,"elapsed":12284959,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/20\n","542/542 [==============================] - 617s 1s/step - loss: 3.2438 - sparse_categorical_accuracy: 0.9020 - val_loss: 0.6460 - val_sparse_categorical_accuracy: 0.9225\n","Epoch 2/20\n","542/542 [==============================] - 575s 1s/step - loss: 0.5874 - sparse_categorical_accuracy: 0.9274 - val_loss: 0.4974 - val_sparse_categorical_accuracy: 0.9334\n","Epoch 3/20\n","542/542 [==============================] - 584s 1s/step - loss: 0.4951 - sparse_categorical_accuracy: 0.9335 - val_loss: 0.4557 - val_sparse_categorical_accuracy: 0.9362\n","Epoch 4/20\n","542/542 [==============================] - 575s 1s/step - loss: 0.4565 - sparse_categorical_accuracy: 0.9360 - val_loss: 0.4294 - val_sparse_categorical_accuracy: 0.9387\n","Epoch 5/20\n","542/542 [==============================] - 623s 1s/step - loss: 0.4282 - sparse_categorical_accuracy: 0.9384 - val_loss: 0.4060 - val_sparse_categorical_accuracy: 0.9410\n","Epoch 6/20\n","542/542 [==============================] - 601s 1s/step - loss: 0.4033 - sparse_categorical_accuracy: 0.9411 - val_loss: 0.3834 - val_sparse_categorical_accuracy: 0.9438\n","Epoch 7/20\n","542/542 [==============================] - 603s 1s/step - loss: 0.3808 - sparse_categorical_accuracy: 0.9434 - val_loss: 0.3646 - val_sparse_categorical_accuracy: 0.9460\n","Epoch 8/20\n","542/542 [==============================] - 569s 1s/step - loss: 0.3597 - sparse_categorical_accuracy: 0.9458 - val_loss: 0.3454 - val_sparse_categorical_accuracy: 0.9482\n","Epoch 9/20\n","542/542 [==============================] - 602s 1s/step - loss: 0.3404 - sparse_categorical_accuracy: 0.9481 - val_loss: 0.3316 - val_sparse_categorical_accuracy: 0.9501\n","Epoch 10/20\n","542/542 [==============================] - 600s 1s/step - loss: 0.3231 - sparse_categorical_accuracy: 0.9501 - val_loss: 0.3191 - val_sparse_categorical_accuracy: 0.9517\n","Epoch 11/20\n","542/542 [==============================] - 562s 1s/step - loss: 0.3077 - sparse_categorical_accuracy: 0.9520 - val_loss: 0.3053 - val_sparse_categorical_accuracy: 0.9534\n","Epoch 12/20\n","542/542 [==============================] - 599s 1s/step - loss: 0.2924 - sparse_categorical_accuracy: 0.9539 - val_loss: 0.2959 - val_sparse_categorical_accuracy: 0.9549\n","Epoch 13/20\n","542/542 [==============================] - 599s 1s/step - loss: 0.2789 - sparse_categorical_accuracy: 0.9557 - val_loss: 0.2856 - val_sparse_categorical_accuracy: 0.9568\n","Epoch 14/20\n","542/542 [==============================] - 598s 1s/step - loss: 0.2661 - sparse_categorical_accuracy: 0.9574 - val_loss: 0.2767 - val_sparse_categorical_accuracy: 0.9579\n","Epoch 15/20\n","542/542 [==============================] - 564s 1s/step - loss: 0.2541 - sparse_categorical_accuracy: 0.9589 - val_loss: 0.2715 - val_sparse_categorical_accuracy: 0.9589\n","Epoch 16/20\n","542/542 [==============================] - 599s 1s/step - loss: 0.2426 - sparse_categorical_accuracy: 0.9605 - val_loss: 0.2641 - val_sparse_categorical_accuracy: 0.9604\n","Epoch 17/20\n","542/542 [==============================] - 596s 1s/step - loss: 0.2315 - sparse_categorical_accuracy: 0.9619 - val_loss: 0.2592 - val_sparse_categorical_accuracy: 0.9614\n","Epoch 18/20\n","542/542 [==============================] - 598s 1s/step - loss: 0.2212 - sparse_categorical_accuracy: 0.9633 - val_loss: 0.2549 - val_sparse_categorical_accuracy: 0.9624\n","Epoch 19/20\n","542/542 [==============================] - 598s 1s/step - loss: 0.2116 - sparse_categorical_accuracy: 0.9646 - val_loss: 0.2496 - val_sparse_categorical_accuracy: 0.9634\n","Epoch 20/20\n","542/542 [==============================] - 597s 1s/step - loss: 0.2025 - sparse_categorical_accuracy: 0.9658 - val_loss: 0.2443 - val_sparse_categorical_accuracy: 0.9644\n","Tempo necessario per l'addestramento: 3:24:44.506603\n"]}]},{"cell_type":"code","source":["# Carico i pesi modello\n","latest = tf.train.latest_checkpoint(PATH_WEIGHTS)\n","transformer.load_weights(latest)"],"metadata":{"id":"5KeU08tmS3UK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["start = datetime.datetime.now()\n","json_log = open(log_history, mode='a', buffering=1, encoding='utf-8')\n","\n","transformer.fit(train_dataset_ita,\n","                initial_epoch=EPOCHS_ADAM,\n","                epochs=EPOCHS_ADAM+EPOCHS_ADAM,\n","                shuffle=True,\n","                validation_data=validation_dataset_ita,\n","                callbacks=[tensorboard_callback,\n","                           json_logging_callback, \n","                           cp_callback])\n","\n","end = datetime.datetime.now()\n","print(f'Tempo necessario per l\\'addestramento: {end - start}')"],"metadata":{"id":"PLZGGXQxS9V5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Train Dante"],"metadata":{"id":"GhBGzbvrh2Rw"}},{"cell_type":"code","source":["train_dataset_dante, validation_dataset_dante, test_dataset = train_val_test_dataset(df=df, filter_column='DANTE', debug=debug)"],"metadata":{"id":"kndzuk5XVnmM","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1679779707891,"user_tz":-60,"elapsed":9860,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}},"outputId":"0922155c-a744-4117-afcc-0b520df9bb01"},"execution_count":42,"outputs":[{"output_type":"stream","name":"stdout","text":["Lunghezza df 379582\n","Lunghezza dataset 135184\n","Dati totali presenti nel Dataset               : 379582\n","Dati totali presenti nel Dataset di Train      : 94464\n","Dati totali presenti nel Dataset di Validation : 40480\n","Dati totali presenti nel Dataset di Test       : 240\n","\n","----------------------------------- TRAIN SET -----------------------------------------\n","[\"' Kom , gezegend van mijn Vader' \", 'Ich war dieselbe Person , und Beatrice wie das heilige Licht , bevor sie sich bewegte , schien mich genauso zu sehen . ', ' Continuando gritando palabras ofensivas , regresaron al punto opuesto en el cìrculo oscuro desde ambos extremos . ', 'because heaven is not only in my eyes']\n","[\" Venite , benedicti Patris mei' , \", ' tal era io , e tal era sentito e da Beatrice e da la santa lampa che pria per me avea mutato sito', \" Così tornavan per lo cerchio tetro da ogne mano a l' opposito punto , gridandosi anche loro ontoso metro\", \" chè non pur ne' miei occhi è paradiso \"]\n","--------------------------------- VALIDATION SET --------------------------------------\n","[' Como el que sueña con su mal , y sueña con su sueño , para que desee lo que es verdad como si no lo fuera , ', \" Il n' avait aucune considèration pour sa fonction suprême , ni pour les ordres sacerdotaux , ni pour ce cordon franciscain qu' il faisait pencher ceux qui le portaient . \", 'where to stay for the night is what we will have to decide', \" Le plus grand don que Dieu , par sa gènèrositè , ait fait en crèant l' homme , et le plus conforme à sa bontè , \"]\n","[\" Qual è colui che suo dannaggio sogna , che sognando desidera sognare , sì che quel ch' è , come non fosse , agogna , \", ' nè sommo officio nè ordini sacri guardò in sè , nè in me quel capestro che solea fare i suoi cinti più macri', ' però è buon pensar di bel soggiorno', ' Lo maggior don che Dio per sua larghezza fesse creando , e a la sua bontate più conformato , ']\n","----------------------------------- TEST SET ------------------------------------------\n","['Mina vingar räckte inte till en sån flygtur . ', 'Plötsligt slog en chock mig i sinnet , och till slut lät jag mig uträtta det jag ville . ', 'Min fantasi lyckades inte hålla höjden uppe . ', 'Min önskan och vilja styrdes av gudomlig kärlek som driver solen och andra stjärnor framåt som ett hjul flyttade regelbundet . ']\n","[' ma non eran da ciò le proprie penne', ' se non che la mia mente fu percossa da un fulgore in che sua voglia venne', \" A l' alta fantasia qui mancò possa\", \" ma già volgeva il mio disio e 'l velle , sì come rota ch' igualmente è mossa , l' amor che move il sole e l' altre stelle\"]\n","-------------------------------- ANALISI DATI -----------------------------------------\n","Esempi nel Dataset di Train                            : 94464\n","Frase più corta nel Dataset Input di Train             : zei\n","Frase più corta nel Dataset Target di Train            :  E io\n","Frase più lunga nel Dataset Input di Train             : Denk je dat als ik stierf op de eerbiedwaardige leeftijd van een oudere , zou je roem groter zijn dan wat je zou hebben gehad als je als kind gestorven was ? Duizend jaar is een onbeduidende periode in vergelijking met de eeuwigheid en is minder duurzaam dan de flits van een knippering van vleugels in vergelijking met de zeer langzame hemelse beweging ? \n","Frase più lunga nel Dataset Target di Train            :  E già venìa su per le torbide onde un fracasso d' un suon , pien di spavento , per cui tremavano amendue le sponde , non altrimenti fatto che d' un vento impetüoso per li avversi ardori , che fier la selva e sanz' alcun rattento li rami schianta , abbatte e porta fori\n","---------------------------------------------------------------------------------------\n","Esempi nel Dataset di Validation                       : 40480\n","Frase più corta nel Dataset Input di Validation        : y yo\n","Frase più corta nel Dataset Target di Validation       :  E io\n","Frase più lunga nel Dataset Input di Validation        : Sieh mal , sieh mal , sieh mal , sieh mal , sieh mal , sieh mal , sieh mal , sieh mal , sieh mal , sieh mal , sieh mal , sieh mal , sieh mal , sieh mal , sieh mal , sieh mal , sieh mal , sieh mal , sieh mal , sieh mal , sieh mal , sieh mal , sieh mal , sieh mal , sieh mal , sieh mal , sieh mal , sieh mal , sieh mal , sieh mal , sieh mal , sieh mal , sieh mal , sieh mal , sieh mal , sieh mal , sieh mal , sieh mal ! \n","Frase più lunga nel Dataset Target di Validation       :  E già venìa su per le torbide onde un fracasso d' un suon , pien di spavento , per cui tremavano amendue le sponde , non altrimenti fatto che d' un vento impetüoso per li avversi ardori , che fier la selva e sanz' alcun rattento li rami schianta , abbatte e porta fori\n","---------------------------------------------------------------------------------------\n","Esempi nel Dataset di Test                             : 240\n","Frase più corta nel Dataset Input di Test              : Så jag bad\n","Frase più corta nel Dataset Target di Test             :  Ond' elli\n","Frase più lunga nel Dataset Input di Test              : Med min djärvhet kysstes jag av den överflödande nåd som gjorde det möjligt för mig att möta en direkt exponering för det eviga ljuset , till den grad att jag pressade mina ögon att nå den maximala gräns de kunde nå . \n","Frase più lunga nel Dataset Target di Test             :  Nel giallo de la rosa sempiterna , che si digrada e dilata e redole odor di lode al sol che sempre verna , qual è colui che tace e dicer vole , mi trasse Bëatrice , e disse\n","\n","--------------------------------- EXAMPLE ---------------------------------------------\n","['zei']\n","tf.Tensor(\n","[[  101 10941 10116   102     0     0     0     0     0     0     0     0\n","      0     0     0     0     0     0     0     0     0     0     0     0\n","      0     0     0     0     0     0     0     0]], shape=(1, 32), dtype=int32)\n","------------------------------------------------------------------\n","[' E io']\n","<tf.RaggedTensor [[2, 31, 85, 3]]>\n","\n","\n","['Denk je dat als ik stierf op de eerbiedwaardige leeftijd van een oudere , zou je roem groter zijn dan wat je zou hebben gehad als je als kind gestorven was ? Duizend jaar is een onbeduidende periode in vergelijking met de eeuwigheid en is minder duurzaam dan de flits van een knippering van vleugels in vergelijking met de zeer langzame hemelse beweging ? ']\n","tf.Tensor(\n","[[   101  10235  10174  10144  10527  10223  47458  71364  10303  10104\n","   46179  50579  24140  69689  29905  37306  10145  10200  95636    117\n","   15853  10144  25470  10451  55100  10574  10215  11803  10144  15853\n","   15572  47373  10223  10144  10223  22282  46503  42396  11975  10134\n","     136  14925  19181  11534  12626  10124  10200  10135  33627  45977\n","   13201  17715  10106  16719  63884  10230  10428  10104  17758  88509\n","   10110  10124  29393  10168  10546  53214  10215  10104  58768  15508\n","   10145  10200  96820  65237  10230  10145    190 101304  67673  10106\n","   16719  63884  10230  10428  10104  26641  12603  99541  14166  23184\n","   67630    136    102      0      0      0      0      0      0      0\n","       0      0      0      0      0      0      0      0      0      0\n","       0      0      0      0      0      0      0      0      0      0\n","       0      0      0      0      0      0      0      0]], shape=(1, 128), dtype=int32)\n","------------------------------------------------------------------\n","[\" E già venìa su per le torbide onde un fracasso d' un suon , pien di spavento , per cui tremavano amendue le sponde , non altrimenti fatto che d' un vento impetüoso per li avversi ardori , che fier la selva e sanz' alcun rattento li rami schianta , abbatte e porta fori\"]\n","<tf.RaggedTensor [[2, 31, 131, 1468, 127, 82, 88, 11404, 257, 84, 7620, 30, 8, 84, 1467,\n","  10, 1463, 78, 5644, 10, 82, 163, 12062, 1519, 88, 13130, 10, 79, 1439,\n","  143, 76, 30, 8, 84, 671, 12874, 82, 102, 8415, 8364, 10, 76, 2205, 77,\n","  1428, 31, 987, 8, 336, 18304, 102, 2536, 5179, 10, 6816, 31, 323, 1784,\n","  3]]>\n"]}]},{"cell_type":"code","source":["# Carico i pesi modello\n","latest = tf.train.latest_checkpoint(PATH_WEIGHTS)\n","transformer.load_weights(latest)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4ejTGcN8h4we","executionInfo":{"status":"ok","timestamp":1679653648478,"user_tz":-60,"elapsed":15195,"user":{"displayName":"daniele badiali","userId":"08100546172874775759"}},"outputId":"1595be32-937e-437e-a947-b8b3eee1df54"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x7fc4ba61a070>"]},"metadata":{},"execution_count":45}]},{"cell_type":"code","source":["start = datetime.datetime.now()\n","\n","json_log = open(log_history, mode='a', buffering=1, encoding='utf-8')\n","\n","transformer.fit(train_dataset_dante,\n","                initial_epoch=EPOCHS_ADAM,\n","                epochs=EPOCHS_ADAM+EPOCHS_ADAM,\n","                shuffle=True,\n","                validation_data=validation_dataset_dante,\n","                callbacks=[tensorboard_callback,\n","                           json_logging_callback, \n","                           cp_callback])\n","\n","end = datetime.datetime.now()\n","print(f'Tempo necessario per l\\'addestramento: {end - start}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UZ0iTUOXh70W","outputId":"b39b3418-a49c-4f38-9022-ccf3adfb0ae1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 21/40\n","542/542 [==============================] - 615s 1s/step - loss: 0.4851 - sparse_categorical_accuracy: 0.9355 - val_loss: 0.3936 - val_sparse_categorical_accuracy: 0.9417\n","Epoch 22/40\n","542/542 [==============================] - 648s 1s/step - loss: 0.4066 - sparse_categorical_accuracy: 0.9408 - val_loss: 0.3582 - val_sparse_categorical_accuracy: 0.9447\n","Epoch 23/40\n","542/542 [==============================] - 653s 1s/step - loss: 0.3681 - sparse_categorical_accuracy: 0.9440 - val_loss: 0.3343 - val_sparse_categorical_accuracy: 0.9467\n","Epoch 24/40\n","542/542 [==============================] - 635s 1s/step - loss: 0.3392 - sparse_categorical_accuracy: 0.9464 - val_loss: 0.3127 - val_sparse_categorical_accuracy: 0.9488\n","Epoch 25/40\n","542/542 [==============================] - 623s 1s/step - loss: 0.3139 - sparse_categorical_accuracy: 0.9488 - val_loss: 0.2984 - val_sparse_categorical_accuracy: 0.9505\n","Epoch 26/40\n","542/542 [==============================] - 611s 1s/step - loss: 0.2919 - sparse_categorical_accuracy: 0.9510 - val_loss: 0.2858 - val_sparse_categorical_accuracy: 0.9519\n","Epoch 27/40\n","542/542 [==============================] - 646s 1s/step - loss: 0.2718 - sparse_categorical_accuracy: 0.9531 - val_loss: 0.2722 - val_sparse_categorical_accuracy: 0.9534\n","Epoch 28/40\n","542/542 [==============================] - 628s 1s/step - loss: 0.2540 - sparse_categorical_accuracy: 0.9552 - val_loss: 0.2615 - val_sparse_categorical_accuracy: 0.9548\n","Epoch 29/40\n","542/542 [==============================] - 618s 1s/step - loss: 0.2368 - sparse_categorical_accuracy: 0.9573 - val_loss: 0.2511 - val_sparse_categorical_accuracy: 0.9560\n","Epoch 30/40\n","542/542 [==============================] - 611s 1s/step - loss: 0.2214 - sparse_categorical_accuracy: 0.9592 - val_loss: 0.2417 - val_sparse_categorical_accuracy: 0.9571\n","Epoch 31/40\n","542/542 [==============================] - 637s 1s/step - loss: 0.2071 - sparse_categorical_accuracy: 0.9609 - val_loss: 0.2358 - val_sparse_categorical_accuracy: 0.9581\n","Epoch 32/40\n","542/542 [==============================] - 614s 1s/step - loss: 0.1940 - sparse_categorical_accuracy: 0.9626 - val_loss: 0.2272 - val_sparse_categorical_accuracy: 0.9592\n","Epoch 33/40\n","347/542 [==================>...........] - ETA: 3:17 - loss: 0.1838 - sparse_categorical_accuracy: 0.9640"]}]},{"cell_type":"code","source":["start = datetime.datetime.now()\n","\n","json_log = open(log_history, mode='a', buffering=1, encoding='utf-8')\n","\n","transformer.fit(train_dataset_dante,\n","                initial_epoch=32,\n","                epochs=EPOCHS_ADAM+EPOCHS_ADAM,\n","                shuffle=True,\n","                validation_data=validation_dataset_dante,\n","                callbacks=[tensorboard_callback,\n","                           json_logging_callback, \n","                           cp_callback])\n","\n","end = datetime.datetime.now()\n","print(f'Tempo necessario per l\\'addestramento: {end - start}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3yZ-Zq0xJIZX","executionInfo":{"status":"ok","timestamp":1679658518495,"user_tz":-60,"elapsed":4868159,"user":{"displayName":"daniele badiali","userId":"08100546172874775759"}},"outputId":"3a2afb44-8f86-4615-f331-e3c0fb9556f9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 33/40\n","542/542 [==============================] - 592s 1s/step - loss: 0.1819 - sparse_categorical_accuracy: 0.9642 - val_loss: 0.2193 - val_sparse_categorical_accuracy: 0.9602\n","Epoch 34/40\n","542/542 [==============================] - 617s 1s/step - loss: 0.1713 - sparse_categorical_accuracy: 0.9657 - val_loss: 0.2130 - val_sparse_categorical_accuracy: 0.9613\n","Epoch 35/40\n","542/542 [==============================] - 568s 1s/step - loss: 0.1610 - sparse_categorical_accuracy: 0.9670 - val_loss: 0.2081 - val_sparse_categorical_accuracy: 0.9620\n","Epoch 36/40\n","542/542 [==============================] - 565s 1s/step - loss: 0.1523 - sparse_categorical_accuracy: 0.9683 - val_loss: 0.2027 - val_sparse_categorical_accuracy: 0.9631\n","Epoch 37/40\n","542/542 [==============================] - 601s 1s/step - loss: 0.1434 - sparse_categorical_accuracy: 0.9697 - val_loss: 0.2014 - val_sparse_categorical_accuracy: 0.9638\n","Epoch 38/40\n","542/542 [==============================] - 565s 1s/step - loss: 0.1358 - sparse_categorical_accuracy: 0.9709 - val_loss: 0.1974 - val_sparse_categorical_accuracy: 0.9645\n","Epoch 39/40\n","542/542 [==============================] - 566s 1s/step - loss: 0.1282 - sparse_categorical_accuracy: 0.9722 - val_loss: 0.1940 - val_sparse_categorical_accuracy: 0.9652\n","Epoch 40/40\n","542/542 [==============================] - 601s 1s/step - loss: 0.1216 - sparse_categorical_accuracy: 0.9732 - val_loss: 0.1897 - val_sparse_categorical_accuracy: 0.9664\n","Tempo necessario per l'addestramento: 1:21:07.618712\n"]}]},{"cell_type":"markdown","source":["## Valutazione dell'addestramento\n","Avendo in output il log ed i risultati dell'addestramento, possiamo visualizzare\n","queste informazioni relativamente alle metriche di interesse."],"metadata":{"id":"L0w4wF79UhAp"}},{"cell_type":"code","source":["# Recupero il log di addestramento\n","df_history = pd.read_json(log_history, lines=True)\n","\n","# visualizzazione andamento addestramento\n","# su un grafico composto da due sub-plot\n","# uno per il loss, l'altro per l'accuracy\n","fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15,5))\n","\n","# Errore durante l'addestramento\n","ax1.plot(df_history['loss'], label='Loss')\n","ax1.plot(df_history['val_loss'], label='Validation Loss')\n","ax1.set_title('Training Loss')\n","ax1.legend()\n","\n","# Accuratezza durante l'addestramento\n","ax2.plot(df_history['sparse_categorical_accuracy'], label='Accuracy')\n","ax2.plot(df_history['val_sparse_categorical_accuracy'], label='Validation Accuracy')\n","ax2.set_title('Training Accuracy')\n","ax2.legend()\n","\n","plt.show()"],"metadata":{"id":"RpXR2p5VAdoG","colab":{"base_uri":"https://localhost:8080/","height":336},"executionInfo":{"status":"ok","timestamp":1679658829399,"user_tz":-60,"elapsed":635,"user":{"displayName":"daniele badiali","userId":"08100546172874775759"}},"outputId":"e73c8ad7-333d-493c-aba6-772cf2caeebd"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 1080x360 with 2 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","source":["## Test del modello\n","La seguente cella permette di caricare l'ultimo checkpoint dell'addestramento\n","precedentemente salvato."],"metadata":{"id":"ReOkcBp2WHWW"}},{"cell_type":"code","source":["trainable = False\n","\n","transformer = TransformerBlock(NUM_LAYERS, \n","                               EMBEDDING_DIM, \n","                               NUM_HEADS, \n","                               FF_DIM,\n","                               MAX_SEQ_LENGTH,\n","                               tokenizers.ita.get_vocab_size(),\n","                               tfhub_handle_encoder,\n","                               trainable,\n","                               DROPUOT)"],"metadata":{"id":"RN0mnV8Wd92H"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Carico i pesi modello\n","latest = tf.train.latest_checkpoint(PATH_WEIGHTS)\n","transformer.load_weights(latest)"],"metadata":{"id":"5PIf_6-RSBb1","colab":{"base_uri":"https://localhost:8080/","height":363},"executionInfo":{"status":"error","timestamp":1679658995855,"user_tz":-60,"elapsed":5514,"user":{"displayName":"daniele badiali","userId":"08100546172874775759"}},"outputId":"19502e51-7eb0-43e6-deec-5b3f56630ca0"},"execution_count":null,"outputs":[{"output_type":"error","ename":"DataLossError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mDataLossError\u001b[0m                             Traceback (most recent call last)","\u001b[0;32m<ipython-input-57-73523d561144>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Carico i pesi modello\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mlatest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPATH_WEIGHTS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlatest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     53\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mDataLossError\u001b[0m: {{function_node __wrapped__RestoreV2_dtypes_100_device_/job:localhost/replica:0/task:0/device:CPU:0}} TensorBundle at /content/drive/MyDrive/BERT/weights/transformer_multi_bert_it_v2/cp.ckpt shard 0 (1572864 bytes): Checksum does not match: stored 703612876 vs. calculated on the restored bytes 1919215207 [Op:RestoreV2]"]}]},{"cell_type":"code","source":["class Translate:\n","  def __init__(self, transformer_block, tokenizers):\n","    self.transformer = transformer_block\n","    self.tokenizers = tokenizers\n","\n","  def predict(self, input_text, max_length):\n","    if input_text is None:\n","      input_text = (df[ORIGINAL_COLUMN].tolist())[np.random.choice(len(df[ORIGINAL_COLUMN].tolist()))]\n","      print(input_text)\n","\n","    inputs_bert = self.tokenizers.multilingual.tokenize(input_text)\n","\n","    start_end = self.tokenizers.ita.tokenize([''])[0]\n","    start = (start_end[0][tf.newaxis]).numpy()[0]\n","    end = (start_end[1][tf.newaxis]).numpy()[0]\n","\n","    output_array = tf.TensorArray(dtype=tf.int32, size=max_length, dynamic_size=True)\n","    output_array = output_array.write(0, tf.constant([start]))     \n","\n","    out_words = []\n","\n","    for i in tf.range(max_length):\n","      # decodifica e recupero probabilità di output\n","      output = tf.transpose(output_array.stack())\n","\n","      transformer_output = transformer((inputs_bert, output), \n","                                        training=False,\n","                                        debug=False)\n","\n","      predictions = transformer_output[:, -1:, :]\n","\n","      # selezione della parola più probabile\n","      predict = tf.argmax(predictions, -1)\n","      pred_values = (tf.keras.backend.argmax(transformer_output, axis=-1)).numpy()\n","    \n","      # inserimento della parola nella sequenza di output\n","      output_array = output_array.write(i+1, [pred_values[0][i]])\n","\n","      if pred_values[0][i] == end:\n","        break\n","\n","    output = tf.transpose(output_array.stack())\n","    text = tokenizers.ita.detokenize(output)[0]  \n","    tokens = tokenizers.ita.lookup(output)[0]\n","\n","    return text, tokens"],"metadata":{"id":"L2PEoJVb1V8x"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["translate = Translate(transformer_block=transformer,\n","                      tokenizers=tokenizers)\n","\n","# Recupero un batch di esempi per la verifica delle classi custom che andrò a creare\n","for test_input_data, test_target_data in test_dataset.take(30):\n","  test_input_data = test_input_data.numpy().decode()\n","  test_target_data = test_target_data.numpy().decode()\n","\n","  text, token = translate.predict(tf.constant([test_input_data]), MAX_SEQ_LENGTH)\n","\n","  print(f'{\"Input\":15s}: {test_input_data}')\n","  print(f'{\"Target\":15s}: {test_target_data}')\n","  print(f'{\"Prediction\":15s}: {text.numpy().decode(\"utf-8\")}')  \n","  print('---------------------------------------------')"],"metadata":{"id":"udIjI2jZWR6g","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1679658588388,"user_tz":-60,"elapsed":50822,"user":{"displayName":"daniele badiali","userId":"08100546172874775759"}},"outputId":"0ef71b2f-1c59-4662-fd09-ad2c6c3684d5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Input          : Je lui ai fait croire que son bien être\n","Target         : A chui intender faciea , che 'l su' disdotto\n","Prediction     : a chui intender faciea , che ' l su ' disdotto\n","---------------------------------------------\n","Input          : J' ètais plus excitèe que tout . \n","Target         : Mi piaciea più che null' altro , ch' e' ssia . \n","Prediction     : i ' era piu bella che ciaschedun l ' avria morto .\n","---------------------------------------------\n","Input          : J' ètais sèduisante , jeune et drôle . \n","Target         : I' era bella , e giovane , e folletta , \n","Prediction     : i ' era bella , giovane , e bello ,\n","---------------------------------------------\n","Input          : Mais il n' ètait pas à l' ècole d' affection . \n","Target         : Ma non era a la scuola de l' Amore\n","Prediction     : ma non era a la scuola de l ' amore\n","---------------------------------------------\n","Input          : C' ètait; cependant , je le sais maintenant en profondeur par c ur . \n","Target         : Istata; ma i' so or ben per cuore\n","Prediction     : istata ; ma i ' so or per cuore\n","---------------------------------------------\n","Input          : L' exercice qui sera prèsentè ici . \n","Target         : La pratica , la qual ti fie qui detta . \n","Prediction     : la qual porta mise qui detta .\n","---------------------------------------------\n","Input          : L' habitude m' a rendu si expèrimentèe . \n","Target         : Usanza me n' à fatta sì savietta , \n","Prediction     : ardimento a ben s ' a ben s ' acortesito .\n","---------------------------------------------\n","Input          : Je ne pouvais pas tromper les lecteurs . \n","Target         : Ched i' non dotterei nessun lettore , \n","Prediction     : ched i ' non de far grazia fecier lor venite\n","---------------------------------------------\n","Input          : qu' il m' a donnè une mauvaise opinion de ça . \n","Target         : Che di ciò mi faciesse desinore , \n","Prediction     : che di cio mi fecie punto ringio .\n","---------------------------------------------\n","Input          : Mais parce que j' ètais sèduisante et jeune . \n","Target         : Ma' ched i' fosse bella e giovanetta \n","Prediction     : ma ' ched i ' fosse bella e giovanetta\n","---------------------------------------------\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"Qex8JVqvJxzp"},"execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"},"colab":{"provenance":[],"collapsed_sections":["Day7C7Qh0b4G"]},"gpuClass":"standard"},"nbformat":4,"nbformat_minor":0}