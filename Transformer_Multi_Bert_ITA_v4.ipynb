{"cells":[{"cell_type":"markdown","source":["## Pacchetti da installare"],"metadata":{"id":"yDKuSNBd92YI"}},{"cell_type":"code","source":["!pip install -q -U 'tensorflow-text==2.8.*'"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NE4enZGpvMRX","executionInfo":{"status":"ok","timestamp":1679653432700,"user_tz":-60,"elapsed":62895,"user":{"displayName":"daniele badiali","userId":"08100546172874775759"}},"outputId":"296a9c86-d733-4d91-b13f-740d882a4378"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m35.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m498.1/498.1 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m63.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m33.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 KB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m462.3/462.3 KB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}]},{"cell_type":"code","source":["!pip install -q tf-models-official"],"metadata":{"id":"FPtWz_qHuofc","executionInfo":{"status":"ok","timestamp":1679653498354,"user_tz":-60,"elapsed":65663,"user":{"displayName":"daniele badiali","userId":"08100546172874775759"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"3967b38f-049d-4a9a-91c1-1975e7a64018"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m59.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.9/118.9 KB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m49.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 KB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m630.1/630.1 KB\u001b[0m \u001b[31m56.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m73.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m588.3/588.3 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m352.1/352.1 KB\u001b[0m \u001b[31m29.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m238.9/238.9 KB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m38.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m29.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m63.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m439.2/439.2 KB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n"]}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"hJy-juNOpUOY","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1679653532920,"user_tz":-60,"elapsed":34572,"user":{"displayName":"daniele badiali","userId":"08100546172874775759"}},"outputId":"d93eee86-3e42-41f9-f322-d4738937372f"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","source":["## Import notebook"],"metadata":{"id":"xXYm-Qqw-ANh"}},{"cell_type":"code","execution_count":4,"metadata":{"collapsed":true,"id":"UaAiWsEuC_4K","executionInfo":{"status":"ok","timestamp":1679653536769,"user_tz":-60,"elapsed":3859,"user":{"displayName":"daniele badiali","userId":"08100546172874775759"}}},"outputs":[],"source":["import os\n","import re\n","import datetime\n","import pathlib\n","import json\n","from pathlib import Path\n","\n","import pandas as pd\n","import numpy as np\n","\n","from sklearn.model_selection import train_test_split\n","\n","import tensorflow as tf\n","import tensorflow_hub as hub\n","import tensorflow_text as text\n","from tensorflow_text.tools.wordpiece_vocab import bert_vocab_from_dataset as bert_vocab\n","\n","import matplotlib.pyplot as plt\n","\n","from typing import Tuple\n"]},{"cell_type":"code","source":["tf.get_logger().setLevel('ERROR')\n","tf.config.run_functions_eagerly(True)"],"metadata":{"id":"uKEqRlKowOQS","executionInfo":{"status":"ok","timestamp":1679653536769,"user_tz":-60,"elapsed":13,"user":{"displayName":"daniele badiali","userId":"08100546172874775759"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["## Variabili Globali"],"metadata":{"id":"HRe16D-rUBLA"}},{"cell_type":"code","source":["# PARAMETRI GLOBALI\n","root_folder = 'drive/MyDrive/BERT/'\n","\n","# DATI\n","data_folder_name = 'data'\n","train_filename = 'train_data.csv'\n","\n","DATA_PATH = os.path.abspath(os.path.join(root_folder, data_folder_name))\n","train_data_filenamepath = os.path.abspath(os.path.join(DATA_PATH, train_filename))\n","\n","# PATH LOG Tensorboard\n","PATH_LOG = 'logs/fit/transformer_multi_bert_it_v2'\n","PATH_LOG = os.path.abspath(os.path.join(root_folder, PATH_LOG))\n","log_dir =  os.path.abspath(os.path.join(PATH_LOG, datetime.datetime.now().strftime('%Y%m%d-%H%M%S'))) \n","log_history = os.path.abspath(os.path.join(PATH_LOG, 'histrory.json'))\n","\n","# PATH WEIGHTS Tensorboard\n","PATH_WEIGHTS = 'weights/transformer_multi_bert_it_v2'\n","PATH_WEIGHTS = os.path.abspath(os.path.join(root_folder, PATH_WEIGHTS))\n","checkpoint_path = os.path.abspath(os.path.join(PATH_WEIGHTS, 'cp.ckpt'))\n","\n","# VOCABOLARIO\n","vocab_folder = 'vocab'\n","multilingual_vocab_finalname = 'multilingual_vocab.txt'\n","ita_vocab_finalname = 'ita_vocab.txt'\n","\n","VOCAB_PATH = os.path.abspath(os.path.join(root_folder, vocab_folder))\n","multilingual_vocab_filenamepath = os.path.abspath(os.path.join(VOCAB_PATH, multilingual_vocab_finalname))\n","ita_vocab_filenamepath = os.path.abspath(os.path.join(VOCAB_PATH, ita_vocab_finalname))\n","\n","# parametri per il modello\n","ORIGINAL_COLUMN = 'Original'\n","TRANSLATE_COLUMN = 'Translate'\n","TYPE_COLUMN ='Type'"],"metadata":{"id":"ewLgCIuEpczO","executionInfo":{"status":"ok","timestamp":1679653536770,"user_tz":-60,"elapsed":12,"user":{"displayName":"daniele badiali","userId":"08100546172874775759"}}},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":["## Iper Parametri Modello"],"metadata":{"id":"LCiP6wT05k6j"}},{"cell_type":"code","source":["NUM_SAMPLES = 25000\n","TEST = 200\n","TEST_SIZE = 0.3\n","\n","MAX_VOCAB_SIZE = 30000 \n","EMBEDDING_DIM = 128\n","HIDDEN_DIM = 1024 # numero di celle nei layer ricorrenti nascosti\n","\n","BATCH_SIZE = 32\n","BUFFER_SIZE = 2000\n","MAX_SEQ_LENGTH = 128\n","\n","NUM_LAYERS = 1 # Numero di layer di Decoder del Transformer\n","NUM_HEADS = 8 # Numero di meccanismi di multi-head attention\n","FF_DIM = 16 # Numero di celle dei Layer Feed Forward\n","DROPUOT = 0.5\n","\n","# Ottimizzatore Adam\n","LEARNING_RATE_ADAM = 1e-4\n","BETA_1 = 0.66\n","BETA_2 = 0.999\n","EPOCHS_ADAM = 20\n","\n","# IMPOSTO IL DEBUG A TRUE \n","debug = True\n","trainable = True\n","training = True"],"metadata":{"id":"8CN-4Uzoqbjl","executionInfo":{"status":"ok","timestamp":1679653536771,"user_tz":-60,"elapsed":12,"user":{"displayName":"daniele badiali","userId":"08100546172874775759"}}},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":["## Parametri BERT"],"metadata":{"id":"BehZY4rETECN"}},{"cell_type":"code","source":["bert_model_name = 'distilbert_multi_cased_L-6_H-768_A-12/1'  \n","tfhub_handle_preprocess = 'https://tfhub.dev/jeongukjae/distilbert_multi_cased_preprocess/2'\n","tfhub_handle_encoder =  'https://tfhub.dev/jeongukjae/distilbert_multi_cased_L-6_H-768_A-12/1'\n","\n","if debug:\n","  print('BERT model name                    : ', bert_model_name)\n","  print('BERT model selected                : ', tfhub_handle_encoder)\n","  print('BERT preprocess                    : ', tfhub_handle_preprocess)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fodDcY6sm392","executionInfo":{"status":"ok","timestamp":1679653536771,"user_tz":-60,"elapsed":10,"user":{"displayName":"daniele badiali","userId":"08100546172874775759"}},"outputId":"fd78495e-71df-4780-de07-aea80c0a151d"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["BERT model name                    :  distilbert_multi_cased_L-6_H-768_A-12/1\n","BERT model selected                :  https://tfhub.dev/jeongukjae/distilbert_multi_cased_L-6_H-768_A-12/1\n","BERT preprocess                    :  https://tfhub.dev/jeongukjae/distilbert_multi_cased_preprocess/2\n"]}]},{"cell_type":"markdown","source":["## DATASET"],"metadata":{"id":"5DPeN9Vanbvv"}},{"cell_type":"markdown","source":["### Caricamento Dati"],"metadata":{"id":"LU7AorKXT8K7"}},{"cell_type":"code","source":["def preprocess_sentence(w):\n","  '''\n","  Preprocessing dei testi di input, impostando tutti i caratteri\n","  minuscoli, aggiungendo uno spazio prima di ogni punto e sostituendo\n","  qualsiasi carattere con uno spazio se non è compreso nel seguente elenco:\n","  (a-z, A-Z, \".\", \"?\", \"!\", \",\", \"'\", \"’\")\n","  '''\n","  # inserimento di uno spazio tra ogni parola e il successivo punto,\n","  # punto esclamativo, punto interrogativo e virgola\n","  # esempio: \"ciao, come và?\" => \"ciao , come và ?\"\n","  w = re.sub(r\"([?.!,])\", r\" \\1 \", w) # inserimento di uno spazio\n","\n","  # sostituzione dei caratteri apostrofo\n","  w = re.sub(r\"([’]+)\", \"'\", w)\n","\n","  w = w.replace(\"á\", \"à\")\n","  w = w.replace(\"é\", \"è\")\n","  w = w.replace(\"í\", \"ì\")\n","  w = w.replace(\"ó\", \"ò\")\n","  w = w.replace(\"ú\", \"ù\")\n","  w = w.replace('\"', \" \")\n","  w = w.replace(':', \" \")\n","  w = w.replace('«', \" \")\n","  w = w.replace('»', \" \")\n","  w = w.replace('‘', \" \")\n","  w = w.replace('-', \" \")\n","  w = w.replace('[', \" \")\n","  w = w.replace(']', \" \")\n","  w = w.replace('(', \" \")\n","  w = w.replace(')', \" \")\n","  w = w.replace(\"•\", \" \")\n","  w = w.replace(\"..\", \".\")\n","  w = w.replace(\"...\", \".\")\n","  w = w.replace(\"\\xa0\", \" \")\n","  w = w.replace(\"\\xc3\\xa8\", \" \")\n","  w = w.replace(\"\\xe2\\x80\\xaf\", \" \")\n","  w = w.replace(\"   \", \" \")\n","  w = w.replace(\"–\", \" \")\n","  w = w.replace(\"“\", \" \")\n","  w = w.replace(\"”\", \" \")\n","  w = w.replace(\"„\", \" \")\n","  w = w.replace(\"─\", \" \")\n","  w = w.replace(\"♪\", \" \")\n","  w = w.replace(\"#\", \" \")\n","  w = w.replace(\"/\", \" \")\n","  w = w.replace(\"=\", \" \")\n","  w = w.replace(\">\", \" \")\n","  w = w.replace(\"\\\\\", \" \")\n","  w = w.replace(\"`\", \" \")\n","  w = w.replace(\"¡\", \" \")\n","  w = w.replace(\"¿\", \" \")\n","  w = w.replace(\"œ\", \" \")\n","\n","  # inserimento di uno spazio dopo apostrofo\n","  w = re.sub(r\"(['])\", r\"\\1 \", w) \n","\n","  w = w.replace(\" ' \", \" '\")\n","\n","  w = re.sub(r'[\" \"]+', \" \", w) # rimozione di più spazi consecutivi\n","  return w"],"metadata":{"id":"Jm_Up6gyOTgW","executionInfo":{"status":"ok","timestamp":1679653536771,"user_tz":-60,"elapsed":7,"user":{"displayName":"daniele badiali","userId":"08100546172874775759"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["df = pd.read_csv(\n","  train_data_filenamepath,\n","  usecols=[ORIGINAL_COLUMN, TRANSLATE_COLUMN, TYPE_COLUMN],\n",")\n","\n","# Preprocessing dei dati di Input\n","df[ORIGINAL_COLUMN] = df[ORIGINAL_COLUMN].apply(lambda x : preprocess_sentence(x))\n","\n","# Preprocessing dei dati Target con aggiunta del token di fine frase\n","df[TRANSLATE_COLUMN] = df[TRANSLATE_COLUMN].apply(lambda x : preprocess_sentence(x))\n","\n","if debug:\n","  print(f'Dati totali presenti nel Dataset               : {len(df)}')\n","\n","  print('----------------------------------- TRAIN SET -----------------------------------------')\n","  print((df[ORIGINAL_COLUMN].tolist())[-1:])\n","  print((df[TRANSLATE_COLUMN].tolist())[-1:])\n","  print((df[ORIGINAL_COLUMN].tolist())[:1])\n","  print((df[TRANSLATE_COLUMN].tolist())[:1])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"duGPhZ_jgPVI","executionInfo":{"status":"ok","timestamp":1679653561950,"user_tz":-60,"elapsed":25185,"user":{"displayName":"daniele badiali","userId":"08100546172874775759"}},"outputId":"80952c6a-42b0-467c-f595-55b91a8213ca"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Dati totali presenti nel Dataset               : 270358\n","----------------------------------- TRAIN SET -----------------------------------------\n","[\"Et c' ètait une femme de bon sens ! \"]\n","[\"E sì n' er' ella dona di ragione ! \"]\n","[\"De même que , en temps de guerre , officiers et soldats se sentent autorisès par l' opinion gènèrale à commettre des actes qui , en temps de paix , sont tenus pour criminels , de même les rèvolutionnaires , dans leur lutte , se regardaient comme couverts par l' opinion de leur cercle , en vertu de laquelle les actes de cruautè qu' ils commettaient ètaient nobles et moraux , ètant commis par eux au prix de leur libertè , de leur vie , de tout ce qui est cher à la plupart des hommes . Ainsi s' expliquait , que des personnes excellentes , incapables non seulement de causer une souffrance , mais même d' en supporter la vue , pussent se prèparer tranquillement à la violence et au meurtre , et professer la saintetè de tels actes , considèrès comme moyens de dèfense , ou encore comme instrument utile à la rèalisation d' un idèal de bonheur pour l' humanitè . \"]\n","[\"Così come in tempo di guerra , ufficiali e soldati si sentono responsabilizzati dall' opinione generale a commettere atti che , in tempo di pace , sono necessari per i criminali , anche rivoluzionari nella loro lotta , considerati coperti dal parere del loro circolo , secondo cui gli atti di crudeltà che hanno commesso erano nobili e morali , essendo commessi da loro nel prezzo della loro libertà , della loro vita , di tutto ciò che è caro alla maggior parte degli uomini . Ciò ha spiegato che persone eccellenti , in grado non solo di causare sofferenza , ma anche di sopportarne la vista , potrebbero felicemente prepararsi alla violenza e all' omicidio , e professare la santità di tali atti , considerati come un mezzo di difesa , o come utili per la realizzazione di un ideale di felicità per l' umanità . \"]\n"]}]},{"cell_type":"markdown","source":["## Tokenizer\n","\n","Creo due differenti tokenizer che mi servizranno per la predisposizione dei dati di input:\n","\n","\n","*   EncTokenizer classe custom per la tokenizzazione dei dati di input al Layer di Encoder di Bert\n","*   DecTokenizer classe custom per la tokenizzazione dei dati di input al Layer di Decoder\n","\n"],"metadata":{"id":"njyY9RWlFMWu"}},{"cell_type":"code","source":["input_data_vocab = df[ORIGINAL_COLUMN].tolist()\n","target_data_vocab = df[TRANSLATE_COLUMN].tolist()\n","\n","dataset = tf.data.Dataset.from_tensor_slices((input_data_vocab, target_data_vocab))\n","dataset = dataset.shuffle(len(input_data_vocab)).batch(BATCH_SIZE, drop_remainder=True)\n","\n","train_multilingual = dataset.map(lambda multilingual, ita: multilingual)\n","train_ita = dataset.map(lambda multilingual, ita: ita)"],"metadata":{"id":"fUG1fTAYekOy","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1679653567247,"user_tz":-60,"elapsed":5314,"user":{"displayName":"daniele badiali","userId":"08100546172874775759"}},"outputId":"5dce829b-61f0-4e2d-cd5c-82c7f0f3279a"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/tensorflow/python/data/ops/structured_function.py:256: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n","  warnings.warn(\n"]}]},{"cell_type":"code","source":["def write_vocab_file(filepath, vocab):\n","  with open(filepath, 'w') as f:\n","    for token in vocab:\n","      print(token, file=f)"],"metadata":{"id":"xWO-LrXJe0cF","executionInfo":{"status":"ok","timestamp":1679653567247,"user_tz":-60,"elapsed":23,"user":{"displayName":"daniele badiali","userId":"08100546172874775759"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["def cleanup_text(reserved_tokens, token_txt):\n","\n","  # Drop the reserved tokens, except for \"[UNK]\".\n","  bad_tokens = [re.escape(tok) for tok in reserved_tokens if tok != \"[UNK]\"]\n","  bad_token_re = \"|\".join(bad_tokens)\n","\n","  bad_cells = tf.strings.regex_full_match(token_txt, bad_token_re)\n","  result = tf.ragged.boolean_mask(token_txt, ~bad_cells)\n","\n","  # Join them into strings.\n","  result = tf.strings.reduce_join(result, separator=' ', axis=-1)\n","\n","  return result"],"metadata":{"id":"yGdsrOoKiYUK","executionInfo":{"status":"ok","timestamp":1679653567248,"user_tz":-60,"elapsed":22,"user":{"displayName":"daniele badiali","userId":"08100546172874775759"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["tokenizers = tf.Module()"],"metadata":{"id":"qbKNS_uQhHLz","executionInfo":{"status":"ok","timestamp":1679653567248,"user_tz":-60,"elapsed":20,"user":{"displayName":"daniele badiali","userId":"08100546172874775759"}}},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":["### Classe EncTokenizer\n","\n","Classe custom per la tokenizzazione dei dati di italiano e che crea i tre vettori necessari al layer di Encoder \n","Bert:\n","\n","\n","*   input_word_ids\n","*   input_type_ids\n","*   input_mask\n","\n","\n","\n"],"metadata":{"id":"0KUcCnjXVjt3"}},{"cell_type":"code","source":["bert_tokenizer_params=dict(lower_case=True)\n","reserved_tokens = {\n","  'start_of_sequence_id': 101,\n","  'end_of_segment_id': 102,\n","  'padding_id': 0,\n","  'mask_id': 103\n","}\n","\n","bert_vocab_args = dict(\n","  # The target vocabulary size\n","  vocab_size = MAX_VOCAB_SIZE,\n","  # Reserved tokens that must be included in the vocabulary\n","  reserved_tokens=reserved_tokens,\n","  # Arguments for `text.BertTokenizer`\n","  bert_tokenizer_params=bert_tokenizer_params,\n","  # Arguments for `wordpiece_vocab.wordpiece_tokenizer_learner_lib.learn`\n","  learn_params={},\n",")"],"metadata":{"id":"Yr0izOZLembx","executionInfo":{"status":"ok","timestamp":1679653567248,"user_tz":-60,"elapsed":19,"user":{"displayName":"daniele badiali","userId":"08100546172874775759"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["exist_vocab = Path(multilingual_vocab_filenamepath)\n","\n","if not exist_vocab.exists():\n","  multilingual_vocab = bert_vocab.bert_vocab_from_dataset(\n","      train_multilingual.batch(MAX_VOCAB_SIZE).prefetch(tf.data.AUTOTUNE),\n","      **bert_vocab_args\n","  )\n","\n","  write_vocab_file(multilingual_vocab_filenamepath, multilingual_vocab)"],"metadata":{"id":"BwSKtlLSe7bH","executionInfo":{"status":"ok","timestamp":1679653567249,"user_tz":-60,"elapsed":20,"user":{"displayName":"daniele badiali","userId":"08100546172874775759"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["class EncTokenizer(tf.Module):\n","  def __init__(self, tfhub_handle_preprocess):\n","    self.preprocessor = hub.KerasLayer(tfhub_handle_preprocess)\n","    \n","  @tf.function\n","  def tokenize(self, strings):\n","    return self.preprocessor(strings)"],"metadata":{"id":"WmsNdDLNf6vr","executionInfo":{"status":"ok","timestamp":1679653567249,"user_tz":-60,"elapsed":19,"user":{"displayName":"daniele badiali","userId":"08100546172874775759"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["tokenizers.multilingual = EncTokenizer(tfhub_handle_preprocess)"],"metadata":{"id":"-4B-HWWcmsmz","executionInfo":{"status":"ok","timestamp":1679653580396,"user_tz":-60,"elapsed":13166,"user":{"displayName":"daniele badiali","userId":"08100546172874775759"}}},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":["### Classe DecTokenizer\n","\n","Classe custom per la tokenizzazione dei dati in lingua italiana per il layer di Decoder\n"],"metadata":{"id":"mICEGEzJVnvx"}},{"cell_type":"code","source":["bert_tokenizer_params=dict(lower_case=True)\n","reserved_tokens_vocab=[\"[PAD]\", \"[UNK]\", \"[START]\", \"[END]\"]\n","\n","bert_vocab_args = dict(\n","  # The target vocabulary size\n","  vocab_size = MAX_VOCAB_SIZE,\n","  # Reserved tokens that must be included in the vocabulary\n","  reserved_tokens=reserved_tokens_vocab,\n","  # Arguments for `text.BertTokenizer`\n","  bert_tokenizer_params=bert_tokenizer_params,\n","  # Arguments for `wordpiece_vocab.wordpiece_tokenizer_learner_lib.learn`\n","  learn_params={},\n",")"],"metadata":{"id":"abBEnJJGV0AD","executionInfo":{"status":"ok","timestamp":1679653580397,"user_tz":-60,"elapsed":24,"user":{"displayName":"daniele badiali","userId":"08100546172874775759"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["exist_vocab = Path(ita_vocab_filenamepath)\n","\n","if not exist_vocab.exists():\n","  ita_vocab = bert_vocab.bert_vocab_from_dataset(\n","      train_ita.batch(MAX_VOCAB_SIZE).prefetch(tf.data.AUTOTUNE),\n","      **bert_vocab_args\n","  )\n","\n","  write_vocab_file(ita_vocab_filenamepath, ita_vocab)"],"metadata":{"id":"dGsP1V4nVz6S","executionInfo":{"status":"ok","timestamp":1679653580398,"user_tz":-60,"elapsed":23,"user":{"displayName":"daniele badiali","userId":"08100546172874775759"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["START = tf.argmax(tf.constant(reserved_tokens_vocab) == \"[START]\")\n","END = tf.argmax(tf.constant(reserved_tokens_vocab) == \"[END]\")\n","\n","def add_start_end(ragged):\n","  count = ragged.bounding_shape(out_type=tf.int32)[0]\n","\n","  starts = tf.fill([count,1], START)\n","  starts = tf.cast(starts, tf.int32)\n","\n","  ends = tf.fill([count,1], END)\n","  ends = tf.cast(ends, tf.int32)\n","\n","  x = tf.concat([starts, ragged, ends], axis=1)\n","  return x"],"metadata":{"id":"BeaD2-uLWT50","executionInfo":{"status":"ok","timestamp":1679653580398,"user_tz":-60,"elapsed":22,"user":{"displayName":"daniele badiali","userId":"08100546172874775759"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["class DecTokenizer(tf.Module):\n","  def __init__(self, reserved_tokens_vocab, vocab_path):\n","    self.tokenizer = text.BertTokenizer(vocab_path, lower_case=True, token_out_type=tf.int32)\n","    self._reserved_tokens_vocab = reserved_tokens_vocab\n","    self._vocab_path = tf.saved_model.Asset(vocab_path)\n","\n","    vocab = pathlib.Path(vocab_path).read_text().splitlines()\n","    self.vocab = tf.Variable(vocab)\n","\n","    ## Create the signatures for export:   \n","\n","    # Include a tokenize signature for a batch of strings. \n","    self.tokenize.get_concrete_function(\n","        tf.TensorSpec(shape=[None], dtype=tf.string))\n","    \n","    # Include `detokenize` and `lookup` signatures for:\n","    #   * `Tensors` with shapes [tokens] and [batch, tokens]\n","    #   * `RaggedTensors` with shape [batch, tokens]\n","    self.detokenize.get_concrete_function(\n","        tf.TensorSpec(shape=[None, None], dtype=tf.int32))\n","    self.detokenize.get_concrete_function(\n","          tf.RaggedTensorSpec(shape=[None, None], dtype=tf.int32))\n","\n","    self.lookup.get_concrete_function(\n","        tf.TensorSpec(shape=[None, None], dtype=tf.int32))\n","    self.lookup.get_concrete_function(\n","          tf.RaggedTensorSpec(shape=[None, None], dtype=tf.int32))\n","\n","    # These `get_*` methods take no arguments\n","    self.get_vocab_size.get_concrete_function()\n","    self.get_vocab_path.get_concrete_function()\n","    self.get_reserved_tokens.get_concrete_function()\n","    \n","  @tf.function\n","  def tokenize(self, strings):\n","    enc = self.tokenizer.tokenize(strings)\n","    # Merge the `word` and `word-piece` axes.\n","    enc = enc.merge_dims(-2,-1)\n","    enc = add_start_end(enc)\n","    return enc\n","\n","  @tf.function\n","  def detokenize(self, tokenized):\n","    words = self.tokenizer.detokenize(tokenized)\n","    return cleanup_text(self._reserved_tokens_vocab, words)\n","\n","  @tf.function\n","  def lookup(self, token_ids):\n","    return tf.gather(self.vocab, token_ids)\n","\n","  @tf.function\n","  def get_vocab_size(self):\n","    return tf.shape(self.vocab)[0]\n","\n","  @tf.function\n","  def get_vocab_path(self):\n","    return self._vocab_path\n","\n","  @tf.function\n","  def get_reserved_tokens(self):\n","    return tf.constant(self._reserved_tokens_vocab)"],"metadata":{"id":"iaAW-xm5WT1_","executionInfo":{"status":"ok","timestamp":1679653580399,"user_tz":-60,"elapsed":21,"user":{"displayName":"daniele badiali","userId":"08100546172874775759"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["tokenizers.ita = DecTokenizer(reserved_tokens_vocab, ita_vocab_filenamepath)"],"metadata":{"id":"svlLobM4WTzC","executionInfo":{"status":"ok","timestamp":1679653583674,"user_tz":-60,"elapsed":3294,"user":{"displayName":"daniele badiali","userId":"08100546172874775759"}}},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":["### Analisi Dati Tokenizzati"],"metadata":{"id":"pKZxiQ5_Whmw"}},{"cell_type":"code","source":["print(f'Vocabolario Italiano : {tokenizers.ita.get_vocab_size()}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Jrg6TwQzW5LN","executionInfo":{"status":"ok","timestamp":1679653583675,"user_tz":-60,"elapsed":12,"user":{"displayName":"daniele badiali","userId":"08100546172874775759"}},"outputId":"74e625c6-57c6-4bc5-caac-101376e71496"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["Vocabolario Italiano : 12844\n"]}]},{"cell_type":"markdown","source":["## Creazione dataset\n","Utilizzo della libreria tf.data per la gestione del dataset da utilizzare.\n","Verranno creati batch di esempi che verranno utilizzati durante l'addestramento."],"metadata":{"id":"5QIDajkEsVU1"}},{"cell_type":"code","source":["def split_dataset(df: pd.DataFrame,\n","                  filter_column: str, \n","                  debug: bool = False) -> Tuple:\n","\n","  dataset = (df.loc[df[TYPE_COLUMN] == filter_column]).copy() \n","  \n","  if NUM_SAMPLES > 0:\n","    dataset = dataset[:NUM_SAMPLES]\n","\n","  input_data = dataset[ORIGINAL_COLUMN].tolist()\n","  target_data = dataset[TRANSLATE_COLUMN].tolist()\n","\n","  train_input_data, validation_input_data, train_target_data, validation_target_data = train_test_split(\n","    input_data[:-TEST], \n","    target_data[:-TEST], \n","    test_size=TEST_SIZE, \n","    random_state=42,\n","    shuffle=True\n","  ) \n","\n","  train_input_data = train_input_data[:(int((len(train_input_data) / BATCH_SIZE)) * BATCH_SIZE)]\n","  train_target_data = train_target_data[:(int((len(train_target_data) / BATCH_SIZE)) * BATCH_SIZE)]\n","  \n","  validation_input_data = validation_input_data[:(int((len(validation_input_data) / BATCH_SIZE)) * BATCH_SIZE)]\n","  validation_target_data = validation_target_data[:(int((len(validation_target_data) / BATCH_SIZE)) * BATCH_SIZE)]\n","\n","  test_input_data = input_data[len(train_input_data)+len(validation_input_data):]\n","  test_target_data = target_data[len(train_target_data)+len(validation_target_data):]\n","\n","  if debug:\n","    print(f'Dati totali presenti nel Dataset               : {len(df)}')\n","    print(f'Dati totali presenti nel Dataset di Train      : {len(train_input_data)}')\n","    print(f'Dati totali presenti nel Dataset di Validation : {len(validation_input_data)}')\n","    print(f'Dati totali presenti nel Dataset di Test       : {len(test_input_data)}\\n')\n","\n","\n","    print('----------------------------------- TRAIN SET -----------------------------------------')\n","    print(train_input_data[-4:])\n","    print(train_target_data[-4:])\n","    print('--------------------------------- VALIDATION SET --------------------------------------')\n","    print(validation_input_data[-4:])\n","    print(validation_target_data[-4:])\n","    print('----------------------------------- TEST SET ------------------------------------------')\n","    print(test_input_data[-4:])\n","    print(test_target_data[-4:])\n","\n","    print('-------------------------------- ANALISI DATI -----------------------------------------')\n","    print(f'Esempi nel Dataset di Train                            : {len(train_input_data)}')\n","    print(f'Frase più corta nel Dataset Input di Train             : {min(train_input_data, key = len)}')\n","    print(f'Frase più corta nel Dataset Target di Train            : {min(train_target_data, key = len)}')\n","    print(f'Frase più lunga nel Dataset Input di Train             : {max(train_input_data, key = len)}')\n","    print(f'Frase più lunga nel Dataset Target di Train            : {max(train_target_data, key = len)}')\n","    print('---------------------------------------------------------------------------------------')\n","    print(f'Esempi nel Dataset di Validation                       : {len(validation_input_data)}')\n","    print(f'Frase più corta nel Dataset Input di Validation        : {min(validation_input_data, key = len)}')\n","    print(f'Frase più corta nel Dataset Target di Validation       : {min(validation_target_data, key = len)}')\n","    print(f'Frase più lunga nel Dataset Input di Validation        : {max(validation_input_data, key = len)}')\n","    print(f'Frase più lunga nel Dataset Target di Validation       : {max(validation_target_data, key = len)}')\n","    print('---------------------------------------------------------------------------------------')\n","    print(f'Esempi nel Dataset di Test                             : {len(test_input_data)}')\n","    print(f'Frase più corta nel Dataset Input di Test              : {min(test_input_data, key = len)}')\n","    print(f'Frase più corta nel Dataset Target di Test             : {min(test_target_data, key = len)}')\n","    print(f'Frase più lunga nel Dataset Input di Test              : {max(test_input_data, key = len)}')\n","    print(f'Frase più lunga nel Dataset Target di Test             : {max(test_target_data, key = len)}')    \n","\n","    print('\\n--------------------------------- EXAMPLE ---------------------------------------------')\n","    print([min(train_input_data, key = len)])\n","    print(tokenizers.multilingual.tokenize([min(train_input_data, key = len)])['input_word_ids'][:, :32])\n","    print('------------------------------------------------------------------')\n","    print([min(train_target_data, key = len)])\n","    print(tokenizers.ita.tokenize([min(train_target_data, key = len)]))\n","    print('\\n')\n","    print([max(train_input_data, key = len)])\n","    print(tokenizers.multilingual.tokenize([max(train_input_data, key = len)])['input_word_ids'])\n","    print('------------------------------------------------------------------')\n","    print([max(train_target_data, key = len)])\n","    print(tokenizers.ita.tokenize([max(train_target_data, key = len)]))  \n","  \n","  return train_input_data, validation_input_data, test_input_data, train_target_data, validation_target_data, test_target_data "],"metadata":{"id":"ESHUcQtthhd2","executionInfo":{"status":"ok","timestamp":1679653583675,"user_tz":-60,"elapsed":10,"user":{"displayName":"daniele badiali","userId":"08100546172874775759"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","source":["def prepare_batch(multilingual, ita):\n","  zero = tf.zeros([BATCH_SIZE, MAX_SEQ_LENGTH], tf.int32)\n","\n","  # Tokenizzo l'input per l'Encoder\n","  encoder = tokenizers.multilingual.tokenize(multilingual)          \n","\n","  # Tokenizzo l'input per il Decder e creo la variabile Target\n","  ita = tokenizers.ita.tokenize(ita)\n","  decoder = ita[:, :-1].to_tensor()  # Drop the [END] tokens\n","  target = ita[:, 1:].to_tensor()   # Drop the [START] tokens\n","  \n","  decoder = tf.concat([decoder, zero], 1)\n","  decoder = decoder[:, :(MAX_SEQ_LENGTH)]\n","\n","  target = tf.concat([target, zero], 1)\n","  target = target[:, :(MAX_SEQ_LENGTH)]\n","\n","  return (encoder, decoder), target"],"metadata":{"id":"ccH3jHoABPzV","executionInfo":{"status":"ok","timestamp":1679653583676,"user_tz":-60,"elapsed":10,"user":{"displayName":"daniele badiali","userId":"08100546172874775759"}}},"execution_count":26,"outputs":[]},{"cell_type":"code","source":["def make_batches(ds):\n","  return (\n","    ds\n","    .shuffle(BUFFER_SIZE)\n","    .batch(BATCH_SIZE)\n","    .map(prepare_batch, tf.data.AUTOTUNE)\n","    .prefetch(buffer_size=tf.data.AUTOTUNE))"],"metadata":{"id":"l_dswlCiBTdR","executionInfo":{"status":"ok","timestamp":1679653583677,"user_tz":-60,"elapsed":11,"user":{"displayName":"daniele badiali","userId":"08100546172874775759"}}},"execution_count":27,"outputs":[]},{"cell_type":"code","source":["def train_val_test_dataset(df: pd.DataFrame, \n","                          filter_column: str, \n","                          debug: bool = False) -> Tuple:\n","\n","  # Recupero il dataset \n","  train_input_data, validation_input_data, test_input_data, train_target_data, validation_target_data, test_target_data = split_dataset(df=df, filter_column=filter_column, debug=debug)\n","\n","  # Definizione del dataset\n","  # [from_tensor_slices] permette di recuperare batch\n","  # di esempi dai dataset di riferimento\n","  train_dataset = tf.data.Dataset.from_tensor_slices((train_input_data, train_target_data))\n","  validation_dataset = tf.data.Dataset.from_tensor_slices((validation_input_data, validation_target_data))\n","  test_dataset = tf.data.Dataset.from_tensor_slices((test_input_data, test_target_data))\n","\n","  # impostazione del recupero di esempi presi in maniera\n","  # casuale in gruppi di [BATCH_SIZE] tra quelli disponibili\n","  train_dataset = make_batches(train_dataset)\n","  validation_dataset = make_batches(validation_dataset)\n","\n","  return train_dataset, validation_dataset, test_dataset"],"metadata":{"id":"tktJ5YuIsYe3","executionInfo":{"status":"ok","timestamp":1679653583678,"user_tz":-60,"elapsed":11,"user":{"displayName":"daniele badiali","userId":"08100546172874775759"}}},"execution_count":28,"outputs":[]},{"cell_type":"code","source":["train_dataset_ita, validation_dataset_ita, test_dataset = train_val_test_dataset(df=df,\n","                                                                                 filter_column='ITA',\n","                                                                                 debug=debug)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nkcyLV1qqQHL","executionInfo":{"status":"ok","timestamp":1679653588412,"user_tz":-60,"elapsed":4745,"user":{"displayName":"daniele badiali","userId":"08100546172874775759"}},"outputId":"9d11536d-c1d5-4358-8472-38fcf0f16e66"},"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["Dati totali presenti nel Dataset               : 270358\n","Dati totali presenti nel Dataset di Train      : 17344\n","Dati totali presenti nel Dataset di Validation : 7424\n","Dati totali presenti nel Dataset di Test       : 232\n","\n","----------------------------------- TRAIN SET -----------------------------------------\n","[\"C' est le braquage de banque le plus sanglant qu' a connu ce pays . \", \"Il s' est converti au christianisme . \", 'Vous pouvez ècrire dans la langue que vous voulez . Sur Tatoeba , toutes les langues sont ègales . ', 'Elle a trois s urs une est infirmière et les autres sont enseignantes . ']\n","['È la rapina in banca più sanguinosa della storia di questo paese . ', 'Si è convertito al Cristianesimo . ', 'Puoi scrivere in qualsiasi lingua desideri . Su Tatoeba tutte le lingue sono uguali . ', 'Lei ha tre sorelle una è infermiera e le altre sono insegnanti . ']\n","--------------------------------- VALIDATION SET --------------------------------------\n","['Pourquoi la chance vous haït elle ? ', \"Le gouvernement des États Unis a taxè plusieurs pays d' États voyous , mais l' ironie du sort est qu' aujourd' hui , et après des dècennies de politiques agressives , d' interventions et d' invasions , ce sont les États Unis eux mêmes qui sont considèrès , dans le monde , comme l' État voyou par excellence . \", \"Je m' inquiète des rèsultats de l' examen . \", 'Vous allez marcher tous les matins . ']\n","['Perchè la fortuna vi odia ? ', \"Il governo americano ha tacciato diversi paesi come Stati canaglia , ma l' ironia è che oggi , dopo decenni di politiche aggressive , interventi e invasioni , sono gli Stati Uniti sono considerati in tutto il mondo come lo Stato canaglia per eccellenza . \", \"Mi preoccupo per i risultati dell' esame . \", 'Va a camminare ogni mattina . ']\n","----------------------------------- TEST SET ------------------------------------------\n","['Je ne vois aucun problème avec ça . ', 'Vous devez travailler , pas penser . ', \"Tatoeba n' est pas un dictionnaire . \", \"L' orthographe est très importante . \"]\n","['Non vedo dove stia il problema . ', 'Dovete lavorare , non pensare . ', 'Tatoeba non è un dizionario . ', \"L' ortografia è molto importante . \"]\n","-------------------------------- ANALISI DATI -----------------------------------------\n","Esempi nel Dataset di Train                            : 17344\n","Frase più corta nel Dataset Input di Train             :  Veux tu l' acheter ? Oui . \n","Frase più corta nel Dataset Target di Train            : Oggi offro io . \n","Frase più lunga nel Dataset Input di Train             : De même que , en temps de guerre , officiers et soldats se sentent autorisès par l' opinion gènèrale à commettre des actes qui , en temps de paix , sont tenus pour criminels , de même les rèvolutionnaires , dans leur lutte , se regardaient comme couverts par l' opinion de leur cercle , en vertu de laquelle les actes de cruautè qu' ils commettaient ètaient nobles et moraux , ètant commis par eux au prix de leur libertè , de leur vie , de tout ce qui est cher à la plupart des hommes . Ainsi s' expliquait , que des personnes excellentes , incapables non seulement de causer une souffrance , mais même d' en supporter la vue , pussent se prèparer tranquillement à la violence et au meurtre , et professer la saintetè de tels actes , considèrès comme moyens de dèfense , ou encore comme instrument utile à la rèalisation d' un idèal de bonheur pour l' humanitè . \n","Frase più lunga nel Dataset Target di Train            : Così come in tempo di guerra , ufficiali e soldati si sentono responsabilizzati dall' opinione generale a commettere atti che , in tempo di pace , sono necessari per i criminali , anche rivoluzionari nella loro lotta , considerati coperti dal parere del loro circolo , secondo cui gli atti di crudeltà che hanno commesso erano nobili e morali , essendo commessi da loro nel prezzo della loro libertà , della loro vita , di tutto ciò che è caro alla maggior parte degli uomini . Ciò ha spiegato che persone eccellenti , in grado non solo di causare sofferenza , ma anche di sopportarne la vista , potrebbero felicemente prepararsi alla violenza e all' omicidio , e professare la santità di tali atti , considerati come un mezzo di difesa , o come utili per la realizzazione di un ideale di felicità per l' umanità . \n","---------------------------------------------------------------------------------------\n","Esempi nel Dataset di Validation                       : 7424\n","Frase più corta nel Dataset Input di Validation        :  Veux tu l' acheter ? Oui . \n","Frase più corta nel Dataset Target di Validation       : Vuoi farlo ora ? \n","Frase più lunga nel Dataset Input di Validation        : Les États Unis ont plusieurs fois justifiè des interventions dans d' autres pays au nom de la protection des sacro saints intèrêts amèricains ou des citoyens amèricains à travers le monde . Le jour où , en 2008 , la Gèorgie avait attaquè des civils et des militaires russes en Ossètie du Sud , les Russes sont ègalement intervenus pour la protection lègitime de ses citoyens et militaires qui n' ètaient pas seulement victimes d' une attaque , mais d' un massacre . Mais lorsque ce sont les autres pays qui dèfendent leurs intèrêts et leurs civils au delà de leurs frontières , ceci ne plaît èvidemment pas aux États Unis . \n","Frase più lunga nel Dataset Target di Validation       : Gli Stati Uniti hanno ripetutamente giustificato degli interventi in altri paesi in nome della tutela degli interessi sacrosanti americani o dei cittadini americani in tutto il mondo . Il giorno in cui , nel 2008 , la Georgia ha attaccato civili e soldati russi in Ossezia del Sud , i russi sono ugualmente intervenuti per la legittima tutela dei loro cittadini e soldati che non erano solo le vittime di un attacco , ma di un massacro . Ma quando gli altri paesi stanno difendendo i loro interessi e civili oltre i loro confini , questo ovviamente non piace agli Stati Uniti . \n","---------------------------------------------------------------------------------------\n","Esempi nel Dataset di Test                             : 232\n","Frase più corta nel Dataset Input di Test              :  J' aime voyager . Moi aussi . \n","Frase più corta nel Dataset Target di Test             : Oggi è venerdì . \n","Frase più lunga nel Dataset Input di Test              : L' un est rouge , l' autre est blanc . \n","Frase più lunga nel Dataset Target di Test             : Molte persone hanno partecipato alla riunione . \n","\n","--------------------------------- EXAMPLE ---------------------------------------------\n","[\" Veux tu l' acheter ? Oui . \"]\n","tf.Tensor(\n","[[  101 19561 11855 13055   180   112 33478 28647   136 47060 10116   119\n","    102     0     0     0     0     0     0     0     0     0     0     0\n","      0     0     0     0     0     0     0     0]], shape=(1, 32), dtype=int32)\n","------------------------------------------------------------------\n","['Oggi offro io . ']\n","<tf.RaggedTensor [[2, 194, 10166, 91, 11, 3]]>\n","\n","\n","[\"De même que , en temps de guerre , officiers et soldats se sentent autorisès par l' opinion gènèrale à commettre des actes qui , en temps de paix , sont tenus pour criminels , de même les rèvolutionnaires , dans leur lutte , se regardaient comme couverts par l' opinion de leur cercle , en vertu de laquelle les actes de cruautè qu' ils commettaient ètaient nobles et moraux , ètant commis par eux au prix de leur libertè , de leur vie , de tout ce qui est cher à la plupart des hommes . Ainsi s' expliquait , que des personnes excellentes , incapables non seulement de causer une souffrance , mais même d' en supporter la vue , pussent se prèparer tranquillement à la violence et au meurtre , et professer la saintetè de tels actes , considèrès comme moyens de dèfense , ou encore comme instrument utile à la rèalisation d' un idèal de bonheur pour l' humanitè . \"]\n","tf.Tensor(\n","[[   101  10190  11594  10121    117  10110  12358  10104  14158    117\n","   59973  10131  25734  10126  97705  10368  37882  10107  13230  10248\n","     180    112  32282    175  20276  37833  10284    254  10986  11527\n","   10246  10139  37481  10355    117  10110  12358  10104  41795    117\n","   10647  69323  10107  10322    171 102422  58798    117  10104  11594\n","   10152    186  13340  34381  30861  38260    117  10260  11807  43927\n","     117  10126  42047  32247  10986  11170  98095  10107  10248    180\n","     112  32282  10104  11807  57775    117  10110  20900  10138  10104\n","   20600  10152  37481  10104    171  60021  11159  13340  10608    112\n","   13178  10986  12201  15617    262  26812  11405  43657  10131  25528\n","   11855    117    262  19533  10212  15240  10248  22502  10257  18236\n","   10104  11807  72517  10123  13340    117  10104  11807  13772    117\n","   10104  13003  10794  10355  10176  10262  10129    102]], shape=(1, 128), dtype=int32)\n","------------------------------------------------------------------\n","[\"Così come in tempo di guerra , ufficiali e soldati si sentono responsabilizzati dall' opinione generale a commettere atti che , in tempo di pace , sono necessari per i criminali , anche rivoluzionari nella loro lotta , considerati coperti dal parere del loro circolo , secondo cui gli atti di crudeltà che hanno commesso erano nobili e morali , essendo commessi da loro nel prezzo della loro libertà , della loro vita , di tutto ciò che è caro alla maggior parte degli uomini . Ciò ha spiegato che persone eccellenti , in grado non solo di causare sofferenza , ma anche di sopportarne la vista , potrebbero felicemente prepararsi alla violenza e all' omicidio , e professare la santità di tali atti , considerati come un mezzo di difesa , o come utili per la realizzazione di un ideale di felicità per l' umanità . \"]\n","<tf.RaggedTensor [[2, 154, 115, 87, 158, 81, 590, 10, 7398, 3091, 31, 2452, 93, 4776, 3824,\n","  3472, 368, 8, 983, 1701, 27, 3791, 4933, 82, 10, 87, 158, 81, 1203, 10,\n","  90, 10155, 89, 35, 2689, 10, 234, 44, 251, 360, 789, 1450, 9879, 583,\n","  159, 106, 3435, 10, 7543, 9991, 201, 3447, 103, 106, 9968, 10, 661, 206,\n","  111, 4933, 81, 3059, 250, 82, 117, 2065, 191, 7077, 31, 8708, 10, 2500,\n","  502, 5178, 99, 106, 139, 896, 120, 106, 1268, 10, 120, 106, 200, 10, 81,\n","  144, 238, 82, 31, 1662, 122, 973, 237, 235, 664, 11, 238, 88, 3037, 82,\n","  219, 9480, 10, 87, 399, 80, 167, 81, 8605, 10269, 10, 127, 234, 81, 180,\n","  9337, 3299, 83, 631, 10, 5976, 320, 605, 7091, 122, 2798, 31, 169, 8,\n","  1711, 10, 31, 4217, 8506, 12044, 83, 3034, 250, 81, 3766, 4933, 10,\n","  7543, 115, 86, 1054, 81, 3931, 10, 41, 115, 3770, 89, 83, 8754, 81, 86,\n","  6557, 81, 1569, 89, 38, 8, 3198, 11, 3]]>\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"7fQujOqYnQ5u","executionInfo":{"status":"ok","timestamp":1679653588413,"user_tz":-60,"elapsed":28,"user":{"displayName":"daniele badiali","userId":"08100546172874775759"}}},"execution_count":29,"outputs":[]},{"cell_type":"code","source":["# Recupero un batch di esempi per la verifica delle classi custom che andrò a creare\n","for (enc_input, dec_input), target in train_dataset_ita.take(1):\n","  print('----------------------- ENCODER  -------------------------------')\n","  print(f'Shape                    : {enc_input[\"input_word_ids\"].shape}')\n","  print(f'Word Ids                 : {enc_input[\"input_word_ids\"][0, :MAX_SEQ_LENGTH]}')\n","  print(f'Input Mask               : {enc_input[\"input_mask\"][0, :MAX_SEQ_LENGTH]}')\n","  print('--------------------- DECODER ----------------------------------')\n","  print(f'Shape it input           : {dec_input.shape}')\n","  print(f'Example it input         : {dec_input[0]}')  \n","  print('--------------------- TARGET -----------------------------------')\n","  print(f'Shape it input           : {target.shape}')\n","  print(f'Example it target        : {target[0]}')  "],"metadata":{"id":"VH_aKPlV_AWA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1679653590509,"user_tz":-60,"elapsed":2121,"user":{"displayName":"daniele badiali","userId":"08100546172874775759"}},"outputId":"d18381a3-eae7-4199-a867-1242f8fd1094"},"execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["----------------------- ENCODER  -------------------------------\n","Shape                    : (32, 128)\n","Word Ids                 : [  101 10468 82116 73170 22884 10647 10119 34949 26391 16401 31271   119\n","   102     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0]\n","Input Mask               : [1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n","--------------------- DECODER ----------------------------------\n","Shape it input           : (32, 128)\n","Example it input         : [   2   83 1044   31   86 1376  555   11    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0]\n","--------------------- TARGET -----------------------------------\n","Shape it input           : (32, 128)\n","Example it target        : [  83 1044   31   86 1376  555   11    3    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0]\n"]}]},{"cell_type":"markdown","source":["## Encoder BERT\n","\n","Predispondo la classe necessaria per la costruzione di BERT\n"],"metadata":{"id":"8dtVuZGJpvXl"}},{"cell_type":"code","source":["class EncoderBert(tf.keras.layers.Layer):\n","  def __init__(self, bert_encoder, embedding_dim, max_len, trainable):\n","    super(EncoderBert, self).__init__()\n","\n","    self.encoder = hub.KerasLayer(bert_encoder, name='BERT_encoder', trainable=trainable)\n","\n","    self.conv_1 = tf.keras.layers.Conv1D(embedding_dim * 4, 1, activation='relu') \n","    self.conv_2 = tf.keras.layers.Conv1D(embedding_dim, 1, activation='relu') \n","    self.lambda_layer = tf.keras.layers.Lambda(lambda x: x[:,:max_len])\n","    self.max_len = max_len\n","\n","  def call(self, x, debug=False):\n","\n","    if debug:\n","      print(f'****************** DEBUG ENCODER BERT ******************')\n","      print(f\"First example\")\n","      print(f'Keys                         : {list(x.keys())}')\n","      print(f'Shape                        : {x[\"input_word_ids\"].shape}')\n","      print(f'Word Ids                     : {x[\"input_word_ids\"][0, :16]}')\n","      print(f'Input Mask                   : {x[\"input_mask\"][0, :16]}')\n","      \n","    x = self.encoder(x)['sequence_output'] \n","    # encoder_outputs stato intermedio di BERT prima che esegua la traduzione recuperare la metà della lunghezza\n","    # x = self.encoder(x)['encoder_outputs'] \n","    # x = x[int(len(x) / 2) - 1]\n","\n","    if debug:\n","      print()\n","      print(f'Encoder Outputs BERT Shape   : {x.shape}')\n","      print(f'Encoder Outputs BERT Values  : {x[0, :1, :16]}')\n","\n","    x = self.conv_1(x)\n","    if debug:\n","      print()\n","      print(f'Sequence Conv1 Shape         : {x.shape}')\n","\n","    x = self.conv_2(x)\n","    if debug:\n","      print(f'Sequence Conv2 Shape         : {x.shape}')\n","\n","    x = self.lambda_layer(x)\n","    if debug:\n","      print(f'Sequence Lambda Layer        : {x.shape}')\n","      print()\n","      print(f'Sequence Outputs Values      : {x[0, 0, :16]}')      \n","      print('*********************************************************') \n","\n","    return x"],"metadata":{"id":"m7v9Y-Lep4CD","executionInfo":{"status":"ok","timestamp":1679653590509,"user_tz":-60,"elapsed":7,"user":{"displayName":"daniele badiali","userId":"08100546172874775759"}}},"execution_count":31,"outputs":[]},{"cell_type":"code","source":["encoder_bert = EncoderBert(tfhub_handle_encoder, \n","                           EMBEDDING_DIM, \n","                           MAX_SEQ_LENGTH,\n","                           trainable=trainable)\n","\n","bert_outputs = encoder_bert(enc_input, debug) "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Q08luTkusEfn","executionInfo":{"status":"ok","timestamp":1679653620824,"user_tz":-60,"elapsed":30321,"user":{"displayName":"daniele badiali","userId":"08100546172874775759"}},"outputId":"1473a8a9-0eed-483b-e7ec-481a6033adfe"},"execution_count":32,"outputs":[{"output_type":"stream","name":"stdout","text":["****************** DEBUG ENCODER BERT ******************\n","First example\n","Keys                         : ['input_word_ids', 'input_mask']\n","Shape                        : (32, 128)\n","Word Ids                     : [  101 10468 82116 73170 22884 10647 10119 34949 26391 16401 31271   119\n","   102     0     0     0]\n","Input Mask                   : [1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0]\n","\n","Encoder Outputs BERT Shape   : (32, 128, 768)\n","Encoder Outputs BERT Values  : [[-0.05932622 -0.02450966  0.01594409  0.16939148 -0.22637883  0.04824363\n","  -0.00487404  0.05210905  0.03817005  0.4283629   0.12320639 -0.15807968\n","  -0.42329246  0.28118968 -0.71894264 -0.01534941]]\n","\n","Sequence Conv1 Shape         : (32, 128, 512)\n","Sequence Conv2 Shape         : (32, 128, 128)\n","Sequence Lambda Layer        : (32, 128, 128)\n","\n","Sequence Outputs Values      : [0.         0.08652572 0.         0.3065675  0.         0.\n"," 0.         0.40885028 0.         0.         0.         0.\n"," 0.10284092 0.         0.         0.        ]\n","*********************************************************\n"]}]},{"cell_type":"markdown","source":["## Decoder\n","\n","Predispondo la classe necessaria per la costruzione di un Layer di Decoder"],"metadata":{"id":"ReEQ5rX7aGtl"}},{"cell_type":"markdown","source":["### TOKEN AND POSITION EMBEDDING\n","\n","Implementazione del blocco Embedding per l'utilizzo di vettori posizionali insieme ai vettori di token di parole tramite estensione della classe Layer di Keras. "],"metadata":{"id":"gAu1IXlRZzlq"}},{"cell_type":"code","source":["class TokenAndPositionEmbedding(tf.keras.layers.Layer):\n","  def __init__(self, maxlen, vocab_size, embed_dim):\n","    super(TokenAndPositionEmbedding, self).__init__()\n","    self.maxlen = maxlen\n","    self.token_emb = tf.keras.layers.Embedding(input_dim=vocab_size, output_dim=embed_dim)\n","    self.pos_emb = tf.keras.layers.Embedding(input_dim=maxlen, output_dim=embed_dim)\n","\n","  def call(self, x, debug=False):\n","    x = tf.keras.preprocessing.sequence.pad_sequences(x, maxlen=self.maxlen, padding='post')\n","    maxlen = tf.shape(x)[-1]\n","\n","    if debug:\n","      print('********** DEBUG TOKEN AND POSITION EMBEDDING ***********')\n","      print(f'Sequence Max len                          : {maxlen}')\n","      print(f'Sequence Shape                            : {tf.shape(x)}')\n","\n","    positions = tf.range(start=0, limit=maxlen, delta=1)\n","    positions = self.pos_emb(positions)\n","    x = self.token_emb(x)\n","    output = x + positions\n","\n","    if debug:\n","      print(f'Shape TokenAndPositionEmbedding           : {output.shape}')\n","      print('*********************************************************')\n","\n","    return output"],"metadata":{"id":"o9-RSKTqsmUC","executionInfo":{"status":"ok","timestamp":1679653620825,"user_tz":-60,"elapsed":30,"user":{"displayName":"daniele badiali","userId":"08100546172874775759"}}},"execution_count":33,"outputs":[]},{"cell_type":"code","source":["token_position_it = TokenAndPositionEmbedding(MAX_SEQ_LENGTH, tokenizers.ita.get_vocab_size(), EMBEDDING_DIM)\n","\n","inputs_decoder = token_position_it(dec_input, debug)"],"metadata":{"id":"rr_EWQUX8EWP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1679653620826,"user_tz":-60,"elapsed":30,"user":{"displayName":"daniele badiali","userId":"08100546172874775759"}},"outputId":"7f2b785e-c8e5-4a48-971d-6c5cdf42d6ca"},"execution_count":34,"outputs":[{"output_type":"stream","name":"stdout","text":["********** DEBUG TOKEN AND POSITION EMBEDDING ***********\n","Sequence Max len                          : 128\n","Sequence Shape                            : [ 32 128]\n","Shape TokenAndPositionEmbedding           : (32, 128, 128)\n","*********************************************************\n"]}]},{"cell_type":"markdown","source":["### LAYER DECODER\n","\n","Implementazione di un blocco di DecoderTransformer tramite estensione della classe Layer di Keras"],"metadata":{"id":"XdLv-6nidKGK"}},{"cell_type":"markdown","source":["#### DecodeBert\n","\n","Implmentazione di un blocco di  decodifica custom per decodificare l'output dal layer EncoderBert prima di passarlo al Decoder del Transformer tramite estensione della classe Layer di Keras"],"metadata":{"id":"_iq7Y-d4eRd8"}},{"cell_type":"code","source":["class DecodeBert(tf.keras.layers.Layer):\n","  def __init__(self, max_len, embed_dim, num_heads, ff_dim, rate=0.5, name='DecodeBert'):\n","    super(DecodeBert, self).__init__()\n","    self.att = tf.keras.layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n","    self.ffn = tf.keras.Sequential(\n","      [tf.keras.layers.Dense(ff_dim, activation='relu'), \n","       tf.keras.layers.Dense(embed_dim),]\n","    )\n","    self.layernorm1 = tf.keras.layers.LayerNormalization()\n","    self.layernorm2 = tf.keras.layers.LayerNormalization()\n","    self.dropout1 = tf.keras.layers.Dropout(rate)\n","    self.dropout2 = tf.keras.layers.Dropout(rate)\n","    self._name = name\n","\n","  def call(self, bert_outputs, training=False, debug=False):\n","    attn_output = self.att(query=bert_outputs,\n","                           value=bert_outputs, \n","                           key=bert_outputs)\n","    \n","    attn_output = self.dropout1(attn_output)\n","    out1 = self.layernorm1(bert_outputs + attn_output)\n","\n","    ffn_output = self.ffn(out1)\n","    ffn_output = self.dropout2(ffn_output, training=training)\n","\n","    output = self.layernorm2(out1 + ffn_output)\n","\n","    if debug:\n","      print('********************* DEBUG DECODE-BERT *********************')\n","      print(f'Shape Input Layer Decode-Bert       : {bert_outputs.shape}')\n","      print(f'Shape Output Layer Decode-Bert      : {output.shape}')\n","      print('*********************************************************')\n","\n","    return output"],"metadata":{"id":"joTBTlWF8ETD","executionInfo":{"status":"ok","timestamp":1679653620827,"user_tz":-60,"elapsed":28,"user":{"displayName":"daniele badiali","userId":"08100546172874775759"}}},"execution_count":35,"outputs":[]},{"cell_type":"code","source":["encoder = DecodeBert(MAX_SEQ_LENGTH, \n","                  EMBEDDING_DIM, \n","                  NUM_HEADS, \n","                  FF_DIM, \n","                  DROPUOT)\n","\n","outputs_encoder = encoder(bert_outputs=bert_outputs,\n","                          training=training, \n","                          debug=debug)"],"metadata":{"id":"JaIzBxFCfKe9","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1679653621990,"user_tz":-60,"elapsed":1190,"user":{"displayName":"daniele badiali","userId":"08100546172874775759"}},"outputId":"77e1ee94-8d73-46e3-c90f-0eee6f120129"},"execution_count":36,"outputs":[{"output_type":"stream","name":"stdout","text":["********************* DEBUG DECODE-BERT *********************\n","Shape Input Layer Decode-Bert       : (32, 128, 128)\n","Shape Output Layer Decode-Bert      : (32, 128, 128)\n","*********************************************************\n"]}]},{"cell_type":"markdown","source":["#### Layer Decoder"],"metadata":{"id":"dMTKLwd3dRw5"}},{"cell_type":"code","source":["class Decoder(tf.keras.layers.Layer):\n","  def __init__(self, max_len, embed_dim, num_heads, ff_dim, rate=0.5, name='DEC'):\n","    super(Decoder, self).__init__()\n","    self.decode_bert = DecodeBert(max_len=max_len, embed_dim=embed_dim, num_heads=num_heads, ff_dim=ff_dim, rate=rate)\n","    self.att1 = tf.keras.layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n","    self.att2 = tf.keras.layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n","    self.ffn = tf.keras.Sequential(\n","      [tf.keras.layers.Dense(ff_dim, activation='relu'), \n","       tf.keras.layers.Dense(embed_dim),]\n","    )\n","    self.layernorm1 = tf.keras.layers.LayerNormalization()\n","    self.layernorm2 = tf.keras.layers.LayerNormalization()\n","    self.layernorm3 = tf.keras.layers.LayerNormalization()\n","    self.dropout1 = tf.keras.layers.Dropout(rate)\n","    self.dropout2 = tf.keras.layers.Dropout(rate)\n","    self.dropout3 = tf.keras.layers.Dropout(rate)\n","    self._name = name\n","\n","  def call(self, inputs, bert_outputs, training=False, debug=False):\n","    attn_output1 = self.att1(query=inputs,\n","                             value=inputs, \n","                             key=inputs, \n","                             use_causal_mask=True)\n","    \n","    attn_output1 = self.dropout1(attn_output1)\n","    out1 = self.layernorm1(inputs + attn_output1)\n","\n","    dec_bert = self.decode_bert(bert_outputs=bert_outputs, training=training, debug=debug)\n","\n","    attn_output2 = self.att2(key=dec_bert, \n","                             value=dec_bert, \n","                             query=out1)\n","    \n","    attn_output2 = self.dropout2(attn_output2, training=training)\n","    out2 = self.layernorm2(out1 + attn_output2)\n","\n","    ffn_output = self.ffn(out2)\n","    ffn_output = self.dropout3(ffn_output, training=training)\n","\n","    output = self.layernorm3(out2 + ffn_output)\n","\n","    if debug:\n","      print('******************* DEBUG DECODER ***********************')\n","      print(f'Input Shape                       : {inputs.shape}')\n","      print(f'Shape Outputs Decoder             : {output.shape}')\n","      print('*********************************************************')\n","\n","    return output"],"metadata":{"id":"SO5rYsFpfFS_","executionInfo":{"status":"ok","timestamp":1679653621990,"user_tz":-60,"elapsed":8,"user":{"displayName":"daniele badiali","userId":"08100546172874775759"}}},"execution_count":37,"outputs":[]},{"cell_type":"code","source":["decoder = Decoder(MAX_SEQ_LENGTH, \n","                  EMBEDDING_DIM, \n","                  NUM_HEADS, \n","                  FF_DIM, \n","                  DROPUOT)\n","\n","outputs_decoder = decoder(inputs=inputs_decoder, \n","                          bert_outputs=bert_outputs,  \n","                          training=training,\n","                          debug=debug)"],"metadata":{"id":"yysVdkHH8EPH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1679653621991,"user_tz":-60,"elapsed":9,"user":{"displayName":"daniele badiali","userId":"08100546172874775759"}},"outputId":"39f64d1f-98e6-4826-cff7-e85441e4c9f6"},"execution_count":38,"outputs":[{"output_type":"stream","name":"stdout","text":["********************* DEBUG DECODE-BERT *********************\n","Shape Input Layer Decode-Bert       : (32, 128, 128)\n","Shape Output Layer Decode-Bert      : (32, 128, 128)\n","*********************************************************\n","******************* DEBUG DECODER ***********************\n","Input Shape                       : (32, 128, 128)\n","Shape Outputs Decoder             : (32, 128, 128)\n","*********************************************************\n"]}]},{"cell_type":"markdown","source":["## TRANSFORMER\n","\n","Implementazione del blocco Transformer tramite estensione della classe Layer di Keras."],"metadata":{"id":"ne4zTOG_NKfV"}},{"cell_type":"code","execution_count":39,"metadata":{"pycharm":{"name":"#%%\n"},"id":"lw2xMCAMC_4M","executionInfo":{"status":"ok","timestamp":1679653621991,"user_tz":-60,"elapsed":5,"user":{"displayName":"daniele badiali","userId":"08100546172874775759"}}},"outputs":[],"source":["class TransformerBlock(tf.keras.Model):\n","  def __init__(self, \n","               num_layers, \n","               embed_dim, \n","               num_heads, \n","               ff_dim, \n","               max_len,\n","               vocab_size,\n","               tfhub_handle_encoder,\n","               trainable,\n","               rate=0.5):\n","    \n","    super(TransformerBlock, self).__init__()\n","\n","    self.num_layers = num_layers\n","\n","    self.token_pos_dec = TokenAndPositionEmbedding(max_len, vocab_size, embed_dim)\n","\n","    self.encoder = EncoderBert(tfhub_handle_encoder, embed_dim, max_len, trainable=trainable)\n","    self.decoder = [Decoder(max_len, embed_dim, num_heads, ff_dim, rate) for _ in range(num_layers)]\n","\n","    self.dropout = tf.keras.layers.Dropout(rate)\n","    self.final_layer = tf.keras.layers.Dense(vocab_size)\n","\n","  def call(self, inputs, training=False, debug=False):\n","    inputs_encoder, inputs_decoder  = inputs\n","\n","    encoder_output = self.encoder(inputs_encoder, debug) \n","\n","    inputs_decoder = self.token_pos_dec(inputs_decoder, debug)\n","\n","    if debug:\n","      print(f'---------------- DEBUG TRANSFORMER BLOCK ----------------')\n","      print(f'inputs_encoder       : {inputs_encoder[\"input_word_ids\"].shape}')\n","      print(f'inputs_decoder       : {inputs_decoder.shape}')      \n","\n","    transformer_output = inputs_decoder\n","      \n","    for i in range(self.num_layers):\n","      transformer_output = self.decoder[i](inputs=transformer_output, \n","                                           bert_outputs=encoder_output, \n","                                           training=training,\n","                                           debug=debug)\n","\n","    transformer_output = self.dropout(transformer_output)\n","    logits = self.final_layer(transformer_output)\n","\n","    if debug:\n","      print(f'Output Shape       : {logits.shape}')\n","      print(f'Output Transformer : {logits[0, :1, :12]}')    \n","      print(f'---------------------------------------------------------')\n","\n","    return logits"]},{"cell_type":"code","source":["transformer = TransformerBlock(NUM_LAYERS, \n","                               EMBEDDING_DIM, \n","                               NUM_HEADS, \n","                               FF_DIM,\n","                               MAX_SEQ_LENGTH,\n","                               tokenizers.ita.get_vocab_size(),\n","                               tfhub_handle_encoder,\n","                               trainable,\n","                               DROPUOT)\n","\n","transformer_output = transformer((enc_input, dec_input), \n","                                 training=training,\n","                                 debug=debug)"],"metadata":{"id":"pr--G0ZZVAMi","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1679653629201,"user_tz":-60,"elapsed":7214,"user":{"displayName":"daniele badiali","userId":"08100546172874775759"}},"outputId":"c542f09b-0d77-494a-c145-2cfeaa33e94d"},"execution_count":40,"outputs":[{"output_type":"stream","name":"stdout","text":["****************** DEBUG ENCODER BERT ******************\n","First example\n","Keys                         : ['input_word_ids', 'input_mask']\n","Shape                        : (32, 128)\n","Word Ids                     : [  101 10468 82116 73170 22884 10647 10119 34949 26391 16401 31271   119\n","   102     0     0     0]\n","Input Mask                   : [1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0]\n","\n","Encoder Outputs BERT Shape   : (32, 128, 768)\n","Encoder Outputs BERT Values  : [[-0.07143205  0.02140668  0.02530316  0.00798056  0.03708839  0.03234966\n","  -0.03790144 -0.04606504  0.07782634  0.43882686  0.0689071  -0.16919303\n","  -0.36454916  0.23624077 -0.7633237   0.04033431]]\n","\n","Sequence Conv1 Shape         : (32, 128, 512)\n","Sequence Conv2 Shape         : (32, 128, 128)\n","Sequence Lambda Layer        : (32, 128, 128)\n","\n","Sequence Outputs Values      : [0.2168459  0.44895282 0.         0.         0.         0.\n"," 0.19694921 0.         0.         0.00430052 0.5972345  0.18939322\n"," 0.         0.62338215 0.6419823  0.        ]\n","*********************************************************\n","********** DEBUG TOKEN AND POSITION EMBEDDING ***********\n","Sequence Max len                          : 128\n","Sequence Shape                            : [ 32 128]\n","Shape TokenAndPositionEmbedding           : (32, 128, 128)\n","*********************************************************\n","---------------- DEBUG TRANSFORMER BLOCK ----------------\n","inputs_encoder       : (32, 128)\n","inputs_decoder       : (32, 128, 128)\n","********************* DEBUG DECODE-BERT *********************\n","Shape Input Layer Decode-Bert       : (32, 128, 128)\n","Shape Output Layer Decode-Bert      : (32, 128, 128)\n","*********************************************************\n","******************* DEBUG DECODER ***********************\n","Input Shape                       : (32, 128, 128)\n","Shape Outputs Decoder             : (32, 128, 128)\n","*********************************************************\n","Output Shape       : (32, 128, 12844)\n","Output Transformer : [[ 0.0796621  -0.11398695  0.15711969 -0.03479096 -0.45892045 -0.2534207\n","  -0.12932934 -0.10040827  0.0839111  -0.12099002 -0.47772974 -0.05605769]]\n","---------------------------------------------------------\n"]}]},{"cell_type":"code","source":["transformer.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0kYt6ehvh-8B","executionInfo":{"status":"ok","timestamp":1679653629202,"user_tz":-60,"elapsed":35,"user":{"displayName":"daniele badiali","userId":"08100546172874775759"}},"outputId":"f50d1bbf-3ffb-4c16-8165-48f174013cd7"},"execution_count":41,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"transformer_block\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," token_and_position_embeddin  multiple                 1660416   \n"," g_1 (TokenAndPositionEmbedd                                     \n"," ing)                                                            \n","                                                                 \n"," encoder_bert_1 (EncoderBert  multiple                 135193472 \n"," )                                                               \n","                                                                 \n"," DEC (Decoder)               multiple                  1592224   \n","                                                                 \n"," dropout_16 (Dropout)        multiple                  0         \n","                                                                 \n"," dense_10 (Dense)            multiple                  1656876   \n","                                                                 \n","=================================================================\n","Total params: 140,102,988\n","Trainable params: 140,102,988\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"markdown","source":["## Addestramento Modello"],"metadata":{"id":"IFmcHTSDTvYk"}},{"cell_type":"markdown","source":["### Compilazione"],"metadata":{"id":"tiuqPlHo0Z0n"}},{"cell_type":"code","source":["transformer.compile(\n","  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n","  optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE_ADAM, \n","                                     beta_1=BETA_1, \n","                                     beta_2=BETA_2),\n","  metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])"],"metadata":{"id":"bOyqCyjIr-L2","executionInfo":{"status":"ok","timestamp":1679653629202,"user_tz":-60,"elapsed":20,"user":{"displayName":"daniele badiali","userId":"08100546172874775759"}}},"execution_count":42,"outputs":[]},{"cell_type":"markdown","source":["### Callbacks"],"metadata":{"id":"-z6qj1uclHRa"}},{"cell_type":"code","source":["# Create a callback that saves the model's weights\n","cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n","                                                 save_weights_only=True,\n","                                                 save_best_only=True)\n","\n","# Create a callback Tensorboard\n","tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir)\n","\n","# Create a callback save the log history\n","json_logging_callback = tf.keras.callbacks.LambdaCallback(\n","  on_epoch_end=lambda epoch, logs: json_log.write(\n","    json.dumps({'epoch': epoch, \n","                'loss': logs['loss'],\n","                'sparse_categorical_accuracy': logs['sparse_categorical_accuracy'],\n","                'val_loss': logs['val_loss'],\n","                'val_sparse_categorical_accuracy': logs['val_sparse_categorical_accuracy']}) + '\\n'),\n","  on_train_end=lambda logs: json_log.close()\n",")"],"metadata":{"id":"3hurmpSjJ_dT","executionInfo":{"status":"ok","timestamp":1679653629202,"user_tz":-60,"elapsed":19,"user":{"displayName":"daniele badiali","userId":"08100546172874775759"}}},"execution_count":43,"outputs":[]},{"cell_type":"markdown","source":["### Train Ita"],"metadata":{"id":"Day7C7Qh0b4G"}},{"cell_type":"code","source":["start = datetime.datetime.now()\n","json_log = open(log_history, mode='a', buffering=1, encoding='utf-8')\n","\n","transformer.fit(train_dataset_ita,\n","                initial_epoch=0,\n","                epochs=EPOCHS_ADAM,\n","                shuffle=True,\n","                validation_data=validation_dataset_ita,\n","                callbacks=[tensorboard_callback,\n","                           json_logging_callback, \n","                           cp_callback])\n","\n","end = datetime.datetime.now()\n","print(f'Tempo necessario per l\\'addestramento: {end - start}')"],"metadata":{"id":"etOGtBcer9yi","colab":{"base_uri":"https://localhost:8080/"},"outputId":"04663486-4e59-43f1-b28d-eda32778355d","executionInfo":{"status":"ok","timestamp":1679617258039,"user_tz":-60,"elapsed":12284959,"user":{"displayName":"Daniele Badiali","userId":"10202881816518872932"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/20\n","542/542 [==============================] - 617s 1s/step - loss: 3.2438 - sparse_categorical_accuracy: 0.9020 - val_loss: 0.6460 - val_sparse_categorical_accuracy: 0.9225\n","Epoch 2/20\n","542/542 [==============================] - 575s 1s/step - loss: 0.5874 - sparse_categorical_accuracy: 0.9274 - val_loss: 0.4974 - val_sparse_categorical_accuracy: 0.9334\n","Epoch 3/20\n","542/542 [==============================] - 584s 1s/step - loss: 0.4951 - sparse_categorical_accuracy: 0.9335 - val_loss: 0.4557 - val_sparse_categorical_accuracy: 0.9362\n","Epoch 4/20\n","542/542 [==============================] - 575s 1s/step - loss: 0.4565 - sparse_categorical_accuracy: 0.9360 - val_loss: 0.4294 - val_sparse_categorical_accuracy: 0.9387\n","Epoch 5/20\n","542/542 [==============================] - 623s 1s/step - loss: 0.4282 - sparse_categorical_accuracy: 0.9384 - val_loss: 0.4060 - val_sparse_categorical_accuracy: 0.9410\n","Epoch 6/20\n","542/542 [==============================] - 601s 1s/step - loss: 0.4033 - sparse_categorical_accuracy: 0.9411 - val_loss: 0.3834 - val_sparse_categorical_accuracy: 0.9438\n","Epoch 7/20\n","542/542 [==============================] - 603s 1s/step - loss: 0.3808 - sparse_categorical_accuracy: 0.9434 - val_loss: 0.3646 - val_sparse_categorical_accuracy: 0.9460\n","Epoch 8/20\n","542/542 [==============================] - 569s 1s/step - loss: 0.3597 - sparse_categorical_accuracy: 0.9458 - val_loss: 0.3454 - val_sparse_categorical_accuracy: 0.9482\n","Epoch 9/20\n","542/542 [==============================] - 602s 1s/step - loss: 0.3404 - sparse_categorical_accuracy: 0.9481 - val_loss: 0.3316 - val_sparse_categorical_accuracy: 0.9501\n","Epoch 10/20\n","542/542 [==============================] - 600s 1s/step - loss: 0.3231 - sparse_categorical_accuracy: 0.9501 - val_loss: 0.3191 - val_sparse_categorical_accuracy: 0.9517\n","Epoch 11/20\n","542/542 [==============================] - 562s 1s/step - loss: 0.3077 - sparse_categorical_accuracy: 0.9520 - val_loss: 0.3053 - val_sparse_categorical_accuracy: 0.9534\n","Epoch 12/20\n","542/542 [==============================] - 599s 1s/step - loss: 0.2924 - sparse_categorical_accuracy: 0.9539 - val_loss: 0.2959 - val_sparse_categorical_accuracy: 0.9549\n","Epoch 13/20\n","542/542 [==============================] - 599s 1s/step - loss: 0.2789 - sparse_categorical_accuracy: 0.9557 - val_loss: 0.2856 - val_sparse_categorical_accuracy: 0.9568\n","Epoch 14/20\n","542/542 [==============================] - 598s 1s/step - loss: 0.2661 - sparse_categorical_accuracy: 0.9574 - val_loss: 0.2767 - val_sparse_categorical_accuracy: 0.9579\n","Epoch 15/20\n","542/542 [==============================] - 564s 1s/step - loss: 0.2541 - sparse_categorical_accuracy: 0.9589 - val_loss: 0.2715 - val_sparse_categorical_accuracy: 0.9589\n","Epoch 16/20\n","542/542 [==============================] - 599s 1s/step - loss: 0.2426 - sparse_categorical_accuracy: 0.9605 - val_loss: 0.2641 - val_sparse_categorical_accuracy: 0.9604\n","Epoch 17/20\n","542/542 [==============================] - 596s 1s/step - loss: 0.2315 - sparse_categorical_accuracy: 0.9619 - val_loss: 0.2592 - val_sparse_categorical_accuracy: 0.9614\n","Epoch 18/20\n","542/542 [==============================] - 598s 1s/step - loss: 0.2212 - sparse_categorical_accuracy: 0.9633 - val_loss: 0.2549 - val_sparse_categorical_accuracy: 0.9624\n","Epoch 19/20\n","542/542 [==============================] - 598s 1s/step - loss: 0.2116 - sparse_categorical_accuracy: 0.9646 - val_loss: 0.2496 - val_sparse_categorical_accuracy: 0.9634\n","Epoch 20/20\n","542/542 [==============================] - 597s 1s/step - loss: 0.2025 - sparse_categorical_accuracy: 0.9658 - val_loss: 0.2443 - val_sparse_categorical_accuracy: 0.9644\n","Tempo necessario per l'addestramento: 3:24:44.506603\n"]}]},{"cell_type":"code","source":["# Carico i pesi modello\n","latest = tf.train.latest_checkpoint(PATH_WEIGHTS)\n","transformer.load_weights(latest)"],"metadata":{"id":"5KeU08tmS3UK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["start = datetime.datetime.now()\n","json_log = open(log_history, mode='a', buffering=1, encoding='utf-8')\n","\n","transformer.fit(train_dataset_ita,\n","                initial_epoch=EPOCHS_ADAM,\n","                epochs=EPOCHS_ADAM+EPOCHS_ADAM,\n","                shuffle=True,\n","                validation_data=validation_dataset_ita,\n","                callbacks=[tensorboard_callback,\n","                           json_logging_callback, \n","                           cp_callback])\n","\n","end = datetime.datetime.now()\n","print(f'Tempo necessario per l\\'addestramento: {end - start}')"],"metadata":{"id":"PLZGGXQxS9V5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Train Dante"],"metadata":{"id":"GhBGzbvrh2Rw"}},{"cell_type":"code","source":["train_dataset_dante, validation_dataset_dante, test_dataset = train_val_test_dataset(df=df, filter_column='DANTE', debug=debug)"],"metadata":{"id":"kndzuk5XVnmM","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1679653633286,"user_tz":-60,"elapsed":4103,"user":{"displayName":"daniele badiali","userId":"08100546172874775759"}},"outputId":"ff727f47-2cf9-497e-fdcd-50ee77607524"},"execution_count":44,"outputs":[{"output_type":"stream","name":"stdout","text":["Dati totali presenti nel Dataset               : 270358\n","Dati totali presenti nel Dataset di Train      : 17344\n","Dati totali presenti nel Dataset di Validation : 7424\n","Dati totali presenti nel Dataset di Test       : 232\n","\n","----------------------------------- TRAIN SET -----------------------------------------\n","['E al pelare conviene avere maniera , ', 'essayer , comprendre et ècouter', 'e così si pentirà della sua follia . ', 'mostrando di fare vita agreste , ']\n","['E al pelar convien aver maniera , ', 'A ritenere intendi , e a udire , ', 'Sì ssi ripentirà di sua follia . ', \"Mostrando ched i' faccia vita agresta;\"]\n","--------------------------------- VALIDATION SET --------------------------------------\n","['Si je le dis pour le tromper . ', \"con tutt' altro che nobile e vero amore . \", 'ihren Status und ihren Zustand;', \"Et il n' a jamais dit un vrai mot . \"]\n","[\"Ched i' non dica ciò per inghanarlo . \", 'Se non di fino e di leal amore . ', 'Di loro stato e di lor condizione;', 'Nè non diciea giamai parola vera . ']\n","----------------------------------- TEST SET ------------------------------------------\n","['Bien sûr , si Dieu vous accorde la vie , ', \"Que vous aurez de l' èducation et apprendre . \", 'Tu as commencè à apprendre de moi . ', 'Regarde toi , tu es bien rassurèe . ']\n","['Ciertana son , se Dio ti dona vita , ', 'Che ttu terai scuola , e legierai . ', \"Di legierne da me congìo tu n' ài;\", 'Ma guardati , che ttu sie ben fornita']\n","-------------------------------- ANALISI DATI -----------------------------------------\n","Esempi nel Dataset di Train                            : 17344\n","Frase più corta nel Dataset Input di Train             : kühn , kühn , \n","Frase più corta nel Dataset Target di Train            : E gli giurai a le sante\n","Frase più lunga nel Dataset Input di Train             : Auch die Erscheinung des Menschen nicht zu schätzen , der mit seiner eigenen Schönheit ausgestattet ist\n","Frase più lunga nel Dataset Target di Train            : Chè 'l cuor , che nn' ama un sol , non val un fico . \n","---------------------------------------------------------------------------------------\n","Esempi nel Dataset di Validation                       : 7424\n","Frase più corta nel Dataset Input di Validation        : Trotz Neid . \n","Frase più corta nel Dataset Target di Validation       : E gli giurai a le sante\n","Frase più lunga nel Dataset Input di Validation        : Er ist vielleicht nicht feindseliger gegen mich , aber er wird vielleicht auf den Boden abgeschossen . \n","Frase più lunga nel Dataset Target di Validation       : Chè 'l cuor , che nn' ama un sol , non val un fico . \n","---------------------------------------------------------------------------------------\n","Esempi nel Dataset di Test                             : 232\n","Frase più corta nel Dataset Input di Test              : hardiment , hardiment , \n","Frase più corta nel Dataset Target di Test             : A gran pena può femina venire\n","Frase più lunga nel Dataset Input di Test              : Cependant , il est prèfèrable pour lui de savoir comment les gèrer avec compètence . \n","Frase più lunga nel Dataset Target di Test             : Chè 'l cuor , che nn' ama un sol , non val un fico . \n","\n","--------------------------------- EXAMPLE ---------------------------------------------\n","['kühn , kühn , ']\n","tf.Tensor(\n","[[  101   179 12369 15797   117   179 12369 15797   117   102     0     0\n","      0     0     0     0     0     0     0     0     0     0     0     0\n","      0     0     0     0     0     0     0     0]], shape=(1, 32), dtype=int32)\n","------------------------------------------------------------------\n","['E gli giurai a le sante']\n","<tf.RaggedTensor [[2, 31, 111, 5351, 251, 27, 96, 5527, 3]]>\n","\n","\n","['Auch die Erscheinung des Menschen nicht zu schätzen , der mit seiner eigenen Schönheit ausgestattet ist']\n","tf.Tensor(\n","[[   101  14427  10128 101457  10139  16352  10726  10304    187  10269\n","   81293    117  10118  10221  11411  21111  55260  90929  15543  57862\n","   10298    102      0      0      0      0      0      0      0      0\n","       0      0      0      0      0      0      0      0      0      0\n","       0      0      0      0      0      0      0      0      0      0\n","       0      0      0      0      0      0      0      0      0      0\n","       0      0      0      0      0      0      0      0      0      0\n","       0      0      0      0      0      0      0      0      0      0\n","       0      0      0      0      0      0      0      0      0      0\n","       0      0      0      0      0      0      0      0      0      0\n","       0      0      0      0      0      0      0      0      0      0\n","       0      0      0      0      0      0      0      0      0      0\n","       0      0      0      0      0      0      0      0]], shape=(1, 128), dtype=int32)\n","------------------------------------------------------------------\n","[\"Chè 'l cuor , che nn' ama un sol , non val un fico . \"]\n","<tf.RaggedTensor [[2, 82, 8, 38, 1192, 10, 82, 4726, 8, 707, 86, 1638, 10, 80, 7152, 86,\n","  7269, 11, 3]]>\n"]}]},{"cell_type":"code","source":["# Carico i pesi modello\n","latest = tf.train.latest_checkpoint(PATH_WEIGHTS)\n","transformer.load_weights(latest)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4ejTGcN8h4we","executionInfo":{"status":"ok","timestamp":1679653648478,"user_tz":-60,"elapsed":15195,"user":{"displayName":"daniele badiali","userId":"08100546172874775759"}},"outputId":"1595be32-937e-437e-a947-b8b3eee1df54"},"execution_count":45,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x7fc4ba61a070>"]},"metadata":{},"execution_count":45}]},{"cell_type":"code","source":["start = datetime.datetime.now()\n","\n","json_log = open(log_history, mode='a', buffering=1, encoding='utf-8')\n","\n","transformer.fit(train_dataset_dante,\n","                initial_epoch=EPOCHS_ADAM,\n","                epochs=EPOCHS_ADAM+EPOCHS_ADAM,\n","                shuffle=True,\n","                validation_data=validation_dataset_dante,\n","                callbacks=[tensorboard_callback,\n","                           json_logging_callback, \n","                           cp_callback])\n","\n","end = datetime.datetime.now()\n","print(f'Tempo necessario per l\\'addestramento: {end - start}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UZ0iTUOXh70W","outputId":"b39b3418-a49c-4f38-9022-ccf3adfb0ae1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 21/40\n","542/542 [==============================] - 615s 1s/step - loss: 0.4851 - sparse_categorical_accuracy: 0.9355 - val_loss: 0.3936 - val_sparse_categorical_accuracy: 0.9417\n","Epoch 22/40\n","542/542 [==============================] - 648s 1s/step - loss: 0.4066 - sparse_categorical_accuracy: 0.9408 - val_loss: 0.3582 - val_sparse_categorical_accuracy: 0.9447\n","Epoch 23/40\n","542/542 [==============================] - 653s 1s/step - loss: 0.3681 - sparse_categorical_accuracy: 0.9440 - val_loss: 0.3343 - val_sparse_categorical_accuracy: 0.9467\n","Epoch 24/40\n","542/542 [==============================] - 635s 1s/step - loss: 0.3392 - sparse_categorical_accuracy: 0.9464 - val_loss: 0.3127 - val_sparse_categorical_accuracy: 0.9488\n","Epoch 25/40\n","542/542 [==============================] - 623s 1s/step - loss: 0.3139 - sparse_categorical_accuracy: 0.9488 - val_loss: 0.2984 - val_sparse_categorical_accuracy: 0.9505\n","Epoch 26/40\n","542/542 [==============================] - 611s 1s/step - loss: 0.2919 - sparse_categorical_accuracy: 0.9510 - val_loss: 0.2858 - val_sparse_categorical_accuracy: 0.9519\n","Epoch 27/40\n","542/542 [==============================] - 646s 1s/step - loss: 0.2718 - sparse_categorical_accuracy: 0.9531 - val_loss: 0.2722 - val_sparse_categorical_accuracy: 0.9534\n","Epoch 28/40\n","542/542 [==============================] - 628s 1s/step - loss: 0.2540 - sparse_categorical_accuracy: 0.9552 - val_loss: 0.2615 - val_sparse_categorical_accuracy: 0.9548\n","Epoch 29/40\n","542/542 [==============================] - 618s 1s/step - loss: 0.2368 - sparse_categorical_accuracy: 0.9573 - val_loss: 0.2511 - val_sparse_categorical_accuracy: 0.9560\n","Epoch 30/40\n","542/542 [==============================] - 611s 1s/step - loss: 0.2214 - sparse_categorical_accuracy: 0.9592 - val_loss: 0.2417 - val_sparse_categorical_accuracy: 0.9571\n","Epoch 31/40\n","542/542 [==============================] - 637s 1s/step - loss: 0.2071 - sparse_categorical_accuracy: 0.9609 - val_loss: 0.2358 - val_sparse_categorical_accuracy: 0.9581\n","Epoch 32/40\n","542/542 [==============================] - 614s 1s/step - loss: 0.1940 - sparse_categorical_accuracy: 0.9626 - val_loss: 0.2272 - val_sparse_categorical_accuracy: 0.9592\n","Epoch 33/40\n","347/542 [==================>...........] - ETA: 3:17 - loss: 0.1838 - sparse_categorical_accuracy: 0.9640"]}]},{"cell_type":"code","source":["start = datetime.datetime.now()\n","\n","json_log = open(log_history, mode='a', buffering=1, encoding='utf-8')\n","\n","transformer.fit(train_dataset_dante,\n","                initial_epoch=32,\n","                epochs=EPOCHS_ADAM+EPOCHS_ADAM,\n","                shuffle=True,\n","                validation_data=validation_dataset_dante,\n","                callbacks=[tensorboard_callback,\n","                           json_logging_callback, \n","                           cp_callback])\n","\n","end = datetime.datetime.now()\n","print(f'Tempo necessario per l\\'addestramento: {end - start}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3yZ-Zq0xJIZX","executionInfo":{"status":"ok","timestamp":1679658518495,"user_tz":-60,"elapsed":4868159,"user":{"displayName":"daniele badiali","userId":"08100546172874775759"}},"outputId":"3a2afb44-8f86-4615-f331-e3c0fb9556f9"},"execution_count":46,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 33/40\n","542/542 [==============================] - 592s 1s/step - loss: 0.1819 - sparse_categorical_accuracy: 0.9642 - val_loss: 0.2193 - val_sparse_categorical_accuracy: 0.9602\n","Epoch 34/40\n","542/542 [==============================] - 617s 1s/step - loss: 0.1713 - sparse_categorical_accuracy: 0.9657 - val_loss: 0.2130 - val_sparse_categorical_accuracy: 0.9613\n","Epoch 35/40\n","542/542 [==============================] - 568s 1s/step - loss: 0.1610 - sparse_categorical_accuracy: 0.9670 - val_loss: 0.2081 - val_sparse_categorical_accuracy: 0.9620\n","Epoch 36/40\n","542/542 [==============================] - 565s 1s/step - loss: 0.1523 - sparse_categorical_accuracy: 0.9683 - val_loss: 0.2027 - val_sparse_categorical_accuracy: 0.9631\n","Epoch 37/40\n","542/542 [==============================] - 601s 1s/step - loss: 0.1434 - sparse_categorical_accuracy: 0.9697 - val_loss: 0.2014 - val_sparse_categorical_accuracy: 0.9638\n","Epoch 38/40\n","542/542 [==============================] - 565s 1s/step - loss: 0.1358 - sparse_categorical_accuracy: 0.9709 - val_loss: 0.1974 - val_sparse_categorical_accuracy: 0.9645\n","Epoch 39/40\n","542/542 [==============================] - 566s 1s/step - loss: 0.1282 - sparse_categorical_accuracy: 0.9722 - val_loss: 0.1940 - val_sparse_categorical_accuracy: 0.9652\n","Epoch 40/40\n","542/542 [==============================] - 601s 1s/step - loss: 0.1216 - sparse_categorical_accuracy: 0.9732 - val_loss: 0.1897 - val_sparse_categorical_accuracy: 0.9664\n","Tempo necessario per l'addestramento: 1:21:07.618712\n"]}]},{"cell_type":"markdown","source":["## Valutazione dell'addestramento\n","Avendo in output il log ed i risultati dell'addestramento, possiamo visualizzare\n","queste informazioni relativamente alle metriche di interesse."],"metadata":{"id":"L0w4wF79UhAp"}},{"cell_type":"code","source":["# Recupero il log di addestramento\n","df_history = pd.read_json(log_history, lines=True)\n","\n","# visualizzazione andamento addestramento\n","# su un grafico composto da due sub-plot\n","# uno per il loss, l'altro per l'accuracy\n","fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15,5))\n","\n","# Errore durante l'addestramento\n","ax1.plot(df_history['loss'], label='Loss')\n","ax1.plot(df_history['val_loss'], label='Validation Loss')\n","ax1.set_title('Training Loss')\n","ax1.legend()\n","\n","# Accuratezza durante l'addestramento\n","ax2.plot(df_history['sparse_categorical_accuracy'], label='Accuracy')\n","ax2.plot(df_history['val_sparse_categorical_accuracy'], label='Validation Accuracy')\n","ax2.set_title('Training Accuracy')\n","ax2.legend()\n","\n","plt.show()"],"metadata":{"id":"RpXR2p5VAdoG","colab":{"base_uri":"https://localhost:8080/","height":336},"executionInfo":{"status":"ok","timestamp":1679658829399,"user_tz":-60,"elapsed":635,"user":{"displayName":"daniele badiali","userId":"08100546172874775759"}},"outputId":"e73c8ad7-333d-493c-aba6-772cf2caeebd"},"execution_count":53,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 1080x360 with 2 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","source":["## Test del modello\n","La seguente cella permette di caricare l'ultimo checkpoint dell'addestramento\n","precedentemente salvato."],"metadata":{"id":"ReOkcBp2WHWW"}},{"cell_type":"code","source":["trainable = False\n","\n","transformer = TransformerBlock(NUM_LAYERS, \n","                               EMBEDDING_DIM, \n","                               NUM_HEADS, \n","                               FF_DIM,\n","                               MAX_SEQ_LENGTH,\n","                               tokenizers.ita.get_vocab_size(),\n","                               tfhub_handle_encoder,\n","                               trainable,\n","                               DROPUOT)"],"metadata":{"id":"RN0mnV8Wd92H","executionInfo":{"status":"ok","timestamp":1679658849200,"user_tz":-60,"elapsed":4383,"user":{"displayName":"daniele badiali","userId":"08100546172874775759"}}},"execution_count":54,"outputs":[]},{"cell_type":"code","source":["# Carico i pesi modello\n","latest = tf.train.latest_checkpoint(PATH_WEIGHTS)\n","transformer.load_weights(latest)"],"metadata":{"id":"5PIf_6-RSBb1","colab":{"base_uri":"https://localhost:8080/","height":363},"executionInfo":{"status":"error","timestamp":1679658995855,"user_tz":-60,"elapsed":5514,"user":{"displayName":"daniele badiali","userId":"08100546172874775759"}},"outputId":"19502e51-7eb0-43e6-deec-5b3f56630ca0"},"execution_count":57,"outputs":[{"output_type":"error","ename":"DataLossError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mDataLossError\u001b[0m                             Traceback (most recent call last)","\u001b[0;32m<ipython-input-57-73523d561144>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Carico i pesi modello\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mlatest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPATH_WEIGHTS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlatest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     53\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mDataLossError\u001b[0m: {{function_node __wrapped__RestoreV2_dtypes_100_device_/job:localhost/replica:0/task:0/device:CPU:0}} TensorBundle at /content/drive/MyDrive/BERT/weights/transformer_multi_bert_it_v2/cp.ckpt shard 0 (1572864 bytes): Checksum does not match: stored 703612876 vs. calculated on the restored bytes 1919215207 [Op:RestoreV2]"]}]},{"cell_type":"code","source":["class Translate:\n","  def __init__(self, transformer_block, tokenizers):\n","    self.transformer = transformer_block\n","    self.tokenizers = tokenizers\n","\n","  def predict(self, input_text, max_length):\n","    if input_text is None:\n","      input_text = (df[ORIGINAL_COLUMN].tolist())[np.random.choice(len(df[ORIGINAL_COLUMN].tolist()))]\n","      print(input_text)\n","\n","    inputs_bert = self.tokenizers.multilingual.tokenize(input_text)\n","\n","    start_end = self.tokenizers.ita.tokenize([''])[0]\n","    start = (start_end[0][tf.newaxis]).numpy()[0]\n","    end = (start_end[1][tf.newaxis]).numpy()[0]\n","\n","    output_array = tf.TensorArray(dtype=tf.int32, size=max_length, dynamic_size=True)\n","    output_array = output_array.write(0, tf.constant([start]))     \n","\n","    out_words = []\n","\n","    for i in tf.range(max_length):\n","      # decodifica e recupero probabilità di output\n","      output = tf.transpose(output_array.stack())\n","\n","      transformer_output = transformer((inputs_bert, output), \n","                                        training=False,\n","                                        debug=False)\n","\n","      predictions = transformer_output[:, -1:, :]\n","\n","      # selezione della parola più probabile\n","      predict = tf.argmax(predictions, -1)\n","      pred_values = (tf.keras.backend.argmax(transformer_output, axis=-1)).numpy()\n","    \n","      # inserimento della parola nella sequenza di output\n","      output_array = output_array.write(i+1, [pred_values[0][i]])\n","\n","      if pred_values[0][i] == end:\n","        break\n","\n","    output = tf.transpose(output_array.stack())\n","    text = tokenizers.ita.detokenize(output)[0]  \n","    tokens = tokenizers.ita.lookup(output)[0]\n","\n","    return text, tokens"],"metadata":{"id":"L2PEoJVb1V8x","executionInfo":{"status":"ok","timestamp":1679658537570,"user_tz":-60,"elapsed":4,"user":{"displayName":"daniele badiali","userId":"08100546172874775759"}}},"execution_count":50,"outputs":[]},{"cell_type":"code","source":["translate = Translate(transformer_block=transformer,\n","                      tokenizers=tokenizers)\n","\n","# Recupero un batch di esempi per la verifica delle classi custom che andrò a creare\n","for test_input_data, test_target_data in test_dataset.take(30):\n","  test_input_data = test_input_data.numpy().decode()\n","  test_target_data = test_target_data.numpy().decode()\n","\n","  text, token = translate.predict(tf.constant([test_input_data]), MAX_SEQ_LENGTH)\n","\n","  print(f'{\"Input\":15s}: {test_input_data}')\n","  print(f'{\"Target\":15s}: {test_target_data}')\n","  print(f'{\"Prediction\":15s}: {text.numpy().decode(\"utf-8\")}')  \n","  print('---------------------------------------------')"],"metadata":{"id":"udIjI2jZWR6g","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1679658588388,"user_tz":-60,"elapsed":50822,"user":{"displayName":"daniele badiali","userId":"08100546172874775759"}},"outputId":"0ef71b2f-1c59-4662-fd09-ad2c6c3684d5"},"execution_count":51,"outputs":[{"output_type":"stream","name":"stdout","text":["Input          : Je lui ai fait croire que son bien être\n","Target         : A chui intender faciea , che 'l su' disdotto\n","Prediction     : a chui intender faciea , che ' l su ' disdotto\n","---------------------------------------------\n","Input          : J' ètais plus excitèe que tout . \n","Target         : Mi piaciea più che null' altro , ch' e' ssia . \n","Prediction     : i ' era piu bella che ciaschedun l ' avria morto .\n","---------------------------------------------\n","Input          : J' ètais sèduisante , jeune et drôle . \n","Target         : I' era bella , e giovane , e folletta , \n","Prediction     : i ' era bella , giovane , e bello ,\n","---------------------------------------------\n","Input          : Mais il n' ètait pas à l' ècole d' affection . \n","Target         : Ma non era a la scuola de l' Amore\n","Prediction     : ma non era a la scuola de l ' amore\n","---------------------------------------------\n","Input          : C' ètait; cependant , je le sais maintenant en profondeur par c ur . \n","Target         : Istata; ma i' so or ben per cuore\n","Prediction     : istata ; ma i ' so or per cuore\n","---------------------------------------------\n","Input          : L' exercice qui sera prèsentè ici . \n","Target         : La pratica , la qual ti fie qui detta . \n","Prediction     : la qual porta mise qui detta .\n","---------------------------------------------\n","Input          : L' habitude m' a rendu si expèrimentèe . \n","Target         : Usanza me n' à fatta sì savietta , \n","Prediction     : ardimento a ben s ' a ben s ' acortesito .\n","---------------------------------------------\n","Input          : Je ne pouvais pas tromper les lecteurs . \n","Target         : Ched i' non dotterei nessun lettore , \n","Prediction     : ched i ' non de far grazia fecier lor venite\n","---------------------------------------------\n","Input          : qu' il m' a donnè une mauvaise opinion de ça . \n","Target         : Che di ciò mi faciesse desinore , \n","Prediction     : che di cio mi fecie punto ringio .\n","---------------------------------------------\n","Input          : Mais parce que j' ètais sèduisante et jeune . \n","Target         : Ma' ched i' fosse bella e giovanetta \n","Prediction     : ma ' ched i ' fosse bella e giovanetta\n","---------------------------------------------\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"Qex8JVqvJxzp"},"execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"},"colab":{"provenance":[],"collapsed_sections":["Day7C7Qh0b4G"]},"gpuClass":"standard","accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}